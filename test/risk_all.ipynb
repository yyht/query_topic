{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e54c4ab-2741-4f22-a329-61ac15f2e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys,os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "465797f1-b537-4c5f-a151-fbd51c51a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.extend(['/root/xiaoda/query_topic/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f4bdb0-2993-4984-bffb-e7c8306b7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "https://github.com/ondrejbohdal/meta-calibration/blob/main/Metrics/metrics.py\n",
    "\"\"\"\n",
    "\n",
    "class ECE(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(ECE, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels, mode='logits'):\n",
    "        if mode == 'logits':\n",
    "            softmaxes = F.softmax(logits, dim=1)\n",
    "        else:\n",
    "            softmaxes = logits\n",
    "        # softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        \n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfda9622-a378-497d-abff-6e70c1bb62c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senti /root/xiaoda/query_topic/risk_data/senti_label.txt ===schema-path===\n",
      "{'label2id': {'负向': 0, '正向': 1}, 'id2label': {0: '负向', 1: '正向'}, 'label_index': 0} ==schema_type== senti\n",
      "bias /root/xiaoda/query_topic/risk_data/bias_label.txt ===schema-path===\n",
      "{'label2id': {'偏见': 0, '正常': 1}, 'id2label': {0: '偏见', 1: '正常'}, 'label_index': 1} ==schema_type== bias\n",
      "ciron /root/xiaoda/query_topic/risk_data/ciron_label.txt ===schema-path===\n",
      "{'label2id': {'讽刺': 0, '正常': 1}, 'id2label': {0: '讽刺', 1: '正常'}, 'label_index': 2} ==schema_type== ciron\n",
      "intent /root/xiaoda/query_topic/risk_data/intention_label_v0.txt ===schema-path===\n",
      "{'label2id': {'主观评价/比较/判断': 0, '寻求建议/帮助': 1, '其它': 2}, 'id2label': {0: '主观评价/比较/判断', 1: '寻求建议/帮助', 2: '其它'}, 'label_index': 3} ==schema_type== intent\n",
      "offensive /root/xiaoda/query_topic/risk_data/offensive_label.txt ===schema-path===\n",
      "{'label2id': {'冒犯': 0, '正常': 1}, 'id2label': {0: '冒犯', 1: '正常'}, 'label_index': 4} ==schema_type== offensive\n",
      "query_risk /root/xiaoda/query_topic/risk_data/query_risk_label.txt ===schema-path===\n",
      "{'label2id': {'风险': 0, '个人信息': 1, '正常': 2}, 'id2label': {0: '风险', 1: '个人信息', 2: '正常'}, 'label_index': 5} ==schema_type== query_risk\n",
      "teenager /root/xiaoda/query_topic/risk_data/teenager_label.txt ===schema-path===\n",
      "{'label2id': {'不良': 0, '正常': 1}, 'id2label': {0: '不良', 1: '正常'}, 'label_index': 6} ==schema_type== teenager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/23/2022 10:58:26 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/23/2022 10:58:26 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/23/2022 10:58:26 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/23/2022 10:58:26 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/23/2022 10:58:26 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/23/2022 10:58:26 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/23/2022 10:58:26 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizerFast\n",
    "import transformers\n",
    "from datetime import timedelta\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from nets.them_classifier import MyBaseModel, RobertaClassifier\n",
    "\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "\n",
    "cur_dir_path = '/root/xiaoda/query_topic/'\n",
    "\n",
    "def load_label(filepath):\n",
    "    label_list = []\n",
    "    with open(filepath, 'r') as frobj:\n",
    "        for line in frobj:\n",
    "            label_list.append(line.strip())\n",
    "        n_classes = len(label_list)\n",
    "\n",
    "        label2id = {}\n",
    "        id2label = {}\n",
    "        for idx, label in enumerate(label_list):\n",
    "            label2id[label] = idx\n",
    "            id2label[idx] = label\n",
    "        return label2id, id2label\n",
    "\n",
    "class RiskInfer(object):\n",
    "    def __init__(self, config_path):\n",
    "\n",
    "        import torch, os, sys\n",
    "\n",
    "        con = configparser.ConfigParser()\n",
    "        con_path = os.path.join(cur_dir_path, config_path)\n",
    "        con.read(con_path, encoding='utf8')\n",
    "\n",
    "        args_path = dict(dict(con.items('paths')), **dict(con.items(\"para\")))\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(args_path[\"model_path\"], do_lower_case=True)\n",
    "\n",
    "        from collections import OrderedDict\n",
    "        self.schema_dict = OrderedDict({})\n",
    "\n",
    "        for label_index, schema_info in enumerate(args_path[\"label_path\"].split(',')):\n",
    "            schema_type, schema_path = schema_info.split(':')\n",
    "            schema_path = os.path.join(cur_dir_path, schema_path)\n",
    "            print(schema_type, schema_path, '===schema-path===')\n",
    "            label2id, id2label = load_label(schema_path)\n",
    "            self.schema_dict[schema_type] = {\n",
    "                'label2id':label2id,\n",
    "                'id2label':id2label,\n",
    "                'label_index':label_index\n",
    "            }\n",
    "            print(self.schema_dict[schema_type], '==schema_type==', schema_type)\n",
    "        \n",
    "        output_path = os.path.join(cur_dir_path, args_path['output_path'])\n",
    "\n",
    "        from roformer import RoFormerModel, RoFormerConfig\n",
    "\n",
    "        config = RoFormerConfig.from_pretrained(args_path[\"model_path\"])\n",
    "        encoder = RoFormerModel(config=config)\n",
    "        \n",
    "        encoder_net = MyBaseModel(encoder, config)\n",
    "\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        classifier_list = []\n",
    "\n",
    "        schema_list = list(self.schema_dict.keys())\n",
    "\n",
    "        for schema_key in schema_list:\n",
    "            classifier = RobertaClassifier(\n",
    "                hidden_size=config.hidden_size, \n",
    "                dropout_prob=con.getfloat('para', 'out_dropout_rate'),\n",
    "                num_labels=len(self.schema_dict[schema_key]['label2id']), \n",
    "                dropout_type=con.get('para', 'dropout_type'))\n",
    "            classifier_list.append(classifier)\n",
    "\n",
    "        classifier_list = nn.ModuleList(classifier_list)\n",
    "\n",
    "        class MultitaskClassifier(nn.Module):\n",
    "            def __init__(self, transformer, classifier_list):\n",
    "                super().__init__()\n",
    "\n",
    "                self.transformer = transformer\n",
    "                self.classifier_list = classifier_list\n",
    "\n",
    "            def forward(self, input_ids, input_mask, \n",
    "                        segment_ids=None, \n",
    "                        transformer_mode='mean_pooling', \n",
    "                        dt_idx=None):\n",
    "                hidden_states = self.transformer(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              return_mode=transformer_mode)\n",
    "                outputs_list = []\n",
    "                \n",
    "                for idx, classifier in enumerate(self.classifier_list):\n",
    "                    \n",
    "                    if dt_idx is not None and idx != dt_idx:\n",
    "                        continue\n",
    "                    \n",
    "                    ce_logits = classifier(hidden_states)\n",
    "                    outputs_list.append(ce_logits)\n",
    "                return outputs_list, hidden_states\n",
    "\n",
    "        self.net = MultitaskClassifier(encoder_net, classifier_list).to(self.device)\n",
    "\n",
    "        # eo = 9\n",
    "        # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw.focal'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_contrast_cls.pth.{}'.format(eo)), map_location=self.device)\n",
    "        # self.net.load_state_dict(ckpt)\n",
    "        # self.net.eval()\n",
    "        \n",
    "    def reload(self, model_path):\n",
    "        ckpt = torch.load(model_path, map_location=self.device)\n",
    "        self.net.load_state_dict(ckpt)\n",
    "        self.net.eval()\n",
    "\n",
    "    def predict(self, text):\n",
    "\n",
    "        \"\"\"抽取输入text所包含的类型\n",
    "        \"\"\"\n",
    "        encoder_txt = self.tokenizer.encode_plus(text, max_length=256)\n",
    "        input_ids = torch.tensor(encoder_txt[\"input_ids\"]).long().unsqueeze(0).to(self.device)\n",
    "        token_type_ids = torch.tensor(encoder_txt[\"token_type_ids\"]).unsqueeze(0).to(self.device)\n",
    "        attention_mask = torch.tensor(encoder_txt[\"attention_mask\"]).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        scores_dict = {}\n",
    "        with torch.no_grad():\n",
    "            [logits_list, \n",
    "            hidden_states] = self.net(input_ids, \n",
    "                attention_mask, token_type_ids, transformer_mode='cls')\n",
    "        for schema_type, logits in zip(list(self.schema_dict.keys()), logits_list):\n",
    "            scores = torch.nn.Softmax(dim=1)(logits)[0].data.cpu().numpy()\n",
    "            scores_dict[schema_type] = []\n",
    "            for index, score in enumerate(scores):\n",
    "                scores_dict[schema_type].append([self.schema_dict[schema_type]['id2label'][index], \n",
    "                                        float(score)])\n",
    "        return scores_dict\n",
    "\n",
    "risk_api = RiskInfer('./risk_data/config.ini')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44f0df61-6038-4625-98b2-2d1723a74425",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "offensive = []\n",
    "with open('/data/albert.xht/sentiment/dev/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive.append(content)\n",
    "        \n",
    "offensive_test = []\n",
    "with open('/data/albert.xht/sentiment/test/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive_test.append(content)\n",
    "\n",
    "        \n",
    "cdia_bias = []\n",
    "with open('/data/albert.xht/sentiment/dev/cdial_bias.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        cdia_bias.append(content)\n",
    "        \n",
    "senti_copr = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_copr.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_copr.append(content)\n",
    "        \n",
    "ciron = []\n",
    "with open('/data/albert.xht/sentiment/dev/chinese_ciron.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        ciron.append(content)\n",
    "\n",
    "senti_smp = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smp_usual.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smp.append(content)\n",
    "        \n",
    "senti_smpecisa = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smpecisa.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smpecisa.append(content)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a80fa64-5c38-4fbe-b1d8-32620663a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "def eval_all(data, model, key):\n",
    "    pred = []\n",
    "    gold = []\n",
    "    pred_score = []\n",
    "    for item in tqdm(data):\n",
    "        gold.append(item['label'][0])\n",
    "        if isinstance(item['text'], list):\n",
    "            text = \"\\n\".join(item['text'])\n",
    "        else:\n",
    "            text = item['text']\n",
    "        result = model.predict(text)\n",
    "        score = sorted(result[key], key=lambda u:u[1], reverse=True)\n",
    "        pred.append(score[0][0])\n",
    "        pred_score.append(result[key])\n",
    "    print(classification_report(gold, pred, digits=4), '===', key)\n",
    "    return pred, gold, pred_score\n",
    "    \n",
    "\n",
    "def evaluation_ece(pred_score, gold):\n",
    "    pred_score_l = []\n",
    "    mapping_dict = {}\n",
    "    for item in pred_score:\n",
    "        pred_score_l.append([])\n",
    "        for idx, p in enumerate(item):\n",
    "            if p[0] not in mapping_dict:\n",
    "                mapping_dict[p[0]] = idx\n",
    "            pred_score_l[-1].append(p[1])\n",
    "    pred_score_l = torch.tensor(pred_score_l)\n",
    "    gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "\n",
    "    ece_fn = ECE(n_bins=15)\n",
    "    print(ece_fn(pred_score_l, gold_l, mode='probs'), '==ece==')\n",
    "# pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "# evaluation_ece(pred_score, gold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cec7a90e-340c-4972-82fd-cf239ecd51d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model_path):\n",
    "    print(model_path)\n",
    "    risk_api.reload(model_path)\n",
    "    print('===offensive===')\n",
    "    pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===cdia-bias===')\n",
    "    pred, gold, pred_score = eval_all(cdia_bias, risk_api, 'bias')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===ciron===')\n",
    "    pred, gold, pred_score = eval_all(ciron, risk_api, 'ciron')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===chsenti===')\n",
    "    pred, gold, pred_score = eval_all(senti_copr, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smpecisa===')\n",
    "    pred, gold, pred_score = eval_all(senti_smpecisa, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smp===')\n",
    "    pred, gold, pred_score = eval_all(senti_smp, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd9ee668-8b5a-4a99-a124-e9b487915900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2/multitask_cls.pth.9\n",
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5304 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 5304/5304 [00:44<00:00, 120.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7338    0.8680    0.7953      2106\n",
      "          正常     0.9012    0.7927    0.8435      3198\n",
      "\n",
      "    accuracy                         0.8226      5304\n",
      "   macro avg     0.8175    0.8303    0.8194      5304\n",
      "weighted avg     0.8347    0.8226    0.8243      5304\n",
      " === offensive\n",
      "tensor([0.1152]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2829 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'bias#1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50706/3853658553.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2/multitask_cls.pth.9'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_50706/2554813840.py\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===cdia-bias==='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdia_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bias#1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===ciron==='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_50706/3426700064.py\u001b[0m in \u001b[0;36meval_all\u001b[0;34m(data, model, key)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mpred_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bias#1'"
     ]
    }
   ],
   "source": [
    "model_path = '/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2/multitask_cls.pth.9'\n",
    "\n",
    "evaluation(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "c4466dc0-a7a1-4782-b780-146598a9f3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/albert.xht/xiaodao/risk_classification/query_risk_v2/multitask_raw_all_risk_v2_10/multitask_cls.pth.3\n",
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:49<00:00, 106.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7057    0.8837    0.7847      2106\n",
      "          正常     0.9081    0.7573    0.8259      3198\n",
      "\n",
      "    accuracy                         0.8075      5304\n",
      "   macro avg     0.8069    0.8205    0.8053      5304\n",
      "weighted avg     0.8278    0.8075    0.8096      5304\n",
      "\n",
      "tensor([0.1108]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:26<00:00, 106.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.6466    0.4178    0.5076       718\n",
      "          正常     0.8233    0.9223    0.8700      2111\n",
      "\n",
      "    accuracy                         0.7943      2829\n",
      "   macro avg     0.7349    0.6701    0.6888      2829\n",
      "weighted avg     0.7784    0.7943    0.7780      2829\n",
      "\n",
      "tensor([0.0118]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:08<00:00, 107.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9118    0.9692    0.9396       779\n",
      "          讽刺     0.4894    0.2396    0.3217        96\n",
      "\n",
      "    accuracy                         0.8891       875\n",
      "   macro avg     0.7006    0.6044    0.6307       875\n",
      "weighted avg     0.8655    0.8891    0.8718       875\n",
      "\n",
      "tensor([0.0205]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:11<00:00, 105.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9294    0.9325    0.9310       593\n",
      "          负向     0.9339    0.9308    0.9323       607\n",
      "\n",
      "    accuracy                         0.9317      1200\n",
      "   macro avg     0.9316    0.9317    0.9317      1200\n",
      "weighted avg     0.9317    0.9317    0.9317      1200\n",
      "\n",
      "tensor([0.0193]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:23<00:00, 107.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8765    0.8035    0.8384      1201\n",
      "          负向     0.8347    0.8976    0.8650      1328\n",
      "\n",
      "    accuracy                         0.8529      2529\n",
      "   macro avg     0.8556    0.8505    0.8517      2529\n",
      "weighted avg     0.8546    0.8529    0.8524      2529\n",
      "\n",
      "tensor([0.0264]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:26<00:00, 107.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9084    0.8721    0.8899      1126\n",
      "          负向     0.9183    0.9424    0.9302      1718\n",
      "\n",
      "    accuracy                         0.9146      2844\n",
      "   macro avg     0.9134    0.9072    0.9100      2844\n",
      "weighted avg     0.9144    0.9146    0.9142      2844\n",
      "\n",
      "tensor([0.0252]) ==ece==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = '/data/albert.xht/xiaodao/risk_classification/query_risk_v2/multitask_raw_all_risk_v2_10/multitask_cls.pth.3'\n",
    "evaluation(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe28aaa-6f01-4243-bc06-0cb17a8a6f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_api.predict('傻逼')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9e5a0542-4334-4d9a-bcd3-c0d3b4481332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56443it [08:43, 107.87it/s]\n",
      "10001it [01:31, 109.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# risk_api.reload(model)\n",
    "result_list = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/疑似有风险query_from对话预训练数据-20221130.txt') as frobj:\n",
    "    for line in tqdm(frobj):\n",
    "        text = line.strip()\n",
    "        result = risk_api.predict(text)\n",
    "        result_list.append((text, result))\n",
    "with open('/root/xiaoda/risk_detection/data/tmjl_1w.txt') as frobj:\n",
    "    for line in tqdm(frobj):\n",
    "        text = line.strip()\n",
    "        result = risk_api.predict(text)\n",
    "        result_list.append((text, result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "24244b57-9099-420c-9165-5de17e4b9e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_matrix = []\n",
    "for item in result_list:\n",
    "    p = []\n",
    "    for key in ['senti#1', 'senti#2', 'senti#3', 'senti#4', 'senti#5', \n",
    "                'senti#6', 'bias#1', 'bias#2', 'ciron', 'offensive', 'teenager', 'query_risk']:\n",
    "        if item[1][key][0][1] >= 0.75:\n",
    "            p.append(1)\n",
    "        else:\n",
    "            p.append(0)\n",
    "    result_matrix.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "57e65dff-d810-4f00-b9fd-094f6124f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_matrix = result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "7a5d62a0-2c53-41d4-9159-4665acea587d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56443, 2)\n",
      "(56443, 2)\n",
      "(56443, 2)\n",
      "(56443, 2)\n",
      "(56443, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "\n",
    "\n",
    "result_matrix = result_matrix[:56443]\n",
    "random.shuffle(result_matrix)\n",
    "weak_result_matrix = np.array(result_matrix)\n",
    "\n",
    "def SIMPLE(result_matrix):\n",
    "    votes = np.sum(result_matrix, axis=-1)\n",
    "    labels = np.array(votes >= 5).astype(np.int)\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    \n",
    "    for i in range(5):\n",
    "        result = clf.fit(result_matrix, labels)\n",
    "        probs = clf.predict_proba(result_matrix)\n",
    "        print(probs.shape)\n",
    "        labels = np.argmax(probs, axis=-1)\n",
    "    return probs, clf\n",
    "\n",
    "probs, clf = SIMPLE(weak_result_matrix)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "58d54adf-768f-4139-a928-cda80128db59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66444, 2)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = clf.predict_proba(np.array(result_matrix))\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "bd7e123c-27c3-4b39-9f37-1592e936bdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262, 9738)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = []\n",
    "clean = []\n",
    "for idx in range(probs.shape[0]):\n",
    "    if idx <= 56443:\n",
    "        continue\n",
    "    if probs[idx,1] >= 0.7:\n",
    "        ff.append((idx, result_list[idx], probs[idx]))\n",
    "    else:\n",
    "        clean.append((idx, result_list[idx], probs[idx]))\n",
    "        \n",
    "len(ff), len(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c8b3c-d3a8-47c8-a269-bd99dd884133",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "8922e114-8fbc-41e7-a803-8cd2c4606bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/tmjl_1w_clean.json', 'w') as fwobj:\n",
    "    for item in clean:\n",
    "        tmp = {\n",
    "            'text':item[1][0],\n",
    "            'label':['正常']\n",
    "        }\n",
    "        fwobj.write(json.dumps(tmp, ensure_ascii=False)+'\\n')\n",
    "    for item in ff:\n",
    "        tmp = {\n",
    "            'text':item[1][0],\n",
    "            'label':['风险']\n",
    "        }\n",
    "        fwobj.write(json.dumps(tmp, ensure_ascii=False)+'\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "bbeb2b4c-3171-480e-9281-5cd8c6bce7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/albert.xht/xiaodao/risk_classification/query_risk_v2/multitask_raw_all_risk_v2_10/random_forest.joblib']"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, \"/data/albert.xht/xiaodao/risk_classification/query_risk_v2/multitask_raw_all_risk_v2_10/random_forest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d3730bd5-2b5e-4405-8d7c-8cb58c3085da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [03:01, 55.06it/s]\n"
     ]
    }
   ],
   "source": [
    "tmjl_1w_resp = []\n",
    "tmjl_1w_detail = []\n",
    "from tqdm import tqdm\n",
    "with open('/root/xiaoda/risk_detection/data/tmjl_1w.txt') as frobj:\n",
    "    for line in tqdm(frobj):\n",
    "        content = line.strip()\n",
    "        resp, detail = predict(content)\n",
    "        tmjl_1w_resp.append(resp)\n",
    "        tmjl_1w_detail.append(detail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "a2d6c7f2-727f-4baf-a44a-494d4cac791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(text):\n",
    "    resutl = risk_api.predict(text)\n",
    "    from pprint import pprint\n",
    "    p = []\n",
    "    for key in ['senti#1', 'senti#2', 'senti#3', 'senti#4', 'senti#5', \n",
    "                'senti#6', 'bias#1', 'bias#2', 'ciron', 'offensive', 'teenager', 'query_risk']:\n",
    "        if resutl[key][0][1] > 0.7:\n",
    "            p.append(1)\n",
    "        else:\n",
    "            p.append(0)\n",
    "    p = np.array([p])\n",
    "    resp = clf.predict_proba(p).tolist()[0]\n",
    "    key = ['正常', '风险']\n",
    "    return dict(zip(key, resp)), resutl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "036eae67-13f2-4be3-a93a-5f687811dc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'正常': 0.8240041961898732, '风险': 0.17599580381012703},\n",
       " {'senti#1': [['负向', 0.7929189205169678], ['正向', 0.20708103477954865]],\n",
       "  'senti#2': [['负向', 0.6586761474609375], ['正向', 0.3413238227367401]],\n",
       "  'senti#3': [['负向', 0.9517019987106323], ['正向', 0.04829796031117439]],\n",
       "  'senti#4': [['负向', 0.6687620282173157], ['正向', 0.3312379717826843]],\n",
       "  'senti#5': [['负向', 0.9325788021087646], ['正向', 0.06742116808891296]],\n",
       "  'senti#6': [['负向', 0.584587574005127], ['正向', 0.41541245579719543]],\n",
       "  'bias#1': [['偏见', 0.0816979855298996], ['正常', 0.9183019995689392]],\n",
       "  'bias#2': [['偏见', 0.032336749136447906], ['正常', 0.9676632881164551]],\n",
       "  'ciron': [['讽刺', 0.06859628111124039], ['正常', 0.9314036965370178]],\n",
       "  'intent': [['主观评价/比较/判断', 2.3500122097175336e-06],\n",
       "   ['寻求建议/帮助', 0.00012920489825773984],\n",
       "   ['其它', 0.9998683929443359]],\n",
       "  'offensive': [['冒犯', 0.014626090414822102], ['正常', 0.985373854637146]],\n",
       "  'query_risk': [['风险', 0.17795933783054352],\n",
       "   ['个人信息', 0.0015156776644289494],\n",
       "   ['正常', 0.8205249905586243]],\n",
       "  'teenager': [['不良', 0.006299775093793869], ['正常', 0.9937002658843994]]})"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('ABB有哪些')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c6ab19aa-a687-4685-949d-eea2dc3c17a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'debug_info': {}, 'dialog_state': {}, 'grounding_evidence': {'obj': {'sc_name': 'structure_web_info', 'score': 0.0, 'snippet': '沉甸甸、白茫茫、孤零零、黑乎乎、眼睁睁、绿油油、 慢吞吞、急匆匆、笑眯眯、懒洋洋、齐刷刷、笑盈盈、 黑沉沉、亮闪闪、亮晶晶、香喷喷、静悄悄、金灿灿、', 'url': 'http://m.xuexila.com/ciyu/636003.html'}, 'score': 1.0, 'source': 'openweb'}, 'response': '黑沉沉、亮闪闪、亮晶晶、香喷喷、静悄悄、金灿灿', 'response_type': ''}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from urllib import request, parse\n",
    "import json\n",
    "data = {\n",
    "    \"query\":\"ABB形式都有哪些\",\n",
    "    \"history\":[ \n",
    "        # {\n",
    "        #     \"role\":\"human\",\n",
    "        #     \"utterance\":\"天空为什么是蓝色\",\n",
    "        #     \"rewritten_utterance\":\"天空为什么是蓝色\"\n",
    "        # },\n",
    "        # {\n",
    "        #     \"utterance\":\"因为大气对太阳光的散射作用,使我们看到的天空呈现蓝色\",\n",
    "        #     \"role\":\"bot\"\n",
    "        # }\n",
    "        \n",
    "    ],\n",
    "    \"user_profile\":{\n",
    "        \"persona\":[\"你叫小明\"]\n",
    "    },\n",
    "    \"bot_profile\":{\n",
    "        \"persona\":[ \n",
    "            \"我是小达;我是女生;我今年21岁;我生日是2001年11月11日;我是天蝎座;我现在在复旦大学上学;我现在在上海;我的专业是工商管理;我大三了;我还没有工作;我还没有毕业;我是浙江杭州人;我从小在杭州长大;我喜欢阅读，尤其是诗歌;我是个小吃货;我最爱巧克力了\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "data = json.dumps(data).encode('utf-8')\n",
    "req =  request.Request('http://39.105.47.48:8003', data=data) # this will make the method \"POST\"\n",
    "resp = request.urlopen(req).read()\n",
    "resp = json.loads(resp)\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea86860d-7434-458f-9782-57191aa562ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "reject_response = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
