{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d5fd13-e5c8-4c6a-ac32-bab07cb2df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys,os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242205d9-683b-46cd-a078-76853451c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.extend(['/root/xiaoda/query_topic/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cab2549-545f-46e7-b7a0-09c0629b0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "https://github.com/ondrejbohdal/meta-calibration/blob/main/Metrics/metrics.py\n",
    "\"\"\"\n",
    "\n",
    "class ECE(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(ECE, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels, mode='logits'):\n",
    "        if mode == 'logits':\n",
    "            softmaxes = F.softmax(logits, dim=1)\n",
    "        else:\n",
    "            softmaxes = logits\n",
    "        # softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        \n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e70be5-6ca2-4bd6-8e93-26f5f0dd9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizerFast\n",
    "import transformers\n",
    "from datetime import timedelta\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from nets.them_classifier import MyBaseModel, RobertaClassifier\n",
    "\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "\n",
    "cur_dir_path = '/root/xiaoda/query_topic/'\n",
    "\n",
    "def load_label(filepath):\n",
    "    label_list = []\n",
    "    with open(filepath, 'r') as frobj:\n",
    "        for line in frobj:\n",
    "            label_list.append(line.strip())\n",
    "        n_classes = len(label_list)\n",
    "\n",
    "        label2id = {}\n",
    "        id2label = {}\n",
    "        for idx, label in enumerate(label_list):\n",
    "            label2id[label] = idx\n",
    "            id2label[idx] = label\n",
    "        return label2id, id2label\n",
    "\n",
    "class RiskInfer(object):\n",
    "    def __init__(self, config_path):\n",
    "\n",
    "        import torch, os, sys\n",
    "\n",
    "        con = configparser.ConfigParser()\n",
    "        con_path = os.path.join(cur_dir_path, config_path)\n",
    "        con.read(con_path, encoding='utf8')\n",
    "\n",
    "        args_path = dict(dict(con.items('paths')), **dict(con.items(\"para\")))\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(args_path[\"model_path\"], do_lower_case=True)\n",
    "\n",
    "        from collections import OrderedDict\n",
    "        self.schema_dict = OrderedDict({})\n",
    "        self.schema2schema_id = {}\n",
    "        self.schema_id2schema = {}\n",
    "\n",
    "        for label_index, schema_info in enumerate(args_path[\"label_path\"].split(',')):\n",
    "            schema_type, schema_path = schema_info.split(':')\n",
    "            schema_path = os.path.join(cur_dir_path, schema_path)\n",
    "            print(schema_type, schema_path, '===schema-path===')\n",
    "            label2id, id2label = load_label(schema_path)\n",
    "            self.schema_dict[schema_type] = {\n",
    "                'label2id':label2id,\n",
    "                'id2label':id2label,\n",
    "                'label_index':label_index\n",
    "            }\n",
    "            # print(self.schema_dict[schema_type], '==schema_type==', schema_type)\n",
    "            self.schema2schema_id[schema_type] = label_index\n",
    "            self.schema_id2schema[label_index] = schema_type\n",
    "        \n",
    "        output_path = os.path.join(cur_dir_path, args_path['output_path'])\n",
    "\n",
    "        # from roformer import RoFormerModel, RoFormerConfig\n",
    "        from transformers import BertModel, BertConfig\n",
    "\n",
    "        config = BertConfig.from_pretrained(args_path[\"model_path\"])\n",
    "        encoder = BertModel(config=config)\n",
    "        \n",
    "        encoder_net = MyBaseModel(encoder, config)\n",
    "\n",
    "        self.device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        classifier_list = []\n",
    "\n",
    "        schema_list = list(self.schema_dict.keys())\n",
    "\n",
    "        for schema_key in schema_list:\n",
    "            classifier = RobertaClassifier(\n",
    "                hidden_size=config.hidden_size, \n",
    "                dropout_prob=con.getfloat('para', 'out_dropout_rate'),\n",
    "                num_labels=len(self.schema_dict[schema_key]['label2id']), \n",
    "                dropout_type=con.get('para', 'dropout_type'))\n",
    "            classifier_list.append(classifier)\n",
    "\n",
    "        classifier_list = nn.ModuleList(classifier_list)\n",
    "\n",
    "        class MultitaskClassifier(nn.Module):\n",
    "            def __init__(self, transformer, classifier_list):\n",
    "                super().__init__()\n",
    "\n",
    "                self.transformer = transformer\n",
    "                self.classifier_list = classifier_list\n",
    "\n",
    "            def forward(self, input_ids, input_mask, \n",
    "                        segment_ids=None, \n",
    "                        transformer_mode='mean_pooling', \n",
    "                        dt_idx=None, mode='predict'):\n",
    "                hidden_states = self.transformer(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              return_mode=transformer_mode)\n",
    "                outputs_list = []\n",
    "                \n",
    "                for idx, classifier in enumerate(self.classifier_list):\n",
    "                    \n",
    "                    if dt_idx:\n",
    "                        if idx not in dt_idx:\n",
    "                            outputs_list.append([])\n",
    "                            continue\n",
    "                    \n",
    "                    scores = classifier(hidden_states)\n",
    "                    if mode == 'predict':\n",
    "                        scores = torch.nn.Softmax(dim=1)(scores)\n",
    "                    outputs_list.append(scores)\n",
    "                return outputs_list, hidden_states\n",
    "\n",
    "        self.net = MultitaskClassifier(encoder_net, classifier_list).to(self.device)\n",
    "\n",
    "        # eo = 9\n",
    "        # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw.focal'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_contrast_cls.pth.{}'.format(eo)), map_location=self.device)\n",
    "        # self.net.load_state_dict(ckpt)\n",
    "        # self.net.eval()\n",
    "        \n",
    "    def reload(self, model_path):\n",
    "        ckpt = torch.load(model_path, map_location=self.device)\n",
    "        self.net.load_state_dict(ckpt)\n",
    "        self.net.eval()\n",
    "        self.net = self.net.half()\n",
    "\n",
    "    def predict(self, text, allowed_schema_type={}):\n",
    "\n",
    "        \"\"\"抽取输入text所包含的类型\n",
    "        \"\"\"\n",
    "        # start = time.time()\n",
    "        # encoder_txt = self.tokenizer.encode_plus(text, max_length=256)\n",
    "        # input_ids = torch.tensor(encoder_txt[\"input_ids\"]).long().unsqueeze(0).to(self.device)\n",
    "        # token_type_ids = torch.tensor(encoder_txt[\"token_type_ids\"]).unsqueeze(0).to(self.device)\n",
    "        # attention_mask = torch.tensor(encoder_txt[\"attention_mask\"]).unsqueeze(0).to(self.device)\n",
    "        # print(time.time() - start, '====tokenization====')\n",
    "        \n",
    "        start = time.time()\n",
    "        encoder_txt = self.tokenizer([text], max_length=256)\n",
    "        input_ids = torch.tensor(encoder_txt[\"input_ids\"]).long().to(self.device)\n",
    "        token_type_ids = torch.tensor(encoder_txt[\"token_type_ids\"]).to(self.device)\n",
    "        attention_mask = torch.tensor(encoder_txt[\"attention_mask\"]).to(self.device)\n",
    "        # print(time.time() - start, '====tokenization====')\n",
    "        \n",
    "        allowed_schema_type_ids = {}\n",
    "        for schema_type in allowed_schema_type:\n",
    "            allowed_schema_type_ids[self.schema2schema_id[schema_type]] = schema_type\n",
    "        \n",
    "        scores_dict = {}\n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            [logits_list, \n",
    "            hidden_states] = self.net(input_ids, \n",
    "                attention_mask, token_type_ids, transformer_mode='cls', dt_idx=allowed_schema_type_ids)\n",
    "        # print(time.time() - start, '====inference====')\n",
    "        \n",
    "        old_start = time.time()\n",
    "        \n",
    "        for schema_idx, (schema_type, scores) in enumerate(zip(list(self.schema_dict.keys()), logits_list)):\n",
    "            if allowed_schema_type:\n",
    "                if schema_type not in allowed_schema_type:\n",
    "                    continue\n",
    "            # scores = torch.nn.Softmax(dim=1)(logits)[0].data.cpu().numpy()\n",
    "            scores = scores[0].data.cpu().numpy()\n",
    "            scores_dict[schema_type] = []\n",
    "            for index, score in enumerate(scores):\n",
    "                scores_dict[schema_type].append([self.schema_dict[schema_type]['id2label'][index], \n",
    "                                        float(score)])\n",
    "            if schema_type in ['topic']:\n",
    "                schema_type_scores = sorted(scores_dict[schema_type], key=lambda item:item[1], reverse=True)\n",
    "                scores_dict[schema_type] = schema_type_scores[0:5]\n",
    "        # print(time.time() - old_start, '====result analysis====')\n",
    "        return scores_dict\n",
    "    \n",
    "    def get_logitnorm(self, text):\n",
    "        \"\"\"抽取输入text所包含的类型\n",
    "        \"\"\"\n",
    "        encoder_txt = self.tokenizer.encode_plus(text, max_length=256)\n",
    "        input_ids = torch.tensor(encoder_txt[\"input_ids\"]).long().unsqueeze(0).to(self.device)\n",
    "        token_type_ids = torch.tensor(encoder_txt[\"token_type_ids\"]).unsqueeze(0).to(self.device)\n",
    "        attention_mask = torch.tensor(encoder_txt[\"attention_mask\"]).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        scores_dict = {}\n",
    "        logits_norm_list = []\n",
    "        with torch.no_grad():\n",
    "            [logits_list, \n",
    "            hidden_states] = self.net(input_ids, \n",
    "                attention_mask, token_type_ids, transformer_mode='cls')\n",
    "            for logits in logits_list:\n",
    "                logits_norm_list.append(logits/torch.norm(logits, p=2, dim=-1, keepdim=True) + 1e-7)\n",
    "        for schema_type, logit_norm in zip(list(self.schema_dict.keys()), logits_norm_list):\n",
    "            scores_dict[schema_type] = logit_norm[0].data.cpu().numpy()\n",
    "        return scores_dict\n",
    "            \n",
    "    \n",
    "    def predict_batch(self, text, allowed_schema_type={}):\n",
    "        if isinstance(text, list):\n",
    "            text_list = text\n",
    "        else:\n",
    "            text_list = [text]\n",
    "        model_input = self.tokenizer(text_list, return_tensors=\"pt\",padding=True)\n",
    "        for key in model_input:\n",
    "            model_input[key] = model_input[key].to(self.device)\n",
    "        \n",
    "        allowed_schema_type_ids = {}\n",
    "        for schema_type in allowed_schema_type:\n",
    "            allowed_schema_type_ids[self.schema2schema_id[schema_type]] = schema_type\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            [logits_list, \n",
    "            hidden_states] = self.net(model_input['input_ids'], \n",
    "                model_input['attention_mask'], \n",
    "                model_input['token_type_ids'], transformer_mode='cls', dt_idx=allowed_schema_type_ids)\n",
    "        score_dict_list = []\n",
    "        for idx, text in enumerate(text_list):\n",
    "            scores_dict = {}\n",
    "            for schema_idx, (schema_type, scores) in enumerate(zip(list(self.schema_dict.keys()), logits_list)):\n",
    "                if allowed_schema_type:\n",
    "                    if schema_type not in allowed_schema_type:\n",
    "                        continue\n",
    "                # scores = torch.nn.Softmax(dim=1)(logits)[idx].data.cpu().numpy()\n",
    "                scores = scores[idx].data.cpu().numpy()\n",
    "                scores_dict[schema_type] = []\n",
    "                for index, score in enumerate(scores):\n",
    "                    scores_dict[schema_type].append([self.schema_dict[schema_type]['id2label'][index], \n",
    "                                            float(score)])\n",
    "                if schema_type in ['topic']:\n",
    "                    schema_type_scores = sorted(scores_dict[schema_type], key=lambda item:item[1], reverse=True)\n",
    "                    scores_dict[schema_type] = schema_type_scores[0:5]\n",
    "            score_dict_list.append(scores_dict)\n",
    "        return score_dict_list\n",
    "\n",
    "# risk_api = RiskInfer('./risk_data/config.ini')\n",
    "# risk_api = RiskInfer('./risk_data_v5/config_offensive_risk.ini')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b890ed6b-6288-4751-b6ed-a50b6245b299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003151893615722656 {'input_ids': [[101, 872, 3221, 1004, 6873, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "f = green_green_topic_risk_api.tokenizer(['你是傻逼'])\n",
    "print(time.time()-start, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d6ea16-9467-4075-92c0-f9d125759850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# green_risk_api = RiskInfer('./risk_data_tiny/config_risk.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcf8e2f4-7d98-4f95-b42f-f4bbfe668a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# green_topic_risk_api = RiskInfer('./risk_data_tiny/config_topic_risk.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c04e45-48fe-4de7-a8ea-9146219fe529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic /data/albert.xht/raw_chat_corpus/topic_classification_v4/label_list.txt ===schema-path===\n",
      "senti_query /data/albert.xht/xiaoda/sentiment/senti/senti_query_label.txt ===schema-path===\n",
      "senti /data/albert.xht/xiaoda/sentiment/senti/senti_label.txt ===schema-path===\n",
      "bias /data/albert.xht/xiaoda/sentiment/bias/bias_label.txt ===schema-path===\n",
      "ciron /data/albert.xht/xiaoda/sentiment/ciron/ciron_label.txt ===schema-path===\n",
      "intent /data/albert.xht/xiaoda/sentiment/intention_data_v2-1/label.txt ===schema-path===\n",
      "offensive /data/albert.xht/xiaoda/sentiment/offensive/offensive_label.txt ===schema-path===\n",
      "query_risk /data/albert.xht/xiaoda/sentiment/query_risk_v12/query_risk_label.txt ===schema-path===\n",
      "teenager /data/albert.xht/xiaoda/sentiment/teenager//teenager_label.txt ===schema-path===\n",
      "politics /data/albert.xht/xiaoda/sentiment/green_politics/green_politics_label.txt ===schema-path===\n",
      "porn /data/albert.xht/xiaoda/sentiment/green_porn_v1/green_porn_label.txt ===schema-path===\n",
      "abusive /data/albert.xht/xiaoda/sentiment/green_abusive_v1/green_abusive_label.txt ===schema-path===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/13/2023 20:12:21 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "03/13/2023 20:12:21 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "03/13/2023 20:12:21 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "03/13/2023 20:12:21 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "03/13/2023 20:12:21 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "03/13/2023 20:12:21 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "03/13/2023 20:12:21 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "03/13/2023 20:12:21 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "03/13/2023 20:12:21 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "03/13/2023 20:12:21 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "03/13/2023 20:12:21 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "03/13/2023 20:12:21 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "green_green_topic_risk_api = RiskInfer('./risk_data_tiny/config_topic_risk_green_v1.ini')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22cb8822-999f-443b-ac3c-326ab61c777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# green_green_topic_v5_risk_base_api = RiskInfer('./risk_data_tiny/config_topic_v5_risk_green_v1_base.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7464198e-f5c6-444a-b5c1-4eb9ad43180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# green_green_topic_v5_risk_api = RiskInfer('./risk_data_tiny/config_topic_v5_risk_green_v1.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6fcf7d07-6172-4933-bd08-9bd5d8fd9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/data/albert.xht/xiaodao/risk_classification/tiny/multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_green_mtdnn_v18/multitask_cls.pth.13'\n",
    "\n",
    "green_risk_api.reload(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18dbb17e-e249-4e08-aa90-608443588e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_topic_path = '/data/albert.xht/xiaodao/risk_classification/tiny/topic_multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_green_mtdnn_v18/multitask_cls.pth.10'\n",
    "model_topic_path = '/data/albert.xht/xiaodao/risk_classification/tiny/topic_v4_teenager_v1_multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_green_mtdnn_v18/multitask_cls.pth.19'\n",
    "\n",
    "green_topic_risk_api.reload(model_topic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb65cb78-ec9b-4326-8883-a0ea0b205766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_topic_path = '/data/albert.xht/xiaodao/risk_classification/tiny/topic_v4_green_v1_teenager_v1_multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_green_mtdnn_v18/multitask_cls.pth.19'\n",
    "# model_topic_path = '/data/albert.xht/xiaodao/risk_classification/tiny/topic_v4_green_v1_teenager_v1_multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_green_mtdnn_v18/multitask_cls.pth.19'\n",
    "\n",
    "# model_topic_path = '/data/albert.xht/xiaodao/risk_classification/tiny/topic_v4_update_green_v1_teenager_v1_porn_multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_green_mtdnn_v18/multitask_cls.pth.19'\n",
    "# model_topic_path = '/data/albert.xht/xiaodao/risk_classification/tiny/topic_v4_update_green_v1_teenager_v1_porn_multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_green_mtdnn_v20/multitask_cls.pth.13'\n",
    "\n",
    "# model_topic_path = '/data/albert.xht/xiaodao/risk_classification/tiny/topic_v4_update_green_v1_teenager_v1_porn_multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_green_mtdnn_v21/multitask_cls.pth.19'\n",
    "\n",
    "model_topic_path = '/data/albert.xht/xiaodao/risk_classification/tiny/topic_v4_update_green_v1_teenager_v1_porn_multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_green_mtdnn_v22/multitask_cls.pth.19'\n",
    "\n",
    "# model_topic_path = '/data/albert.xht/xiaodao/risk_classification/topic_v4_update_green_v1_teenager_v1_porn_multitask_raw_filter_senti_query_risk_v13_intent_v2-1_10_no_symbol_senti_query_senta_green_mtdnn_v23/multitask_cls.pth.9'\n",
    "green_green_topic_risk_api.reload(model_topic_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7191d19b-0a31-4d26-a72b-f22ba1aaba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_topic_path = '/data/albert.xht/xiaodao/risk_classification/tiny/topic_v5_green_v1_teenager_v1_multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_green_mtdnn_v18/multitask_cls.pth.10'\n",
    "\n",
    "green_green_topic_v5_risk_api.reload(model_topic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc96785-ecbf-43fd-bf09-019126d6eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_topic_path = '/data/albert.xht/xiaodao/risk_classification/tiny/topic_v5_green_v1_teenager_v1_multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_green_mtdnn_v18_base/multitask_cls.pth.15'\n",
    "\n",
    "green_green_topic_v5_risk_base_api.reload(model_topic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60a1ec02-7de2-45d5-9b20-830438ef09ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def predict_fn(text, model):\n",
    "    if isinstance(item['text'], list):\n",
    "        text = \"\\n\".join(item['text'])\n",
    "    else:\n",
    "        text = item['text']\n",
    "    text = re.sub(r\"([，\\_《。》、？；：‘’＂“”【「】」·！@￥…（）—\\,\\<\\.\\>\\/\\?\\;\\:\\'\\\"\\[\\]\\{\\}\\~\\`\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\-\\=\\+])+\", \"\", text)   # 合并正文中过多的空格\n",
    "\n",
    "    result = model.predict(text)\n",
    "    score = sorted(result[key], key=lambda u:u[1], reverse=True)\n",
    "    return score[0]\n",
    "    \n",
    "\n",
    "def eval_all(data, model, key):\n",
    "    pred = []\n",
    "    gold = []\n",
    "    pred_score = []\n",
    "    for item in tqdm(data):\n",
    "        gold.append(item['label'][0])\n",
    "        if isinstance(item['text'], list):\n",
    "            text = \"\\n\".join(item['text'])\n",
    "        else:\n",
    "            text = item['text']\n",
    "        text = re.sub(r\"([，\\_《。》、？；：‘’＂“”【「】」·！@￥…（）—\\,\\<\\.\\>\\/\\?\\;\\:\\'\\\"\\[\\]\\{\\}\\~\\`\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\-\\=\\+])+\", \"\", text)   # 合并正文中过多的空格\n",
    "\n",
    "        result = model.predict(text)\n",
    "        score = sorted(result[key], key=lambda u:u[1], reverse=True)\n",
    "        pred.append(score[0][0])\n",
    "        pred_score.append(result[key])\n",
    "    print(classification_report(gold, pred, digits=4))\n",
    "    return pred, gold, pred_score\n",
    "    \n",
    "\n",
    "def evaluation_ece(pred_score, gold):\n",
    "    pred_score_l = []\n",
    "    mapping_dict = {}\n",
    "    for item in pred_score:\n",
    "        pred_score_l.append([])\n",
    "        for idx, p in enumerate(item):\n",
    "            if p[0] not in mapping_dict:\n",
    "                mapping_dict[p[0]] = idx\n",
    "            pred_score_l[-1].append(p[1])\n",
    "    pred_score_l = torch.tensor(pred_score_l)\n",
    "    gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "\n",
    "    ece_fn = ECE(n_bins=15)\n",
    "    print(ece_fn(pred_score_l, gold_l, mode='probs'), '==ece==')\n",
    "# pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "# evaluation_ece(pred_score, gold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eb1cacd-10c8-4399-aa1b-cc491b99e9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "99442it [19:54, 83.25it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_fn(text, model):\n",
    "    if isinstance(text, list):\n",
    "        text = \"\\n\".join(text)\n",
    "    else:\n",
    "        text = text\n",
    "    text = re.sub(r\"([，\\_《。》、？；：‘’＂“”【「】」·！@￥…（）—\\,\\<\\.\\>\\/\\?\\;\\:\\'\\\"\\[\\]\\{\\}\\~\\`\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\-\\=\\+])+\", \"\", text)   # 合并正文中过多的空格\n",
    "\n",
    "    result = model.predict(text)\n",
    "    return result\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re, time\n",
    "\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_real_toxicity_update/merge.txt.resp', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_real_toxicity_update/merge.txt', 'r') as frobj:\n",
    "        for line in tqdm(frobj):\n",
    "            content = json.loads(line.strip())\n",
    "            if 'text_translate' not in content['prompt']:\n",
    "                continue\n",
    "            if 'text_translate' not in content['continuation']:\n",
    "                continue\n",
    "            content['prompt']['risk'] = predict_fn(content['prompt']['text_translate'], green_green_topic_risk_api)\n",
    "            content['continuation']['risk'] = predict_fn(content['prompt']['text_translate']+content['continuation']['text_translate'], \n",
    "                                                         green_green_topic_risk_api)\n",
    "            fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a8ac8c-5bd1-43d3-a7d3-30d6184ac839",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = {\n",
    "    'prompt':[],\n",
    "    'continuation':[]\n",
    "}\n",
    "\n",
    "risk = {\n",
    "    'prompt':[],\n",
    "    'continuation':[]\n",
    "}\n",
    "\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_real_toxicity_update/merge.txt.resp', 'r') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        for key in ['prompt', 'continuation']:\n",
    "            flag = False\n",
    "            for label in ['sexually_explicit', 'flirtation', 'identity_attack', 'threat', 'insult',\n",
    "                       'severe_toxicity', 'toxicity', 'profanity']:\n",
    "                if content[key]['label'] > 0.6:\n",
    "                    flag = True\n",
    "            if flag:\n",
    "                gold[key].append(1)\n",
    "            else:\n",
    "                gold[key].append(0)\n",
    "            flag = False\n",
    "            for label in content[key]['risk']:\n",
    "                if label in ['topic', 'senti', 'senti_query', 'query_risk']:\n",
    "                    continue\n",
    "                if content[key][label][0] > 0.6:\n",
    "                    flag = True\n",
    "            if flag:\n",
    "                gold[key].append(1)\n",
    "            else:\n",
    "                gold[key].append(0)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9930d9d4-767d-403b-8128-ed4a602ed9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5304 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 5304/5304 [01:01<00:00, 86.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7418    0.8390    0.7874      2106\n",
      "          正常     0.8840    0.8077    0.8441      3198\n",
      "\n",
      "    accuracy                         0.8201      5304\n",
      "   macro avg     0.8129    0.8234    0.8158      5304\n",
      "weighted avg     0.8275    0.8201    0.8216      5304\n",
      "\n",
      "tensor([0.1579]) ==ece==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "offensive = []\n",
    "with open('/data/albert.xht/sentiment/test/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive.append(content)\n",
    "        \n",
    "# pred, gold, pred_score = eval_all(offensive, green_risk_api, 'offensive')\n",
    "pred, gold, pred_score = eval_all(offensive, green_green_topic_v5_risk_base_api, 'offensive')\n",
    "\n",
    "evaluation_ece(pred_score, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8223ae9f-9bbf-444b-9140-0b6cd8bb78fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007134437561035156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'topic': [['城市', 0.1534423828125],\n",
       "  ['社会', 0.07763671875],\n",
       "  ['博彩', 0.0726318359375],\n",
       "  ['交通出行', 0.0640869140625],\n",
       "  ['股票', 0.0638427734375]],\n",
       " 'senti_query': [['负向', 0.1453857421875],\n",
       "  ['中性', 0.7294921875],\n",
       "  ['正向', 0.1248779296875]],\n",
       " 'senti': [['负向', 0.444091796875], ['正向', 0.5556640625]],\n",
       " 'bias': [['偏见', 0.133056640625], ['正常', 0.86669921875]],\n",
       " 'ciron': [['讽刺', 0.325439453125], ['正常', 0.67431640625]],\n",
       " 'intent': [['主观评价/比较/判断', 0.0014944076538085938],\n",
       "  ['寻求建议/帮助', 0.0008478164672851562],\n",
       "  ['其它', 0.99755859375]],\n",
       " 'offensive': [['冒犯', 0.1903076171875], ['正常', 0.8095703125]],\n",
       " 'query_risk': [['风险', 0.712890625],\n",
       "  ['个人信息', 0.005039215087890625],\n",
       "  ['正常', 0.2822265625]],\n",
       " 'teenager': [['不良', 0.2044677734375], ['正常', 0.79541015625]],\n",
       " 'politics': [['涉政', 0.99462890625], ['正常', 0.005138397216796875]],\n",
       " 'porn': [['色情', 0.01248931884765625],\n",
       "  ['低俗', 0.1416015625],\n",
       "  ['色情违禁', 0.0006265640258789062],\n",
       "  ['正常', 0.84521484375]],\n",
       " 'abusive': [['辱骂', 0.00989532470703125],\n",
       "  ['口头语', 0.0196685791015625],\n",
       "  ['正常', 0.97021484375]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "allowed_schema_type = {\n",
    "    # 'topic':'',\n",
    "    # 'query_risk':'',\n",
    "    # 'porn':'',\n",
    "    # 'abusive':'',\n",
    "    # # 'offensive':'',\n",
    "    # 'intent':'',\n",
    "    # 'teenager':'',\n",
    "    # 'politics':''\n",
    "}\n",
    "allowed_schema_type = {}\n",
    "resp = green_green_topic_risk_api.predict('天安门', allowed_schema_type=allowed_schema_type)\n",
    "print(time.time()-start)\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2709bd55-6371-40ad-8541-0cf311574975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"inputs\": {\"utterance\": \"他爸爸是谁\", \"query_rewritten\": \"姚明爸爸是谁\", \"response\": \"姚明的父亲是姚志源\", \"detect_mode\": \"strict\"}}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict = {\"inputs\":\n",
    "{\n",
    "  \"utterance\": \"他爸爸是谁\",\n",
    "   \"query_rewritten\": \"姚明爸爸是谁\",\n",
    "   \"response\": \"姚明的父亲是姚志源\",\n",
    "   \"detect_mode\": \"strict\"\n",
    "}}\n",
    "\n",
    "json.dumps(input_dict, ensure_ascii=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbdfd628-5001-48b8-b016-de8c2cc06757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " '{\"safety_value\": \"safe\", \"response\": \"习近平的爸爸\", \"algo_result\": '\n",
      " '{\"algo_version\": \"v_20230201\", \"result_details\": [{\"topic\": [\"时事政治: '\n",
      " '0.5701584815979004\", \"教育/科学: 0.0786704272031784\"], \"senti_query\": \"正向: '\n",
      " '0.9916815161705017\", \"senti\": \"正向: 0.9883805513381958\", \"bias\": \"正常: '\n",
      " '0.9747865796089172\", \"ciron\": \"正常: 0.8475391864776611\", \"intent\": \"其它: '\n",
      " '0.9999520778656006\", \"offensive\": \"正常: 0.951887309551239\", \"query_risk\": '\n",
      " '\"正常: 0.792395293712616\", \"teenager\": \"正常: 0.9767218828201294\", \"politics\": '\n",
      " '\"涉政: 0.9111408591270447\", \"porn\": \"正常: 0.5156128406524658\", \"abusive\": \"正常: '\n",
      " '0.9579949378967285\", \"text\": \"姚明爸爸习近平的爸爸是谁\", \"vote_result\": {\"topic & '\n",
      " 'intent\": 1.0}}, {\"topic\": [\"时事政治: 0.4016653895378113\", \"社会: '\n",
      " '0.1217777281999588\"], \"senti_query\": \"正向: 0.9440419673919678\", \"senti\": \"正向: '\n",
      " '0.9897205233573914\", \"bias\": \"正常: 0.9701516032218933\", \"ciron\": \"正常: '\n",
      " '0.7880784273147583\", \"intent\": \"其它: 0.9996641874313354\", \"offensive\": \"正常: '\n",
      " '0.928941547870636\", \"query_risk\": \"风险: 0.549170732498169\", \"teenager\": \"正常: '\n",
      " '0.9699081778526306\", \"politics\": \"涉政: 0.995159924030304\", \"porn\": \"正常: '\n",
      " '0.8542316555976868\", \"abusive\": \"正常: 0.8744667172431946\", \"text\": \"习近平的爸爸\", '\n",
      " '\"vote_result\": []}]}, \"success\": true, \"ext_msg\": \"\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\"\n",
    "{\"safety_value\": \"safe\", \"response\": \"\\u4e60\\u8fd1\\u5e73\\u7684\\u7238\\u7238\", \"algo_result\": {\"algo_version\": \"v_20230201\", \"result_details\": [{\"topic\": [\"\\u65f6\\u4e8b\\u653f\\u6cbb: 0.5701584815979004\", \"\\u6559\\u80b2/\\u79d1\\u5b66: 0.0786704272031784\"], \"senti_query\": \"\\u6b63\\u5411: 0.9916815161705017\", \"senti\": \"\\u6b63\\u5411: 0.9883805513381958\", \"bias\": \"\\u6b63\\u5e38: 0.9747865796089172\", \"ciron\": \"\\u6b63\\u5e38: 0.8475391864776611\", \"intent\": \"\\u5176\\u5b83: 0.9999520778656006\", \"offensive\": \"\\u6b63\\u5e38: 0.951887309551239\", \"query_risk\": \"\\u6b63\\u5e38: 0.792395293712616\", \"teenager\": \"\\u6b63\\u5e38: 0.9767218828201294\", \"politics\": \"\\u6d89\\u653f: 0.9111408591270447\", \"porn\": \"\\u6b63\\u5e38: 0.5156128406524658\", \"abusive\": \"\\u6b63\\u5e38: 0.9579949378967285\", \"text\": \"\\u59da\\u660e\\u7238\\u7238\\u4e60\\u8fd1\\u5e73\\u7684\\u7238\\u7238\\u662f\\u8c01\", \"vote_result\": {\"topic & intent\": 1.0}}, {\"topic\": [\"\\u65f6\\u4e8b\\u653f\\u6cbb: 0.4016653895378113\", \"\\u793e\\u4f1a: 0.1217777281999588\"], \"senti_query\": \"\\u6b63\\u5411: 0.9440419673919678\", \"senti\": \"\\u6b63\\u5411: 0.9897205233573914\", \"bias\": \"\\u6b63\\u5e38: 0.9701516032218933\", \"ciron\": \"\\u6b63\\u5e38: 0.7880784273147583\", \"intent\": \"\\u5176\\u5b83: 0.9996641874313354\", \"offensive\": \"\\u6b63\\u5e38: 0.928941547870636\", \"query_risk\": \"\\u98ce\\u9669: 0.549170732498169\", \"teenager\": \"\\u6b63\\u5e38: 0.9699081778526306\", \"politics\": \"\\u6d89\\u653f: 0.995159924030304\", \"porn\": \"\\u6b63\\u5e38: 0.8542316555976868\", \"abusive\": \"\\u6b63\\u5e38: 0.8744667172431946\", \"text\": \"\\u4e60\\u8fd1\\u5e73\\u7684\\u7238\\u7238\", \"vote_result\": []}]}, \"success\": true, \"ext_msg\": \"\"}\n",
    "\"\"\"\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cae1888-4d99-48ca-9cb9-2156ded0162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl com.taobao.search.cro.gen.security:25530 -d '{\"inputs\": {\"utterance\": \"习近平的爸爸\", \"query_rewritten\": \"姚明爸爸习近平的爸爸是谁\", \"response\": \"习近平的爸爸\", \"detect_mode\": \"strict\"}}'  | jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2285cd11-e530-42f9-bdcb-6be603ec3c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"utterance\": \"他爸爸是谁\", \"query_rewritten\": \"姚明爸爸是谁\", \"response\": \"姚明的父亲是姚志源\", \"detect_mode\": \"strict\"}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "d =   {\n",
    "    \"utterance\": \"他爸爸是谁\",\n",
    "     \"query_rewritten\": \"姚明爸爸是谁\",\n",
    "     \"response\": \"姚明的父亲是姚志源\",\n",
    "     \"detect_mode\": \"strict\"\n",
    "  }\n",
    "json.dumps(d, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7c58325-6895-4524-8492-8da68f7304af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "data_dict = {}\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_single/merge.json.harmless') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        query = content['human_translate']\n",
    "        resp = green_green_topic_risk_api.predict(query, allowed_schema_type={})\n",
    "        content['query_risk'] = resp\n",
    "        if query not in data_dict:\n",
    "            data_dict[query] = content\n",
    "        # data_list.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b678fd1-bd1c-4e07-9fac-85a87937903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_single/merge.json.harmless.query', 'w') as fwobj:\n",
    "    for key in data_dict:\n",
    "        if data_dict[key]['query_risk']['query_risk'][0][1] > 0.6:\n",
    "            label = '风险'\n",
    "        else:\n",
    "            label = '正常'\n",
    "        fwobj.write(key+'&&'+label+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2af11b3d-2c96-47e8-93fd-7225a9df4f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         0\n",
      "           1     1.0000    0.2821    0.4401     12210\n",
      "\n",
      "    accuracy                         0.2821     12210\n",
      "   macro avg     0.5000    0.1411    0.2201     12210\n",
      "weighted avg     1.0000    0.2821    0.4401     12210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "gold = []\n",
    "pred = []\n",
    "\n",
    "for key in data_dict:\n",
    "    gold.append(1)\n",
    "    if data_dict[key]['query_risk']['query_risk'][0][1] > 0.6:\n",
    "        pred.append(1)\n",
    "    else:\n",
    "        pred.append(0)\n",
    "\n",
    "print(classification_report(gold, pred, digits=4))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f28ad4f-580d-4c5e-940a-2ed059279d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm im\n",
    "t = Counter()\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.topic.knn.final.update', 'r') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        if '德州扑克' in content['text']:\n",
    "            t[content['label'][0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da5e867e-37bb-49b0-92b6-6786699ac677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'道德伦理': 1,\n",
       "         '创业投资': 2,\n",
       "         '教育/科学': 12,\n",
       "         '人际交往': 1,\n",
       "         '游戏': 9,\n",
       "         '股票': 2,\n",
       "         '职场职业': 1,\n",
       "         '体育/运动': 2,\n",
       "         '影视': 1,\n",
       "         '女性': 1,\n",
       "         '电脑/网络': 4,\n",
       "         '阅读': 2,\n",
       "         '期货': 1,\n",
       "         '情感': 1,\n",
       "         '恋爱': 1})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1be9b8c6-7907-49cc-b648-70c97f8d7f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.398576512455516"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "112/(112+169)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d14d3f4-b997-42a6-95ae-8d2130136534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20641/20641 [02:00<00:00, 171.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.6942    0.7164    0.7051      5514\n",
      "          风险     0.8954    0.8850    0.8902     15127\n",
      "\n",
      "    accuracy                         0.8399     20641\n",
      "   macro avg     0.7948    0.8007    0.7976     20641\n",
      "weighted avg     0.8416    0.8399    0.8407     20641\n",
      "\n",
      "tensor([0.0473]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "risk_query = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/offensive_select_labeled.txt.paraphrase') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        # for d in content['paraphrase']:\n",
    "        #     p = {\n",
    "        #         'text':d[0],\n",
    "        #         'label':content['label']\n",
    "        #     }\n",
    "        #     if d:\n",
    "        #         risk_query.append(p)\n",
    "        risk_query.append(json.loads(line.strip()))\n",
    "pred, gold, pred_score = eval_all(risk_query, green_topic_risk_api, 'query_risk')\n",
    "evaluation_ece(pred_score, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76d2eed5-ad3a-450b-9f81-30bfa7ba86d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5128 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 5128/5128 [00:31<00:00, 163.20it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/itag_labl_data_deal_20230112.xlsx')\n",
    "gold, pred = [], []\n",
    "result_list = []\n",
    "data_dict = {}\n",
    "for idx in tqdm(range(df.shape[0])):\n",
    "    content = df.loc[idx]\n",
    "    \n",
    "    score_list = green_green_topic_risk_api.predict(content['query'])\n",
    "    if content['query'] not in data_dict:\n",
    "        data_dict[content['query']] = ''\n",
    "    else:\n",
    "        continue\n",
    "    if content['human_risk'] in [-1]:\n",
    "        continue\n",
    "    result_list.append((content, score_list))\n",
    "    if score_list['query_risk'][0][1] > 0.5 :\n",
    "        pred.append(1)\n",
    "    else:\n",
    "        pred.append(0)\n",
    "    \n",
    "    gold.append(int(content['human_risk']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7ba21c9-30ee-4930-bc43-1f51a8a2e5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9832    0.9203    0.9507      4378\n",
      "           1     0.6087    0.8873    0.7221       612\n",
      "\n",
      "    accuracy                         0.9162      4990\n",
      "   macro avg     0.7960    0.9038    0.8364      4990\n",
      "weighted avg     0.9372    0.9162    0.9226      4990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(gold, pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43cea07f-4258-4b66-ad5f-0f6097b5d1ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_96362/3844218040.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(gold, pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7543799-6146-438a-a2bb-bfae21f7affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "offensive = []\n",
    "with open('/data/albert.xht/sentiment/dev/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive.append(content)\n",
    "        \n",
    "offensive_test = []\n",
    "with open('/data/albert.xht/sentiment/test/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive_test.append(content)\n",
    "\n",
    "        \n",
    "cdia_bias = []\n",
    "with open('/data/albert.xht/sentiment/dev/cdial_bias.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        cdia_bias.append(content)\n",
    "        \n",
    "senti_copr = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_copr.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_copr.append(content)\n",
    "        \n",
    "ciron = []\n",
    "with open('/data/albert.xht/sentiment/dev/chinese_ciron.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        ciron.append(content)\n",
    "\n",
    "senti_smp = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smp_usual.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smp.append(content)\n",
    "        \n",
    "senti_smpecisa = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smpecisa.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smpecisa.append(content)\n",
    "\n",
    "        \n",
    "senti_query = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_valid.json.filter.0.7') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_query.append(content)\n",
    "\n",
    "def evaluation(risk_api, model_path):\n",
    "    risk_api.reload(model_path)\n",
    "    print('===offensive===')\n",
    "    pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===cdia-bias===')\n",
    "    pred, gold, pred_score = eval_all(cdia_bias, risk_api, 'bias')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===ciron===')\n",
    "    pred, gold, pred_score = eval_all(ciron, risk_api, 'ciron')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===chsenti===')\n",
    "    pred, gold, pred_score = eval_all(senti_copr, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smpecisa===')\n",
    "    pred, gold, pred_score = eval_all(senti_smpecisa, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smp===')\n",
    "    pred, gold, pred_score = eval_all(senti_smp, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_query===')\n",
    "    pred, gold, pred_score = eval_all(senti_query, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c736746-1759-40fc-9134-bade35010db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你怎么挪钱？\n",
      "1.1863462924957275\n"
     ]
    }
   ],
   "source": [
    "import translators as ts\n",
    "import translators.server as tss\n",
    "\n",
    "wyw_text = 'How do you embezzle money?'\n",
    "import time\n",
    "start = time.time()\n",
    "print(tss.bing(wyw_text, professional_field='common', from_language='en', to_language='zh'))\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5af08a12-4ae6-4321-82fe-6fd963391505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation(green_risk_api,\n",
    "#            '/data/albert.xht/xiaodao/risk_classification/tiny/multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_green_mtdnn_v18/multitask_cls.pth.13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58deaa0c-6b9e-4def-b5a0-0d5e208d9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_topic_path = '/data/albert.xht/xiaodao/risk_classification/tiny/topic_v4_teenager_v1_multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_green_mtdnn_v18/multitask_cls.pth.19'\n",
    "\n",
    "# evaluation(green_topic_risk_api,model_topic_path\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e391095-3735-41dc-829b-28fb008d60a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': [['宗教', 0.7294921875],\n",
       "  ['心理健康', 0.028839111328125],\n",
       "  ['文化/艺术', 0.0240478515625],\n",
       "  ['历史', 0.0200958251953125],\n",
       "  ['社会', 0.01422119140625]],\n",
       " 'senti_query': [['负向', 0.970703125],\n",
       "  ['中性', 0.0277557373046875],\n",
       "  ['正向', 0.0014486312866210938]],\n",
       " 'senti': [['负向', 0.98974609375], ['正向', 0.01019287109375]],\n",
       " 'bias': [['偏见', 0.184326171875], ['正常', 0.8154296875]],\n",
       " 'ciron': [['讽刺', 0.359619140625], ['正常', 0.640625]],\n",
       " 'intent': [['主观评价/比较/判断', 0.865234375],\n",
       "  ['寻求建议/帮助', 0.0011014938354492188],\n",
       "  ['其它', 0.1336669921875]],\n",
       " 'offensive': [['冒犯', 0.9443359375], ['正常', 0.05560302734375]],\n",
       " 'query_risk': [['风险', 0.99267578125],\n",
       "  ['个人信息', 1.1563301086425781e-05],\n",
       "  ['正常', 0.00717926025390625]],\n",
       " 'teenager': [['不良', 0.74658203125], ['正常', 0.25341796875]],\n",
       " 'politics': [['涉政', 0.7822265625], ['正常', 0.217529296875]],\n",
       " 'porn': [['色情', 0.00012981891632080078],\n",
       "  ['低俗', 0.01152801513671875],\n",
       "  ['色情违禁', 2.9981136322021484e-05],\n",
       "  ['正常', 0.98828125]],\n",
       " 'abusive': [['辱骂', 0.50048828125],\n",
       "  ['口头语', 0.03680419921875],\n",
       "  ['正常', 0.462646484375]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_green_topic_risk_api.predict('基督教都是傻子')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "96bbabc2-e526-4fdd-b56d-bd1067dd2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "v5_valid = []\n",
    "v5_text = []\n",
    "v5_label = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v5/biake_qa_web_text_zh_valid.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        v5_valid.append(content)\n",
    "        v5_text.append(content['text'])\n",
    "        # v5_label.append(topic_api.label2id[content['label'][0]])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "def eval_all(data, model, top_n=5):\n",
    "    pred = []\n",
    "    gold = []\n",
    "    pred_score = []\n",
    "    pred = 0\n",
    "    queue = []\n",
    "    tt = []\n",
    "    total_pred = []\n",
    "    for item in tqdm(data):\n",
    "        gold.append(item['label'][0])\n",
    "        if isinstance(item['text'], list):\n",
    "            text = \"\\n\".join(item['text'])\n",
    "        else:\n",
    "            text = item['text']\n",
    "        queue.append(text)\n",
    "        tt.append(item)\n",
    "        if np.mod(len(queue), 128) == 0:\n",
    "            result_list = model.predict_batch(queue)\n",
    "            for result, text, t in zip(result_list, queue, tt):\n",
    "                score = sorted(result['topic'], key=lambda u:u[1], reverse=True)\n",
    "                pred_set = set([p[0] for p in score[:top_n]])\n",
    "                total_pred.append(score[0][0])\n",
    "                if set(t['label']) & pred_set:\n",
    "                    pred += 1\n",
    "                pred_score.append(result)\n",
    "            queue = []\n",
    "            tt = []\n",
    "    if queue:\n",
    "        result_list = model.predict_batch(queue)\n",
    "        for result, text, t in zip(result_list, queue, tt):\n",
    "            score = sorted(result['topic'], key=lambda u:u[1], reverse=True)\n",
    "            pred_set = set([p[0] for p in score[:top_n]])\n",
    "            total_pred.append(score[0][0])\n",
    "            if set(t['label']) & pred_set:\n",
    "                pred += 1\n",
    "            pred_score.append(result)\n",
    "        # break\n",
    "    print(classification_report(gold, total_pred, digits=4), '===', top_n)\n",
    "    print(pred/len(pred_score))\n",
    "    return pred_score, total_pred, gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34d2379-ee90-4935-8521-9463c657eea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
