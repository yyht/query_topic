{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c24b51-0baf-4855-baac-3ee4010c944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys,os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ff23bc-1588-42e5-959e-a45d4b3d7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.extend(['/root/xiaoda/query_topic/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25da71ce-1bec-4327-acd7-c3dd78414f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "https://github.com/ondrejbohdal/meta-calibration/blob/main/Metrics/metrics.py\n",
    "\"\"\"\n",
    "\n",
    "class ECE(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(ECE, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels, mode='logits'):\n",
    "        if mode == 'logits':\n",
    "            softmaxes = F.softmax(logits, dim=1)\n",
    "        else:\n",
    "            softmaxes = logits\n",
    "        # softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        \n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cbfd143-9337-4fea-aad8-cf2851192471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senti_query /root/xiaoda/query_topic/risk_data_v5/senti_query_label.txt ===schema-path===\n",
      "{'label2id': {'负向': 0, '中性': 1, '正向': 2}, 'id2label': {0: '负向', 1: '中性', 2: '正向'}, 'label_index': 0} ==schema_type== senti_query\n",
      "senti /root/xiaoda/query_topic/risk_data_v5/senti_label.txt ===schema-path===\n",
      "{'label2id': {'负向': 0, '正向': 1}, 'id2label': {0: '负向', 1: '正向'}, 'label_index': 1} ==schema_type== senti\n",
      "bias /root/xiaoda/query_topic/risk_data_v5/bias_label.txt ===schema-path===\n",
      "{'label2id': {'偏见': 0, '正常': 1}, 'id2label': {0: '偏见', 1: '正常'}, 'label_index': 2} ==schema_type== bias\n",
      "ciron /root/xiaoda/query_topic/risk_data_v5/ciron_label.txt ===schema-path===\n",
      "{'label2id': {'讽刺': 0, '正常': 1}, 'id2label': {0: '讽刺', 1: '正常'}, 'label_index': 3} ==schema_type== ciron\n",
      "intent /root/xiaoda/query_topic/risk_data_v5/intention_label_v0.txt ===schema-path===\n",
      "{'label2id': {'主观评价/比较/判断': 0, '寻求建议/帮助': 1, '其它': 2}, 'id2label': {0: '主观评价/比较/判断', 1: '寻求建议/帮助', 2: '其它'}, 'label_index': 4} ==schema_type== intent\n",
      "offensive /root/xiaoda/query_topic/risk_data_v5/offensive_label.txt ===schema-path===\n",
      "{'label2id': {'冒犯': 0, '正常': 1}, 'id2label': {0: '冒犯', 1: '正常'}, 'label_index': 5} ==schema_type== offensive\n",
      "query_risk /root/xiaoda/query_topic/risk_data_v5/query_risk_label.txt ===schema-path===\n",
      "{'label2id': {'风险': 0, '个人信息': 1, '正常': 2}, 'id2label': {0: '风险', 1: '个人信息', 2: '正常'}, 'label_index': 6} ==schema_type== query_risk\n",
      "teenager /root/xiaoda/query_topic/risk_data_v5/teenager_label.txt ===schema-path===\n",
      "{'label2id': {'不良': 0, '正常': 1}, 'id2label': {0: '不良', 1: '正常'}, 'label_index': 7} ==schema_type== teenager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizerFast\n",
    "import transformers\n",
    "from datetime import timedelta\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from nets.them_classifier import MyBaseModel, RobertaClassifier\n",
    "\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "\n",
    "cur_dir_path = '/root/xiaoda/query_topic/'\n",
    "\n",
    "def load_label(filepath):\n",
    "    label_list = []\n",
    "    with open(filepath, 'r') as frobj:\n",
    "        for line in frobj:\n",
    "            label_list.append(line.strip())\n",
    "        n_classes = len(label_list)\n",
    "\n",
    "        label2id = {}\n",
    "        id2label = {}\n",
    "        for idx, label in enumerate(label_list):\n",
    "            label2id[label] = idx\n",
    "            id2label[idx] = label\n",
    "        return label2id, id2label\n",
    "\n",
    "class RiskInfer(object):\n",
    "    def __init__(self, config_path):\n",
    "\n",
    "        import torch, os, sys\n",
    "\n",
    "        con = configparser.ConfigParser()\n",
    "        con_path = os.path.join(cur_dir_path, config_path)\n",
    "        con.read(con_path, encoding='utf8')\n",
    "\n",
    "        args_path = dict(dict(con.items('paths')), **dict(con.items(\"para\")))\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(args_path[\"model_path\"], do_lower_case=True)\n",
    "\n",
    "        from collections import OrderedDict\n",
    "        self.schema_dict = OrderedDict({})\n",
    "\n",
    "        for label_index, schema_info in enumerate(args_path[\"label_path\"].split(',')):\n",
    "            schema_type, schema_path = schema_info.split(':')\n",
    "            schema_path = os.path.join(cur_dir_path, schema_path)\n",
    "            print(schema_type, schema_path, '===schema-path===')\n",
    "            label2id, id2label = load_label(schema_path)\n",
    "            self.schema_dict[schema_type] = {\n",
    "                'label2id':label2id,\n",
    "                'id2label':id2label,\n",
    "                'label_index':label_index\n",
    "            }\n",
    "            print(self.schema_dict[schema_type], '==schema_type==', schema_type)\n",
    "        \n",
    "        output_path = os.path.join(cur_dir_path, args_path['output_path'])\n",
    "\n",
    "        from roformer import RoFormerModel, RoFormerConfig\n",
    "\n",
    "        config = RoFormerConfig.from_pretrained(args_path[\"model_path\"])\n",
    "        encoder = RoFormerModel(config=config)\n",
    "        \n",
    "        encoder_net = MyBaseModel(encoder, config)\n",
    "\n",
    "        self.device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        classifier_list = []\n",
    "\n",
    "        schema_list = list(self.schema_dict.keys())\n",
    "\n",
    "        for schema_key in schema_list:\n",
    "            classifier = RobertaClassifier(\n",
    "                hidden_size=config.hidden_size, \n",
    "                dropout_prob=con.getfloat('para', 'out_dropout_rate'),\n",
    "                num_labels=len(self.schema_dict[schema_key]['label2id']), \n",
    "                dropout_type=con.get('para', 'dropout_type'))\n",
    "            classifier_list.append(classifier)\n",
    "\n",
    "        classifier_list = nn.ModuleList(classifier_list)\n",
    "\n",
    "        class MultitaskClassifier(nn.Module):\n",
    "            def __init__(self, transformer, classifier_list):\n",
    "                super().__init__()\n",
    "\n",
    "                self.transformer = transformer\n",
    "                self.classifier_list = classifier_list\n",
    "\n",
    "            def forward(self, input_ids, input_mask, \n",
    "                        segment_ids=None, \n",
    "                        transformer_mode='mean_pooling', \n",
    "                        dt_idx=None):\n",
    "                hidden_states = self.transformer(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              return_mode=transformer_mode)\n",
    "                outputs_list = []\n",
    "                \n",
    "                for idx, classifier in enumerate(self.classifier_list):\n",
    "                    \n",
    "                    if dt_idx is not None and idx != dt_idx:\n",
    "                        continue\n",
    "                    \n",
    "                    ce_logits = classifier(hidden_states)\n",
    "                    outputs_list.append(ce_logits)\n",
    "                return outputs_list, hidden_states\n",
    "\n",
    "        self.net = MultitaskClassifier(encoder_net, classifier_list).to(self.device)\n",
    "\n",
    "        # eo = 9\n",
    "        # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw.focal'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_contrast_cls.pth.{}'.format(eo)), map_location=self.device)\n",
    "        # self.net.load_state_dict(ckpt)\n",
    "        # self.net.eval()\n",
    "        \n",
    "    def reload(self, model_path):\n",
    "        ckpt = torch.load(model_path, map_location=self.device)\n",
    "        self.net.load_state_dict(ckpt)\n",
    "        self.net.eval()\n",
    "\n",
    "    def predict(self, text):\n",
    "\n",
    "        \"\"\"抽取输入text所包含的类型\n",
    "        \"\"\"\n",
    "        encoder_txt = self.tokenizer.encode_plus(text, max_length=256)\n",
    "        input_ids = torch.tensor(encoder_txt[\"input_ids\"]).long().unsqueeze(0).to(self.device)\n",
    "        token_type_ids = torch.tensor(encoder_txt[\"token_type_ids\"]).unsqueeze(0).to(self.device)\n",
    "        attention_mask = torch.tensor(encoder_txt[\"attention_mask\"]).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        scores_dict = {}\n",
    "        with torch.no_grad():\n",
    "            [logits_list, \n",
    "            hidden_states] = self.net(input_ids, \n",
    "                attention_mask, token_type_ids, transformer_mode='cls')\n",
    "        for schema_type, logits in zip(list(self.schema_dict.keys()), logits_list):\n",
    "            scores = torch.nn.Softmax(dim=1)(logits)[0].data.cpu().numpy()\n",
    "            scores_dict[schema_type] = []\n",
    "            for index, score in enumerate(scores):\n",
    "                scores_dict[schema_type].append([self.schema_dict[schema_type]['id2label'][index], \n",
    "                                        float(score)])\n",
    "        return scores_dict\n",
    "    \n",
    "    def get_logitnorm(self, text):\n",
    "        \"\"\"抽取输入text所包含的类型\n",
    "        \"\"\"\n",
    "        encoder_txt = self.tokenizer.encode_plus(text, max_length=256)\n",
    "        input_ids = torch.tensor(encoder_txt[\"input_ids\"]).long().unsqueeze(0).to(self.device)\n",
    "        token_type_ids = torch.tensor(encoder_txt[\"token_type_ids\"]).unsqueeze(0).to(self.device)\n",
    "        attention_mask = torch.tensor(encoder_txt[\"attention_mask\"]).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        scores_dict = {}\n",
    "        logits_norm_list = []\n",
    "        with torch.no_grad():\n",
    "            [logits_list, \n",
    "            hidden_states] = self.net(input_ids, \n",
    "                attention_mask, token_type_ids, transformer_mode='cls')\n",
    "            for logits in logits_list:\n",
    "                logits_norm_list.append(logits/torch.norm(logits, p=2, dim=-1, keepdim=True) + 1e-7)\n",
    "        for schema_type, logit_norm in zip(list(self.schema_dict.keys()), logits_norm_list):\n",
    "            scores_dict[schema_type] = logit_norm[0].data.cpu().numpy()\n",
    "        return scores_dict\n",
    "            \n",
    "    \n",
    "    def predict_batch(self, text):\n",
    "        if isinstance(text, list):\n",
    "            text_list = text\n",
    "        else:\n",
    "            text_list = [text]\n",
    "        model_input = self.tokenizer(text_list, return_tensors=\"pt\",padding=True)\n",
    "        for key in model_input:\n",
    "            model_input[key] = model_input[key].to(self.device)\n",
    "        with torch.no_grad():\n",
    "            [logits_list, \n",
    "            hidden_states] = self.net(model_input['input_ids'], \n",
    "                model_input['attention_mask'], \n",
    "                model_input['token_type_ids'], transformer_mode='cls')\n",
    "        score_dict_list = []\n",
    "        for idx, text in enumerate(text_list):\n",
    "            scores_dict = {}\n",
    "            for schema_type, logits in zip(list(self.schema_dict.keys()), logits_list):\n",
    "                scores = torch.nn.Softmax(dim=1)(logits)[idx].data.cpu().numpy()\n",
    "                scores_dict[schema_type] = []\n",
    "                for index, score in enumerate(scores):\n",
    "                    scores_dict[schema_type].append([self.schema_dict[schema_type]['id2label'][index], \n",
    "                                            float(score)])\n",
    "            score_dict_list.append(scores_dict)\n",
    "        return score_dict_list\n",
    "\n",
    "# risk_api = RiskInfer('./risk_data/config.ini')\n",
    "risk_api = RiskInfer('./risk_data_v5/config.ini')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fad1e25-e3e7-4440-a3b9-4fb290a3a8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9965"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "l = 0\n",
    "reader = csv.reader(open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/Query风险分类_全部数据.csv'), delimiter=\"\\t\", quotechar=None)\n",
    "for idx, item in enumerate(reader):\n",
    "    # print(item)\n",
    "    l += 1\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf80f7-c2d9-4bda-80e6-c2c95245d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/albert.xht/pretrained_model_risk/corpus/efaqa-corpus-zh/efaqa-corpus-zh.utf8\", \"r\") as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        title = ''.join(re.split('[\\s,]', content['title'])[1:])\n",
    "        if len(title) >= 5:\n",
    "            if  s3_mapping[content['label']['s3']] in ['正在进行的自杀行为', '策划进行的自杀行为', '自残']:\n",
    "                tmp = {\n",
    "                    'title':title,\n",
    "                    'label':['风险']\n",
    "                }\n",
    "                print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb6923a2-fe55-4610-bf75-36fe3a90dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v5_intent_v2_3/multitask_cls.pth.4')\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v5_intent_v2-1_3//multitask_cls.pth.4')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v6_intent_v2-1_10/multitask_cls.pth.6')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v6_intent_v2-1_10_no_symbol/multitask_cls.pth.5')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/risk_classification/multitask_raw_filter_senti_query_risk_v7_intent_v2-1_10_no_symbol/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v8_intent_v2-1_10_no_symbol/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v8_intent_v2-1_10_no_symbol_v1/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v9_intent_v2-1_10_no_symbol_v1/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v10_intent_v2-1_10_no_symbol_senti_query_senta_balanced_logitclip/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v10_intent_v2-1_10_no_symbol_senti_query_senta_balanced_logitclip_v1/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v11_intent_v2-1_10_no_symbol_senti_query_senta_balanced_v1/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_balanced_v1/multitask_cls.pth.8')\n",
    "\n",
    "risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_balanced_v2/multitask_cls.pth.5')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v6_no_offensive_intent_v2-1_10//multitask_cls.pth.6')\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v5_no_offensive_intent_v2-1_3/multitask_cls.pth.4')\n",
    "\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d055c9c7-e1ca-4e2e-89dd-c1a6f193da4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'senti_query': [['负向', 0.00832600798457861],\n",
       "  ['中性', 0.6789711713790894],\n",
       "  ['正向', 0.31270286440849304]],\n",
       " 'senti': [['负向', 0.7019690871238708], ['正向', 0.29803088307380676]],\n",
       " 'bias': [['偏见', 0.045200686901807785], ['正常', 0.9547992944717407]],\n",
       " 'ciron': [['讽刺', 0.48146119713783264], ['正常', 0.518538773059845]],\n",
       " 'intent': [['主观评价/比较/判断', 2.1881326119910227e-06],\n",
       "  ['寻求建议/帮助', 8.18282387626823e-06],\n",
       "  ['其它', 0.9999896287918091]],\n",
       " 'offensive': [['冒犯', 0.023488081991672516], ['正常', 0.9765118360519409]],\n",
       " 'query_risk': [['风险', 0.010151089169085026],\n",
       "  ['个人信息', 0.00015539505693595856],\n",
       "  ['正常', 0.9896935820579529]],\n",
       " 'teenager': [['不良', 0.02531786449253559], ['正常', 0.9746821522712708]]}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_api.predict('AAB的成语有哪些')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a016e9d-7b74-40e4-b7e9-159a2be0a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_inference(input_path, output_path):\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "    import json, re\n",
    "\n",
    "    def risk_predict_batch(text):\n",
    "        if isinstance(text, list):\n",
    "            text_list = text\n",
    "        else:\n",
    "            text_list = [text]\n",
    "        result_list = risk_api.predict_batch(text_list)\n",
    "        return result_list\n",
    "    \n",
    "    print(input_path, '===input-path===')\n",
    "    print(output_path, '===output-path===')\n",
    "    \n",
    "    with open(output_path, 'w') as fwobj:\n",
    "        with open(input_path, 'r') as frobj:\n",
    "            queue = []\n",
    "            t = []\n",
    "            for line in tqdm(frobj):\n",
    "                content = json.loads(line.strip())\n",
    "                content['text'] = re.sub('请问', '', content['text'])\n",
    "                text = re.sub(r\"([，\\_《。》、？；：‘’＂“”【「】」·！@￥…（）—\\,\\<\\.\\>\\/\\?\\;\\:\\'\\\"\\[\\]\\{\\}\\~\\`\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\-\\=\\+])+\", \"\", content['text'])   # 合并正文中过多的空格\n",
    "                queue.append(text)\n",
    "                t.append(content)\n",
    "                if np.mod(len(queue), 128) == 0:\n",
    "                    probs = risk_predict_batch(queue)\n",
    "                    for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                        content = {\n",
    "                            'text':tt['text'],\n",
    "                            'topic':tt['label'],\n",
    "                            'score_list':prob_dict,\n",
    "                            # 'score_list': tt['score_list']\n",
    "                        }\n",
    "                        fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                    queue = []\n",
    "                    t = []\n",
    "            if queue:\n",
    "                probs = risk_predict_batch(queue)\n",
    "                for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                    content = {\n",
    "                        'text':tt['text'],\n",
    "                        'topic':tt['label'],\n",
    "                        'score_list':prob_dict,\n",
    "                        # 'score_list': tt['score_list']\n",
    "                    }\n",
    "                    fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0811b54-62f5-4990-a06b-13d041acf824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [00:00, 1057.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/albert.xht/xiaodao/topic_classification_v7/biake_qa_web_text_zh_train.json.positive.topic ===input-path===\n",
      "/data/albert.xht/xiaodao/topic_classification_v7/biake_qa_web_text_zh_train.json.positive.topic.v10 ===output-path===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25507it [00:23, 1074.57it/s]\n"
     ]
    }
   ],
   "source": [
    "input_path = '/data/albert.xht/xiaodao/topic_classification_v7/biake_qa_web_text_zh_train.json.positive.topic'\n",
    "output_path = '/data/albert.xht/xiaodao/topic_classification_v7/biake_qa_web_text_zh_train.json.positive.topic.v10'\n",
    "\n",
    "\n",
    "batch_inference(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e1f1486-5ed6-4dbd-bc85-8b4f2c3076f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [00:00, 1055.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/albert.xht/raw_chat_corpus/topic_classification_v4/embed_linear_small_white.json.topic ===input-path===\n",
      "/data/albert.xht/raw_chat_corpus/topic_classification_v4/embed_linear_small_white.json.topic.v10 ===output-path===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23116it [00:21, 1058.94it/s]\n"
     ]
    }
   ],
   "source": [
    "input_path = '/data/albert.xht/raw_chat_corpus/topic_classification_v4/embed_linear_small_white.json.topic'\n",
    "output_path = '/data/albert.xht/raw_chat_corpus/topic_classification_v4/embed_linear_small_white.json.topic.v10'\n",
    "\n",
    "\n",
    "batch_inference(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d6428-d95b-4353-9461-5220d76d5367",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.topic.knn.final'\n",
    "output_path = '/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk.v9.1'\n",
    "\n",
    "\n",
    "batch_inference(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbe1dff7-d2dc-4e9b-9386-ebdfec9e4dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.topic.knn.final ===input-path===\n",
      "/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk.v9.1 ===output-path===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2071401it [45:32, 758.09it/s]\n"
     ]
    }
   ],
   "source": [
    "input_path = '/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.topic.knn.final'\n",
    "output_path = '/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk.v9.1'\n",
    "\n",
    "\n",
    "batch_inference(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "884a652d-e1a0-4702-bd2b-979c4e0890e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [00:00, 959.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/albert.xht/xiaodao/query_risk_v10/biake_qa_web_text_zh_train.json.offensive.all ===input-path===\n",
      "/data/albert.xht/xiaodao/query_risk_v10/biake_qa_web_text_zh_train.json.offensive.all.v10.1 ===output-path===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18456it [00:17, 1072.16it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_path = '/data/albert.xht/xiaodao/query_risk_v10/biake_qa_web_text_zh_train.json.offensive.all'\n",
    "output_path = '/data/albert.xht/xiaodao/query_risk_v10/biake_qa_web_text_zh_train.json.offensive.all.v10.1'\n",
    "\n",
    "batch_inference(input_path, output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78f5eed3-f87a-4751-b53c-749b38682441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2071401it [04:34, 7542.81it/s] \n"
     ]
    }
   ],
   "source": [
    "black = []\n",
    "white = []\n",
    "import fast_json as json\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(output_path) as frobj:\n",
    "    for line in tqdm(frobj):\n",
    "        content = json.loads(line.strip())\n",
    "        if content['score_list']['query_risk'][0][1] > 0.5:\n",
    "            black.append(content)\n",
    "        else:\n",
    "            white.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62e47994-6552-42ee-85ba-335f5e5a90dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177560"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c8dd8ee-2986-4425-825f-3704c128264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_v1 = []\n",
    "black_white = []\n",
    "for d in black:\n",
    "    if d['score_list']['query_risk'][0][1] > 0.9:\n",
    "        black_v1.append(d)\n",
    "    else:\n",
    "        black_white.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "35798b55-7821-41d2-9ac0-7edd91a22899",
   "metadata": {},
   "outputs": [],
   "source": [
    "sssss = []\n",
    "for d in black_white:\n",
    "    p = []\n",
    "    for key in ['senti', 'offensive', 'teenager', 'senti_query', 'senti_query']:\n",
    "        if d['score_list'][key][0][1] < 0.3:\n",
    "            p.append(1)\n",
    "        else:\n",
    "            p.append(0)\n",
    "    if d['score_list']['query_risk'][0][1] < 0.3:\n",
    "        p.append(1)\n",
    "    else:\n",
    "        p.append(0)\n",
    "    if d['score_list']['query_risk'][1][1] < 0.3:\n",
    "        p.append(1)\n",
    "    else:\n",
    "        p.append(0)\n",
    "    if sum(p) >= 5:\n",
    "        sssss.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "499da36d-19c5-41ad-954f-05691be9a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk.v9.1.black', 'w') as fwobj:\n",
    "    for d in black_v1:\n",
    "        content = copy(d)\n",
    "        lssslsl = content.pop('score_list')\n",
    "        content['label'] = ['风险']\n",
    "        fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ad4b5-55e5-4032-b2b7-4b89657f4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "    for d in white:\n",
    "        if d['topic'][0] not in data_dict:\n",
    "            data_dict[d['topic'][0]] = []\n",
    "        data_dict[d['topic'][0]].append(d)\n",
    "    train_sample = []\n",
    "    import random\n",
    "    for key in data_dict:\n",
    "        random.shuffle(data_dict[key])\n",
    "        train_sample.extend(data_dict[key][:int(0.15*len(data_dict[key]))])\n",
    "        \n",
    "    from copy import copy\n",
    "    for d in tqdm(train_sample):\n",
    "        content = d.copy()\n",
    "        if content['topic'][0] in ['死亡', '毒品', '恐怖主义', '战争', '灵异事件', \n",
    "                                   '色情', '灵异灵修', 'LGBT', 'BDSM', '性侵犯', '性骚扰']:\n",
    "            continue\n",
    "        if content['topic'][0] in ['法律']:\n",
    "            if d['score_list']['senti'][0][1] < 0.5 and d['score_list']['offensive'][0][1] < 0.5:\n",
    "                content['label'] = ['正常']\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            content['label'] = ['正常']\n",
    "        p = content.pop('score_list')\n",
    "        content['source'] = 'query_white'\n",
    "        fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03c03fbc-34dd-4b7e-89dd-f3b4b224a273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97158/97158 [00:00<00:00, 297035.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "with open('/data/albert.xht/xiaodao/topic_classification_v7/biake_qa_web_text_zh_train.json.positive.v8', 'w') as fwobj:\n",
    "    ppp = 0\n",
    "    for d in tqdm(black_white):\n",
    "        # if d['score_list']['senti_query'][-1][1] >= 0.8 and d['score_list']['senti'][-1][1] >= 0.8:\n",
    "            # if d['topic'][0] in ['军事', '时事政治', '历史', '国家', '社会', '法律', '色情']:\n",
    "            #     continue\n",
    "            # if d['topic'][0] in [ '色情']:\n",
    "            #     continue\n",
    "        if d['topic'][0] in ['学习', '时尚', '宠物', '娱乐', '校园生活', '电子数码', '动漫']:\n",
    "            content = d.copy()\n",
    "            _del = content.pop('score_list')\n",
    "            fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "#                 else:\n",
    "#                     continue\n",
    "#             fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "        \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8a9e3081-3327-4522-a309-908bc73666cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_dict = {}\n",
    "from collections import Counter\n",
    "t = Counter()\n",
    "for d in white:\n",
    "    t[d['topic'][0]] += 1\n",
    "    if d['topic'][0] not in white_dict:\n",
    "        white_dict[d['topic'][0]] = []\n",
    "    white_dict[d['topic'][0]].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0cb75500-586b-4352-b25a-2626f8ff490e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'senti_query': [['负向', 0.007037341594696045],\n",
       "  ['中性', 0.2305670976638794],\n",
       "  ['正向', 0.7623955607414246]],\n",
       " 'senti': [['负向', 0.05454050004482269], ['正向', 0.9454594850540161]],\n",
       " 'bias': [['偏见', 0.026843402534723282], ['正常', 0.9731566309928894]],\n",
       " 'ciron': [['讽刺', 0.032426558434963226], ['正常', 0.9675734043121338]],\n",
       " 'intent': [['主观评价/比较/判断', 0.16399823129177094],\n",
       "  ['寻求建议/帮助', 0.2048383355140686],\n",
       "  ['其它', 0.631163477897644]],\n",
       " 'offensive': [['冒犯', 0.06728868931531906], ['正常', 0.9327113628387451]],\n",
       " 'query_risk': [['风险', 0.02225596271455288],\n",
       "  ['个人信息', 0.004046468064188957],\n",
       "  ['正常', 0.9736975431442261]],\n",
       " 'teenager': [['不良', 0.009918730705976486], ['正常', 0.990081250667572]]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_api.predict('说的好。亚洲人在那里也属于,少数族裔，但是被压迫的不行了')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "67236c16-3d55-4b99-8e63-7966c02c0113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[unused1]', '后的数据规范环境', '[unused2]', 'gsdhkjsgaf', '[unused2]', '[SEP]']"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.split('(\\\\[unused\\d+\\\\])', '[unused1]后的数据规范环境[unused2]gsdhkjsgaf[unused2][SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "d5e48192-3ca8-4424-94f9-d48c9bbd3746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [], 'token_type_ids': [], 'attention_mask': []}"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_api.tokenizer('', add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "586e1d4e-17fb-43f6-8c6c-eb6bc4fd4b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50175it [00:49, 1023.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30620/4041987884.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrisk_predict_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mprob_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     content = {\n",
      "\u001b[0;32m/tmp/ipykernel_30620/4041987884.py\u001b[0m in \u001b[0;36mrisk_predict_batch\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mresult_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrisk_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_30620/3636409198.py\u001b[0m in \u001b[0;36mpredict_batch\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mscores_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mschema_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0mscores_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mschema_type\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         for hook in itertools.chain(\n\u001b[0m\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                 self._forward_hooks.values()):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json, re\n",
    "\n",
    "def risk_predict_batch(text):\n",
    "    if isinstance(text, list):\n",
    "        text_list = text\n",
    "    else:\n",
    "        text_list = [text]\n",
    "    result_list = risk_api.predict_batch(text_list)\n",
    "    return result_list\n",
    "\n",
    "# with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk', 'w') as fwobj:\n",
    "# with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk_v5', 'w') as fwobj:\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk_v10_logitclip', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json', 'r') as frobj:\n",
    "        queue = []\n",
    "        t = []\n",
    "        for line in tqdm(frobj):\n",
    "            content = json.loads(line.strip())\n",
    "            content['text'] = re.sub('请问', '', content['text'])\n",
    "            queue.append(content['text'])\n",
    "            t.append(content)\n",
    "            if np.mod(len(queue), 512) == 0:\n",
    "                probs = risk_predict_batch(queue)\n",
    "                for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                    content = {\n",
    "                        'text':text,\n",
    "                        'topic':tt['label'],\n",
    "                        'score_list':prob_dict\n",
    "                    }\n",
    "                    fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                queue = []\n",
    "                t = []\n",
    "        if queue:\n",
    "            probs = risk_predict_batch(queue)\n",
    "            for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                content = {\n",
    "                    'text':text,\n",
    "                    'topic':tt['label'],\n",
    "                    'score_list':prob_dict\n",
    "                }\n",
    "                fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7ee70904-41cf-4aa4-8ecd-86bbe3b4823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15414it [00:14, 1069.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json, re\n",
    "\n",
    "def risk_predict_batch(text):\n",
    "    if isinstance(text, list):\n",
    "        text_list = text\n",
    "    else:\n",
    "        text_list = [text]\n",
    "    result_list = risk_api.predict_batch(text_list)\n",
    "    return result_list\n",
    "\n",
    "offensive = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.offensive.all', 'r') as frobj:\n",
    "    queue = []\n",
    "    t = []\n",
    "    for line in tqdm(frobj):\n",
    "        content = json.loads(line.strip())\n",
    "        content['text'] = re.sub('请问', '', content['text'])\n",
    "        queue.append(content['text'])\n",
    "        t.append(content)\n",
    "        if np.mod(len(queue), 512) == 0:\n",
    "            probs = risk_predict_batch(queue)\n",
    "            for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                content = {\n",
    "                    'text':text,\n",
    "                    'topic':tt['label'],\n",
    "                    'score_list':prob_dict\n",
    "                }\n",
    "                offensive.append(content)\n",
    "            queue = []\n",
    "            t = []\n",
    "    if queue:\n",
    "        probs = risk_predict_batch(queue)\n",
    "        for prob_dict, text, tt in zip(probs, queue, t):\n",
    "            content = {\n",
    "                'text':text,\n",
    "                'topic':tt['label'],\n",
    "                'score_list':prob_dict\n",
    "            }\n",
    "            offensive.append(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bfdece-5835-4d7c-80bc-373d2698a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.white', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json', 'r') as frobj:\n",
    "        data_dict = {}\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['text'] not in data_dict:\n",
    "                data_dict[content['text']] = []\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f93dbbc3-5517-4736-8cf1-b3b57a771f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json, re\n",
    "\n",
    "def risk_predict_batch(text):\n",
    "    if isinstance(text, list):\n",
    "        text_list = text\n",
    "    else:\n",
    "        text_list = [text]\n",
    "    result_list = risk_api.predict_batch(text_list)\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de843f4c-6f21-485b-b31c-5925c1e743a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_api.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889bd0b-0c26-4c80-8a75-2d962c79dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json, re\n",
    "\n",
    "def risk_predict_batch(text):\n",
    "    if isinstance(text, list):\n",
    "        text_list = text\n",
    "    else:\n",
    "        text_list = [text]\n",
    "    result_list = risk_api.predict_batch(text_list)\n",
    "    return result_list\n",
    "\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.bias_ciron', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json', 'r') as frobj:\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['label'][0] not in data_dict:\n",
    "                data_dict[content['label'][0]] = []\n",
    "            data_dict[content['label'][0]].append(content)\n",
    "\n",
    "    train_sample = []\n",
    "    import random\n",
    "    for key in data_dict:\n",
    "        random.shuffle(data_dict[key])\n",
    "        train_sample.extend(data_dict[key][:int(0.2*len(data_dict[key]))])\n",
    "    cnt = 1\n",
    "    queue = []\n",
    "    for content in tqdm(train_sample):\n",
    "        content['text'] = re.sub('请问', '', content['text'])\n",
    "        queue.append(content['text'])\n",
    "        if np.mod(len(queue), 256) == 0:\n",
    "            probs = risk_predict_batch(queue)\n",
    "            for prob_dict, text in zip(probs, queue):\n",
    "                score_list = []\n",
    "                for key in ['bias', 'ciron', 'teenager']:\n",
    "                    if prob_dict[key][0][1] > 0.9:\n",
    "                        score_list.append([key, float(prob_dict[key][0][1])])\n",
    "                key = 'query_risk'\n",
    "                if prob_dict[key][0][1] > 0.9:\n",
    "                    score_list.append([prob_dict[key][0][0], float(prob_dict[key][0][1])])\n",
    "                if prob_dict[key][1][1] > 0.9:\n",
    "                    score_list.append([prob_dict[key][1][0], float(prob_dict[key][1][1])])\n",
    "                if score_list:\n",
    "                    content = {\n",
    "                        'text':text,\n",
    "                        'label':['风险'],\n",
    "                        'score_list':score_list\n",
    "                    }\n",
    "                    fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "            queue = []\n",
    "    if queue:\n",
    "        probs = risk_predict_batch(queue)\n",
    "        for prob_dict, text in zip(probs, queue):\n",
    "            score_list = []\n",
    "            for key in ['bias', 'ciron', 'teenager']:\n",
    "                if prob_dict[key][0][1] > 0.9:\n",
    "                    score_list.append([key, float(prob_dict[key][0][1])])\n",
    "            key = 'query_risk'\n",
    "            if prob_dict[key][0][1] > 0.9:\n",
    "                score_list.append([prob_dict[key][0][0], float(prob_dict[key][0][1])])\n",
    "            if prob_dict[key][1][1] > 0.9:\n",
    "                score_list.append([prob_dict[key][1][0], float(prob_dict[key][1][1])])\n",
    "\n",
    "            if score_list:\n",
    "                content = {\n",
    "                    'text':text,\n",
    "                    'label':['风险'],\n",
    "                    'score_list':score_list\n",
    "                }\n",
    "                fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c16ed0d4-d106-45f3-9c69-63174922ba16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['偏见', 0.4076650142669678]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dict[key][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "848ec613-e7bb-488d-ac31-1b3b4107e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_intent_v1/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_mtdnn_ce_256/multitask_cls.pth.9')\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_contrast_intent_v1/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256_20/multitask_cls.pth.19')\n",
    "\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/query_risk_v3/multitask_raw_filter_senti_query_risk_v3/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "922a1706-eca4-49ef-a30f-ff70903cb260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56443it [07:27, 126.13it/s]\n",
      "56443it [07:29, 125.59it/s]\n",
      "56443it [07:25, 126.73it/s]\n",
      "56443it [07:25, 126.60it/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = [\n",
    "'/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256/multitask_cls.pth.9',\n",
    "'/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_intent_v1/multitask_cls.pth.9',\n",
    "'/data/albert.xht/xiaodao/risk_classification/multitask_mtdnn_ce_256/multitask_cls.pth.9',\n",
    "'/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256_20/multitask_cls.pth.19',\n",
    "]\n",
    "\n",
    "from tqdm import tqdm\n",
    "total_result = []\n",
    "for model in model_path:\n",
    "    result_list = []\n",
    "    risk_api.reload(model)\n",
    "    with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/疑似有风险query_from对话预训练数据-20221130.txt') as frobj:\n",
    "        for line in tqdm(frobj):\n",
    "            text = line.strip()\n",
    "            result = risk_api.predict(text)\n",
    "            result_list.append((text, result))\n",
    "    total_result.append(result_list)\n",
    "\n",
    "result_matrix = []\n",
    "for i in range(len(total_result[0])):\n",
    "    p = []\n",
    "    for tmp in total_result:\n",
    "        item = tmp[i]\n",
    "        for key in ['senti', 'bias', 'ciron', 'offensive', 'teenager', 'query_risk']:\n",
    "            if item[1][key][0][1] > 0.6:\n",
    "                p.append(1)\n",
    "            else:\n",
    "                p.append(0)\n",
    "    result_matrix.append(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "730555ae-2ca3-4c8c-8a88-86e8ca26f4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a1ad192a-4cb4-46b9-8ae9-9620b9e2e3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56443it [08:00, 117.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "result_list = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/疑似有风险query_from对话预训练数据-20221130.txt') as frobj:\n",
    "    for line in tqdm(frobj):\n",
    "        text = line.strip()\n",
    "        result = risk_api.predict(text)\n",
    "        result_list.append((text, result))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "0c20e17f-6b80-4c13-ab5d-ca54f63c1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_matrix = []\n",
    "for item in result_list:\n",
    "    p = []\n",
    "    for key in ['senti', 'bias', 'ciron', 'offensive', 'teenager']:\n",
    "        if item[1][key][0][1] > 0.59:\n",
    "            p.append(1)\n",
    "        else:\n",
    "            p.append(0)\n",
    "    result_matrix.append(p)\n",
    "        \n",
    "        \n",
    "# result_matrix = []\n",
    "# for item in result_list:\n",
    "#     p = []\n",
    "#     for key in ['senti', 'bias', 'ciron', 'offensive', 'teenager', 'query_risk']:\n",
    "#         if item[1][key][0][1] >= 0.6:\n",
    "#             p.append(1)\n",
    "#         else:\n",
    "#             p.append(0)\n",
    "#     result_matrix.append(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "cb6c7ddd-52ea-481e-88a4-90a16ef8e4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36067"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_matrix = np.array(result_matrix)\n",
    "votes = np.sum(result_matrix, axis=-1)\n",
    "labels = np.array(votes >= 6).astype(np.int)\n",
    "sum(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "01825f5e-623c-4b7b-88e2-25a1d2da9278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56443, 2)\n",
      "(56443, 2)\n",
      "(56443, 2)\n",
      "(56443, 2)\n",
      "(56443, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "result_matrix = np.array(result_matrix)\n",
    "\n",
    "def SIMPLE(result_matrix):\n",
    "    votes = np.sum(result_matrix, axis=-1)\n",
    "    labels = np.array(votes >= 6).astype(np.int)\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0, ccp_alpha=0.1)\n",
    "    \n",
    "    for i in range(5):\n",
    "        result = clf.fit(result_matrix, labels)\n",
    "        probs = clf.predict_proba(result_matrix)\n",
    "        print(probs.shape)\n",
    "        labels = np.argmax(probs, axis=-1)\n",
    "    return probs\n",
    "\n",
    "\n",
    "probs = SIMPLE(result_matrix)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "7b11c013-2682-44a7-8891-676e2f417832",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = []\n",
    "clean = []\n",
    "for idx in range(probs.shape[0]):\n",
    "    if probs[idx,1] >= 0.8:\n",
    "        ff.append((idx, result_list[idx], probs[idx]))\n",
    "    else:\n",
    "        clean.append((idx, result_list[idx], probs[idx]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dffa0dcb-cebe-4e4b-99b3-502f0a605aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24721it [00:22, 1076.00it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/query_risk_corpus.json.risk', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/query_risk_corpus.json', 'r') as frobj:\n",
    "        queue = []\n",
    "        t = []\n",
    "        for line in tqdm(frobj):\n",
    "            content = json.loads(line.strip())\n",
    "            # content['text'] = re.sub('请问', '', content['text'])\n",
    "            queue.append(content['text'])\n",
    "            t.append(content)\n",
    "            if np.mod(len(queue), 512) == 0:\n",
    "                probs = risk_predict_batch(queue)\n",
    "                for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                    content = {\n",
    "                        'text':text,\n",
    "                        'topic':tt['label'],\n",
    "                        'score_list':prob_dict\n",
    "                    }\n",
    "                    fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                queue = []\n",
    "                t = []\n",
    "        if queue:\n",
    "            probs = risk_predict_batch(queue)\n",
    "            for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                content = {\n",
    "                    'text':text,\n",
    "                    'topic':tt['label'],\n",
    "                    'score_list':prob_dict\n",
    "                }\n",
    "                fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "7d8131b4-0222-4fd2-bf2f-70e9a664a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/query_risk_corpus.json', 'w') as fwobj:\n",
    "    for item in ff:\n",
    "        tmp = {\n",
    "            'text':item[1][0],\n",
    "            'label':['风险']\n",
    "        }\n",
    "        fwobj.write(json.dumps(tmp, ensure_ascii=False)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f2892662-d000-4901-a6c4-7db24e582c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = [] \n",
    "positive = []\n",
    "for item in result_list:\n",
    "    if item[1]['senti'][0][1] >= 0.7 or item[1]['bias'][0][1] >= 0.8 or item[1]['ciron'][0][1] >= 0.8 or item[1]['offensive'][0][1] >= 0.8:\n",
    "        candidate.append(item)\n",
    "    else:\n",
    "        positive.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e0f7dfb-0767-486b-9d82-394f3f01eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "offensive = []\n",
    "with open('/data/albert.xht/sentiment/dev/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive.append(content)\n",
    "        \n",
    "offensive_test = []\n",
    "with open('/data/albert.xht/sentiment/test/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive_test.append(content)\n",
    "\n",
    "        \n",
    "cdia_bias = []\n",
    "with open('/data/albert.xht/sentiment/dev/cdial_bias.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        cdia_bias.append(content)\n",
    "        \n",
    "senti_copr = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_copr.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_copr.append(content)\n",
    "        \n",
    "ciron = []\n",
    "with open('/data/albert.xht/sentiment/dev/chinese_ciron.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        ciron.append(content)\n",
    "\n",
    "senti_smp = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smp_usual.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smp.append(content)\n",
    "        \n",
    "senti_smpecisa = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smpecisa.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smpecisa.append(content)\n",
    "\n",
    "        \n",
    "senti_query = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_valid.json.filter.0.7') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_query.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56a49dd8-fe1a-4fae-b310-627ddf85ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def eval_all(data, model, key):\n",
    "    pred = []\n",
    "    gold = []\n",
    "    pred_score = []\n",
    "    for item in tqdm(data):\n",
    "        gold.append(item['label'][0])\n",
    "        if isinstance(item['text'], list):\n",
    "            text = \"\\n\".join(item['text'])\n",
    "        else:\n",
    "            text = item['text']\n",
    "        text = re.sub(r\"([，\\_《。》、？；：‘’＂“”【「】」·！@￥…（）—\\,\\<\\.\\>\\/\\?\\;\\:\\'\\\"\\[\\]\\{\\}\\~\\`\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\-\\=\\+])+\", \"\", text)   # 合并正文中过多的空格\n",
    "\n",
    "        result = model.predict(text)\n",
    "        score = sorted(result[key], key=lambda u:u[1], reverse=True)\n",
    "        pred.append(score[0][0])\n",
    "        pred_score.append(result[key])\n",
    "    print(classification_report(gold, pred, digits=4))\n",
    "    return pred, gold, pred_score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bef11639-006f-4482-a104-1fc2e8d1b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluation_ece(pred_score, gold):\n",
    "    pred_score_l = []\n",
    "    mapping_dict = {}\n",
    "    for item in pred_score:\n",
    "        pred_score_l.append([])\n",
    "        for idx, p in enumerate(item):\n",
    "            if p[0] not in mapping_dict:\n",
    "                mapping_dict[p[0]] = idx\n",
    "            pred_score_l[-1].append(p[1])\n",
    "    pred_score_l = torch.tensor(pred_score_l)\n",
    "    gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "\n",
    "    ece_fn = ECE(n_bins=15)\n",
    "    print(ece_fn(pred_score_l, gold_l, mode='probs'), '==ece==')\n",
    "# pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "# evaluation_ece(pred_score, gold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "794ca494-16bf-438b-b074-6413f0ef1fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'冒犯': 0, '正常': 1}\n",
      "tensor([0.1119]) ==ece==\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22222f61-41b9-463f-9e00-9f1068e5cee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['正常', 0.9768216013908386]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "181c5de9-6e52-4eaf-b83a-d56f7cd98ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3797b0ad-bfdb-4593-9ea4-a42c2ef8cda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'正常'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1a0b3183-0619-4df4-8d4b-19b0c43e6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model_path):\n",
    "    risk_api.reload(model_path)\n",
    "    print('===offensive===')\n",
    "    pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===cdia-bias===')\n",
    "    pred, gold, pred_score = eval_all(cdia_bias, risk_api, 'bias')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===ciron===')\n",
    "    pred, gold, pred_score = eval_all(ciron, risk_api, 'ciron')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===chsenti===')\n",
    "    pred, gold, pred_score = eval_all(senti_copr, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smpecisa===')\n",
    "    pred, gold, pred_score = eval_all(senti_smpecisa, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smp===')\n",
    "    pred, gold, pred_score = eval_all(senti_smp, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_query===')\n",
    "    pred, gold, pred_score = eval_all(senti_query, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dc4a276d-2a26-4c01-8cb8-c92e928a3bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:25<00:00, 117.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  主观评价/比较/判断     0.9233    0.9784    0.9501       603\n",
      "          其它     0.9913    0.9725    0.9818      2219\n",
      "     寻求建议/帮助     0.9022    0.9326    0.9171       178\n",
      "\n",
      "    accuracy                         0.9713      3000\n",
      "   macro avg     0.9389    0.9612    0.9497      3000\n",
      "weighted avg     0.9723    0.9713    0.9716      3000\n",
      "\n",
      "tensor([0.0181]) ==ece==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2/multitask_cls.pth.9')\n",
    "\n",
    "# # risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_query_risk_20221222/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2_5_aug/multitask_cls.pth.4')\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v10_intent_v2-1_10_no_symbol_senti_query_senta_balanced_logitclip_v1/multitask_cls.pth.9')\n",
    "risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_balanced_v2/multitask_cls.pth.5')\n",
    "\n",
    "intent_v2 = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/xiaoda/intention_data_v2/dev.txt') as frobj:\n",
    "    for line in frobj:\n",
    "        intent_v2.append(json.loads(line.strip()))\n",
    "pred, gold, pred_score = eval_all(intent_v2, risk_api, 'intent')\n",
    "evaluation_ece(pred_score, gold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "10c6dcf8-97f9-4b5d-aaa5-2689a7dbb91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20641/20641 [02:57<00:00, 115.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.8883    0.5134    0.6507      5514\n",
      "          风险     0.8463    0.9765    0.9067     15127\n",
      "\n",
      "    accuracy                         0.8528     20641\n",
      "   macro avg     0.8673    0.7449    0.7787     20641\n",
      "weighted avg     0.8575    0.8528    0.8383     20641\n",
      "\n",
      "tensor([0.0591]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_balanced_v2/multitask_cls.pth.7')\n",
    "\n",
    "risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_mtdnn_v6/multitask_cls.pth.9')\n",
    "\n",
    "risk_query = []\n",
    "with open('/data/albert.xht/xiaodao/query_risk_v11/offensive_select_labeled.txt') as frobj:\n",
    "    for line in frobj:\n",
    "        risk_query.append(json.loads(line.strip()))\n",
    "pred, gold, pred_score = eval_all(risk_query, risk_api, 'query_risk')\n",
    "evaluation_ece(pred_score, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1c8d95e8-8b6c-42a3-bb6a-c0174d764322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20641/20641 [02:57<00:00, 116.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.7792    0.6578    0.7133      5514\n",
      "          风险     0.8820    0.9320    0.9063     15127\n",
      "\n",
      "    accuracy                         0.8588     20641\n",
      "   macro avg     0.8306    0.7949    0.8098     20641\n",
      "weighted avg     0.8545    0.8588    0.8548     20641\n",
      "\n",
      "tensor([0.0275]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_balanced_v4/multitask_cls.pth.9')\n",
    "\n",
    "risk_query = []\n",
    "with open('/data/albert.xht/xiaodao/query_risk_v11/offensive_select_labeled.txt') as frobj:\n",
    "    for line in frobj:\n",
    "        risk_query.append(json.loads(line.strip()))\n",
    "pred, gold, pred_score = eval_all(risk_query, risk_api, 'query_risk')\n",
    "evaluation_ece(pred_score, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1cc50e50-4058-46f3-82e8-9c8582d265b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4, 3, 4, 2, 2, 1, 4, 2, 3, 3, 4, 4, 2, 4, 3, 1, 4, 2])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([1,2,3,4], 20, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2ccfcddc-f2b3-49ac-8ad0-2d40f39e69bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:25<00:00, 117.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  主观评价/比较/判断     0.9367    0.9818    0.9587       603\n",
      "          其它     0.9931    0.9775    0.9852      2219\n",
      "     寻求建议/帮助     0.9239    0.9551    0.9392       178\n",
      "\n",
      "    accuracy                         0.9770      3000\n",
      "   macro avg     0.9513    0.9714    0.9611      3000\n",
      "weighted avg     0.9777    0.9770    0.9772      3000\n",
      "\n",
      "tensor([0.0156]) ==ece==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "intent_v2 = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/xiaoda/intention_data_v2/dev.txt') as frobj:\n",
    "    for line in frobj:\n",
    "        intent_v2.append(json.loads(line.strip()))\n",
    "pred, gold, pred_score = eval_all(intent_v2, risk_api, 'intent')\n",
    "evaluation_ece(pred_score, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2d2f0a6f-407e-4180-afa5-9a9b8fa345bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'senti_query': [['负向', 0.9976022839546204],\n",
       "  ['中性', 0.0023331306874752045],\n",
       "  ['正向', 6.459149881266057e-05]],\n",
       " 'senti': [['负向', 0.9968634843826294], ['正向', 0.0031365305185317993]],\n",
       " 'bias': [['偏见', 0.6690516471862793], ['正常', 0.3309483826160431]],\n",
       " 'ciron': [['讽刺', 0.30152297019958496], ['正常', 0.698477029800415]],\n",
       " 'intent': [['主观评价/比较/判断', 0.0004942239611409605],\n",
       "  ['寻求建议/帮助', 0.9988555908203125],\n",
       "  ['其它', 0.0006501346942968667]],\n",
       " 'offensive': [['冒犯', 0.9131566882133484], ['正常', 0.0868433341383934]],\n",
       " 'query_risk': [['风险', 0.10928872972726822],\n",
       "  ['个人信息', 0.0005252966075204313],\n",
       "  ['正常', 0.8901860117912292]],\n",
       " 'teenager': [['不良', 0.55097496509552], ['正常', 0.44902506470680237]]}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_balanced_v2/multitask_cls.pth.9')\n",
    "\n",
    "risk_api.predict('头疼恶心')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "971aa9fd-bb7d-4979-85ff-3846c5468198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/5304 [00:00<00:46, 114.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:45<00:00, 115.80it/s]\n",
      "  0%|          | 12/2829 [00:00<00:24, 116.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7233    0.8651    0.7879      2106\n",
      "          正常     0.8980    0.7821    0.8360      3198\n",
      "\n",
      "    accuracy                         0.8150      5304\n",
      "   macro avg     0.8107    0.8236    0.8120      5304\n",
      "weighted avg     0.8287    0.8150    0.8169      5304\n",
      "\n",
      "tensor([0.1024]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:24<00:00, 115.61it/s]\n",
      "  1%|▏         | 12/875 [00:00<00:07, 116.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.4979    0.6727    0.5723       718\n",
      "          正常     0.8736    0.7693    0.8181      2111\n",
      "\n",
      "    accuracy                         0.7448      2829\n",
      "   macro avg     0.6858    0.7210    0.6952      2829\n",
      "weighted avg     0.7782    0.7448    0.7557      2829\n",
      "\n",
      "tensor([0.0150]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:07<00:00, 116.38it/s]\n",
      "  1%|          | 12/1200 [00:00<00:10, 114.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9301    0.9397    0.9349       779\n",
      "          讽刺     0.4659    0.4271    0.4457        96\n",
      "\n",
      "    accuracy                         0.8834       875\n",
      "   macro avg     0.6980    0.6834    0.6903       875\n",
      "weighted avg     0.8792    0.8834    0.8812       875\n",
      "\n",
      "tensor([0.0316]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.46it/s]\n",
      "  0%|          | 12/2529 [00:00<00:21, 116.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9121    0.9275    0.9197       593\n",
      "          负向     0.9280    0.9127    0.9203       607\n",
      "\n",
      "    accuracy                         0.9200      1200\n",
      "   macro avg     0.9200    0.9201    0.9200      1200\n",
      "weighted avg     0.9201    0.9200    0.9200      1200\n",
      "\n",
      "tensor([0.0268]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:21<00:00, 116.69it/s]\n",
      "  0%|          | 12/2844 [00:00<00:24, 117.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8096    0.8177    0.8136      1201\n",
      "          负向     0.8336    0.8261    0.8298      1328\n",
      "\n",
      "    accuracy                         0.8221      2529\n",
      "   macro avg     0.8216    0.8219    0.8217      2529\n",
      "weighted avg     0.8222    0.8221    0.8221      2529\n",
      "\n",
      "tensor([0.0986]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:24<00:00, 116.16it/s]\n",
      "  0%|          | 12/50509 [00:00<07:12, 116.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8117    0.9112    0.8586      1126\n",
      "          负向     0.9367    0.8615    0.8975      1718\n",
      "\n",
      "    accuracy                         0.8812      2844\n",
      "   macro avg     0.8742    0.8863    0.8780      2844\n",
      "weighted avg     0.8872    0.8812    0.8821      2844\n",
      "\n",
      "tensor([0.0661]) ==ece==\n",
      "===senti_query===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9193/50509 [01:18<05:52, 117.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_74056/2937549272.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_mtdnn_v6/multitask_cls.pth.9'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_74056/3217327212.py\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===senti_query==='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msenti_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'senti'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_74056/1846423510.py\u001b[0m in \u001b[0;36meval_all\u001b[0;34m(data, model, key)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"([，\\_《。》、？；：‘’＂“”【「】」·！@￥…（）—\\,\\<\\.\\>\\/\\?\\;\\:\\'\\\"\\[\\]\\{\\}\\~\\`\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\-\\=\\+])+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 合并正文中过多的空格\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_74056/387664356.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             [logits_list, \n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                 attention_mask, token_type_ids, transformer_mode='cls')\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mschema_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_74056/387664356.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_mask, segment_ids, transformer_mode, dt_idx)\u001b[0m\n\u001b[1;32m    106\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                     \u001b[0mce_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                     \u001b[0moutputs_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mce_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/xiaoda/query_topic/nets/them_classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mlast_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mlast_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_mtdnn_v6/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "85c6c500-b13e-481b-bc0d-f2a0e8d8e532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "192/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a98ebb-c331-4a98-94b6-c4900cc72bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v5_intent_v2_3/multitask_cls.pth.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6d33604c-c509-4399-8cb2-a85b98ca7ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_balanced_v2/multitask_cls.pth.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "84d023db-629d-45ba-b1eb-715b68847eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v10_intent_v2-1_10_no_symbol_senti_query_senta_balanced_logitclip_v1/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4116d43-9495-43d6-bb69-7355b780047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v10_intent_v2-1_10_no_symbol_senti_query_senta_balanced_logitclip/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c78050ab-618a-4d5c-bf4e-e7dcdcad9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v9_intent_v2-1_10_no_symbol_v1/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c29b8019-e251-44c9-94e4-a61f9a91a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v6_intent_v2-1_10_no_symbol/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d241c474-bcd8-4c0f-ab73-cd54c3078912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v5_no_offensive_intent_v2-1_3/multitask_cls.pth.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d63066c-26d5-45d4-91e6-fa641a592d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/multitask_raw_filter_senti_query_risk_v5_intent_v2-1_3/multitask_cls.pth.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da1db8e-837f-4609-adfc-566ba2583b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [], range(1, 0))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0, 1), random.sample(list(range(1, 2)), k=0), range(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b0f5c9b8-2e59-4186-a9c1-d3736d6738d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2_5_aug/multitask_cls.pth.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5c763a78-8c46-4d58-8632-ed678351854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2/multitask_cls.pth.8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ce62f6d0-bbae-47d4-b570-2799bdeec8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_query_risk_20221222/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8331128b-2671-4129-9a7a-4781b657b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/query_risk_v3/multitask_raw_filter_senti_query_risk_v3/multitask_cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3a0e43c1-6b45-4755-bdec-c6bc93910aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256_20/multitask_cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2c81a54a-1768-4454-9e04-7f9c8c52673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_intent_v1/multitask_cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f1c4efc0-473c-4613-ac20-62c9d193c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_focal/multitask_cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cc5ba38e-db17-4e3d-b05c-caabe86f0e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_balanced_intent_v1//multitask_cls.pth.9')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d330603c-fb51-4465-b010-b852348536cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_focal_128/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "192980fd-608d-418a-baf2-e03061767e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_contrast_balanced_intent_v1/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ef2307e5-3160-4342-8598-af7711f6c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_mtdnn_ce_256/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0e06bba0-2c4c-4a2e-b842-67823dced661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_mtdnn_focal_256/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c84059c2-9bc9-4978-b772-d4bb5b37b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256/multitask_cls.pth.9')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f16c2c92-d5c2-460f-932a-edf2f2495adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_focal_256/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6e3af45a-5bf4-485e-99c4-1519de0f35d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_contrast_intent_v1/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d21ccffe-66ff-4772-88de-6ab24412153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ece_fn = ECE(n_bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32cc476b-9973-4b61-8b05-85cdca4a3e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1104])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict = {\n",
    "    '冒犯':0,\n",
    "    '正常':1\n",
    "}\n",
    "\n",
    "gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "pred_score_l = torch.tensor([[item[0][1], item[1][1]] for item in pred_score])\n",
    "\n",
    "ece_fn(pred_score_l, gold_l, mode='probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f8d4490-f58a-441f-95fa-f38238cc70bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0198])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict = {\n",
    "    '负向':0,\n",
    "    '正向':1\n",
    "}\n",
    "\n",
    "gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "pred_score_l = torch.tensor([[item[0][1], item[1][1]] for item in pred_score])\n",
    "\n",
    "ece_fn(pred_score_l, gold_l, mode='probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32e811-a4a8-4415-b2d5-ef3d3c89ffd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
