{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b887f5ed-cd37-42ab-aa6c-04d0e6d567ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23572it [00:37, 620.65it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_list = []\n",
    "import json\n",
    "from tqdm import tqdm \n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.offensive.all.knn') as frobj:\n",
    "    for line in tqdm(frobj):\n",
    "        data_list.append(json.loads(line.strip()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c575c7d-d0a2-4e42-9b7c-d710ecbdb1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18456it [00:03, 5989.30it/s]\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "import json\n",
    "from tqdm import tqdm \n",
    "with open('/data/albert.xht/xiaodao/query_risk_v10/biake_qa_web_text_zh_train.json.offensive.all.knn') as frobj:\n",
    "    for line in tqdm(frobj):\n",
    "        content = json.loads(line.strip())\n",
    "        if content['topic'][0] in ['正常']:\n",
    "            data_list.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfa291e-c1a5-4bc3-9a1c-758f00778602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3080"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b13f020b-5baa-4a36-af44-2cff018af70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import sys,os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e30929-476e-4e45-9c95-2cbbbda42239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.extend(['/root/xiaoda/query_topic/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a64d00-d016-4ee8-99b3-5d87a6e532fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embed_feature_extraction import Paraphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced7a608-0648-47c4-a9de-f367110679cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RoFormerTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "Some weights of RoFormerForCausalLM were not initialized from the model checkpoint at junnyu/roformer_chinese_sim_char_small and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "'device':'cuda:3'\n",
    "}\n",
    "paraphrase_api = Paraphrase(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9106fcd3-8c42-45f2-b295-7f783cdd229f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:3'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df66b3d4-848c-42fc-ae66-a8b93b04918d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/albert.xht/xiaodao/topic_classification_v7/biake_qa_web_text_zh_train.json.positive ==input-path==\n",
      "/data/albert.xht/xiaodao/knn//feat.json ==output-path==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25507it [00:24, 1045.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding first batch of 25507 elements\n"
     ]
    }
   ],
   "source": [
    "input_path = '/data/albert.xht/xiaodao/topic_classification_v7/biake_qa_web_text_zh_train.json.positive'\n",
    "output_path = '/data/albert.xht/xiaodao/knn/'\n",
    "\n",
    "paraphrase_api.build_index(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cc780a1-868c-481b-bd09-ca2c2ac2610f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25507it [00:05, 4877.53it/s]\n"
     ]
    }
   ],
   "source": [
    "paraphrase_api.load_knn(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa91863-5c33-4b11-b2c9-95ed8ca1655a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008402824401855469 [[{'label': 3815, 'distance': 0.9642647504806519, 'info': {'text': '怎么评价马云？', 'topic': ['电脑/网络']}}, {'label': 2194, 'distance': 0.8742460608482361, 'info': {'text': '如何评价马东？', 'topic': ['明星']}}, {'label': 2849, 'distance': 0.8629987835884094, 'info': {'text': '如何评价马龙？', 'topic': ['体育/运动']}}, {'label': 8533, 'distance': 0.8615167737007141, 'info': {'text': '如何评价马克思？', 'topic': ['历史']}}, {'label': 12660, 'distance': 0.8330047726631165, 'info': {'text': '如何评价马谡？', 'topic': ['历史']}}, {'label': 7990, 'distance': 0.8043173551559448, 'info': {'text': '如何评价马克莱莱？', 'topic': ['体育/运动']}}, {'label': 2336, 'distance': 0.8042776584625244, 'info': {'text': '如何评价马拉多纳？', 'topic': ['体育/运动']}}, {'label': 6363, 'distance': 0.7941882014274597, 'info': {'text': '如何对比评价任正非和马云？', 'topic': ['人物']}}, {'label': 4939, 'distance': 0.793393075466156, 'info': {'text': '如何评价马雪阳？', 'topic': ['音乐']}}, {'label': 4917, 'distance': 0.7922425866127014, 'info': {'text': '如何评价司马昭？', 'topic': ['小说']}}]]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for _ in range(1):\n",
    "    resp = paraphrase_api.get_knn('如何评价马云')\n",
    "print(time.time()-start, resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88a2e70a-c350-4e87-bc3b-e5a3c8dd3b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0986122886681098"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "f = [1.0162e+01, 5.5282e+00, 4.2275e-01, 0.0000e+00, 5.4486e-03, 6.2575e-02,\n",
    "        9.5896e-01, 5.8232e+00]\n",
    "n = [3,2,2,2,3,2,3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0361cba-8117-4f61-8e22-c6f1482c3c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23572it [00:00, 34988.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.offensive.all.knn.filter', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.offensive.all.knn') as frobj:\n",
    "        for line in tqdm(frobj):\n",
    "            content = json.loads(line.strip())\n",
    "            knn_offensive = 0\n",
    "            for knn in content['knn']:\n",
    "                if knn['prob']['冒犯'] >= 0.7 and knn['dist'] >= 0.7:\n",
    "                    knn_offensive += 1\n",
    "            \n",
    "            \n",
    "            \n",
    "            if content['prob']['冒犯'] >= 0.9:\n",
    "                continue\n",
    "            #     fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "            else:\n",
    "                if knn_offensive/(len(content['knn'])+1e-10) >= 0.6 and content['prob']['冒犯'] >= 0.6 and content['prob']['冒犯'] >= 0.6 :\n",
    "                    tmp = copy(content)\n",
    "                    kk = tmp.pop('knn')\n",
    "                    tmp['label'] = ['风险']\n",
    "                    fwobj.write(json.dumps(tmp, ensure_ascii=False)+'\\n')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2e6b2c4d-f297-4387-a05b-9e4f65faa4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'恋爱'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a2e3869-5f59-42df-81e0-981d9687032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.offensive.all.black', 'w') as fwobj:\n",
    "    for key in black:\n",
    "        fwobj.write(json.dumps(black[key], ensure_ascii=False)+'\\n')\n",
    "        \n",
    "    \n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.offensive.all.white', 'w') as fwobj:\n",
    "    for key in white:\n",
    "        fwobj.write(json.dumps(white[key], ensure_ascii=False)+'\\n')\n",
    "        \n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.offensive.all.white', 'w') as fwobj:\n",
    "    for key in gray:\n",
    "        fwobj.write(json.dumps(gray[key], ensure_ascii=False)+'\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14b63c2d-160e-43d7-9af5-393d583b2215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2071401it [00:40, 51284.93it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm \n",
    "data2topic = {}\n",
    "t = 0\n",
    "alter = 0\n",
    "\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json,new_topic') as frobj:\n",
    "    infer_topic = {}\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        if content['text'] not in infer_topic:\n",
    "            infer_topic[content['text']] = []\n",
    "        infer_topic[content['text']] = content['new_topic']\n",
    "        \n",
    "\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.topic.knn') as frobj:\n",
    "    for line in tqdm(frobj):\n",
    "        content = json.loads(line.strip())\n",
    "        if content['text'] not in data2topic:\n",
    "            data2topic[content['text']] = []\n",
    "        \n",
    "        if content['topic_knn']:\n",
    "            data2topic[content['text']] = content['topic_knn']\n",
    "            if content['topic'][0] != content['topic_knn'][0][0]:\n",
    "                alter += 1\n",
    "        else:\n",
    "            data2topic[content['text']] = content['topic']\n",
    "            t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f24618d-8535-45f2-b56c-a7f3e2cf5c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data2topic:\n",
    "    data2topic[key].extend(infer_topic[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d46df0fa-1e3a-4335-ba8f-1b7b928e6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp = []\n",
    "for key in data2topic:\n",
    "    if len(set(data2topic[key])) > 1:\n",
    "        ppp.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "717056f8-d40b-405c-8b96-4b3be97a83f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('为了一件三万八的婚纱和准老公吵翻了，我错了吗？',\n",
       " [['情感', 1],\n",
       "  ['婚姻', 0.36588355898857117],\n",
       "  ['两性', 0.1815391480922699],\n",
       "  ['情感', 0.14907318353652954],\n",
       "  ['人际交往', 0.14164099097251892],\n",
       "  ['心理健康', 0.056371260434389114]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 49\n",
    "ppp[index], data2topic[ppp[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a999ce-2e2f-444d-ba17-48a888f5d379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2071401it [01:03, 32773.18it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.topic.knn.final', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.topic.knn') as frobj:\n",
    "        for line in tqdm(frobj):\n",
    "            content = json.loads(line.strip())\n",
    "            tmp = {\n",
    "                'text':content['text'],\n",
    "                'label':content['topic']\n",
    "            }\n",
    "            if content['topic_knn']:\n",
    "                tmp['old_label'] = tmp['label']\n",
    "                tmp['label'] = [content['topic_knn'][0][0]]\n",
    "            else:\n",
    "                tmp['old_label'] = tmp['label']\n",
    "            fwobj.write(json.dumps(tmp, ensure_ascii=False)+'\\n')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1511d884-b1f5-4091-a067-c01a50332237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "86668it [00:01, 84776.83it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm \n",
    "data2topic = {}\n",
    "t = 0\n",
    "alter = 0\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_valid.json.topic.knn') as frobj:\n",
    "    for line in tqdm(frobj):\n",
    "        content = json.loads(line.strip())\n",
    "        if content['text'] not in data2topic:\n",
    "            data2topic[content['text']] = []\n",
    "        \n",
    "        if content['topic_knn']:\n",
    "            data2topic[content['text']] = content['topic_knn'][0][0]\n",
    "            if content['topic'][0] != content['topic_knn'][0][0]:\n",
    "                alter += 1\n",
    "        else:\n",
    "            data2topic[content['text']] = content['topic'][0]\n",
    "            t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c533a30-9637-4d8b-ad99-d443cd8d03c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1972773it [01:20, 24414.35it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm \n",
    "data2topic = {}\n",
    "t = 0\n",
    "alter = 0\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v5/biake_qa_web_text_zh_train.json.knn') as frobj:\n",
    "    for line in tqdm(frobj):\n",
    "        content = json.loads(line.strip())\n",
    "        if content['text'] not in data2topic:\n",
    "            data2topic[content['text']] = []\n",
    "        \n",
    "        if content['topic_knn']:\n",
    "            data2topic[content['text']] = content['topic_knn'][0][0]\n",
    "            if content['label'][0] != content['topic_knn'][0][0]:\n",
    "                alter += 1\n",
    "        else:\n",
    "            data2topic[content['text']] = content['label'][0]\n",
    "            t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b4bb5ad7-28a8-425b-b795-7c4df02b0cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307147, 7358)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alter, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5abe202-ffae-425f-984a-c3e0650b021f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1972773it [01:27, 22435.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm \n",
    "data_list = []\n",
    "t = 0\n",
    "alter = 0\n",
    "confuse1 = []\n",
    "confuse2 = []\n",
    "confuse3 = []\n",
    "confuse4 = []\n",
    "confuse5 = []\n",
    "confuse6 = []\n",
    "confuse7 = []\n",
    "data2topic = {}\n",
    "\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v5/biake_qa_web_text_zh_train.json.knn') as frobj:\n",
    "    for line in tqdm(frobj):\n",
    "        content = json.loads(line.strip())\n",
    "        if content['text'] not in data2topic:\n",
    "            data2topic[content['text']] = set()\n",
    "        \n",
    "        if content['topic_knn']:\n",
    "            if len(content['topic_knn']) == 1:\n",
    "                if content['topic_knn'][0][0] != content['label'][0]:\n",
    "                    if content['topic_knn'][0][1] >= 2:\n",
    "                        confuse1.append(content['text'])\n",
    "                    else:\n",
    "                        confuse2.append(content['text'])\n",
    "                else:\n",
    "                    confuse3.append(content['text'])\n",
    "            elif len(content['topic_knn']) >= 2:\n",
    "                max_ratio = content['topic_knn'][0][1] / sum([item[1] for item in content['topic_knn']])\n",
    "                if max_ratio > 1/len(content['topic_knn']):\n",
    "                    if content['topic_knn'][0][1] > content['topic_knn'][1][1]:\n",
    "                        confuse4.append(content['text'])\n",
    "                    else:\n",
    "                        confuse5.append(content['text'])\n",
    "                else:\n",
    "                    confuse6.append(content['text'])\n",
    "        else:\n",
    "            confuse7.append(content['text'])\n",
    "            t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "682bb8e2-f5e5-4c81-bf71-97f2e9bbe28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7358, 133844, 46519, 997428, 787188, 357, 79)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(confuse7), len(confuse6), len(confuse5), len(confuse4), len(confuse3), len(confuse2), len(confuse1), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2695bd3a-f24e-436a-be01-7e0da95acf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['为何最近一年间堺雅人突然就这么火了？',\n",
       " '火影中有哪些不经意间触动了你的台词？',\n",
       " '怎么死心，舍不得，但是怎么让自己死心？?',\n",
       " '如何从本源来着手周易入门？',\n",
       " '如何看待大学cs专业学生放弃基础课程学技术？',\n",
       " '女孩的相貌到底有多重要？',\n",
       " '怎样判断自己的年幼女儿是否被性侵了？',\n",
       " '如果让你去当一回MOBA游戏的设计师，你会设计什么英雄？',\n",
       " '问答社区上，月收入超过1万元的人士从事的是什么工作？',\n",
       " '给亲戚的小孩补课，我应该收钱吗？']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse5[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56251c86-d90f-4d83-9f31-a793efa85455",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "import re\n",
    "with open('/data/albert.xht/xiaodao/topic_classification_v7/biake_qa_web_text_zh_train.json.positive') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        if re.search('如何评价', content['text']):\n",
    "            data_list.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8cde061f-67d9-44e1-938d-3654bd827ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1973027it [01:43, 19088.07it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v5/biake_qa_web_text_zh_train.json.knn.final', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/topic_classification_v5/biake_qa_web_text_zh_train.json.knn') as frobj:\n",
    "        for line in tqdm(frobj):\n",
    "            content = json.loads(line.strip())\n",
    "            \n",
    "            tmp = {\n",
    "                'text':content['text'],\n",
    "                'label':content['label']\n",
    "            }\n",
    "            if content['topic_knn']:\n",
    "                tmp['old_label'] = tmp['label']\n",
    "                tmp['label'] = [content['topic_knn'][0][0]]\n",
    "            else:\n",
    "                tmp['old_label'] = tmp['label']\n",
    "            fwobj.write(json.dumps(tmp, ensure_ascii=False)+'\\n')\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba68d60-a9e8-4eb6-91cd-b9b63876830e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1973027it [01:45, 18635.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v5/biake_qa_web_text_zh_train.json.knn.final.partial', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/topic_classification_v5/biake_qa_web_text_zh_train.json.knn') as frobj:\n",
    "        for line in tqdm(frobj):\n",
    "            content = json.loads(line.strip())\n",
    "            tmp = {\n",
    "                'text':content['text'],\n",
    "                'label':content['label'],\n",
    "                'partial_label':[],\n",
    "                'partial_ratio':[]\n",
    "            }\n",
    "            if content['topic_knn']:\n",
    "                for topic in content['topic_knn'][:5]:\n",
    "                    if topic[0] not in tmp['partial_label']:\n",
    "                        tmp['partial_label'].append(topic[0])\n",
    "                        tmp['partial_ratio'].append(topic[1])\n",
    "            fwobj.write(json.dumps(tmp, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72db3f5-cef7-4c68-b1b2-b882fccfcf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1973027it [00:09, 213107.72it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v5/biake_qa_web_text_zh_train.json.knn.final.test', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/topic_classification_v5/biake_qa_web_text_zh_train.json.knn.final') as frobj:\n",
    "        for line in tqdm(frobj):\n",
    "            content = json.loads(line.strip())\n",
    "            if content['label'][0] in ['旅游']:\n",
    "                fwobj.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f9c709bd-6853-4b96-8936-788ac2c838f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.102127075195312"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1972773/65536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5e90a46-8fdf-410d-9a7f-60898c415162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'风险': 531, '正常': 13082}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pppp = {}\n",
    "for d in data_list:\n",
    "    if d['label'][0] not in pppp:\n",
    "        pppp[d['label'][0]] = 0\n",
    "    pppp[d['label'][0]] += 1\n",
    "pppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "565cd6a6-3565-43c2-9ee7-8b242ee6e162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "86668it [00:01, 56709.18it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_valid.json.topic.knn.final', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_valid.json.topic.knn') as frobj:\n",
    "        for line in tqdm(frobj):\n",
    "            content = json.loads(line.strip())\n",
    "            tmp = {\n",
    "                'text':content['text'],\n",
    "                'label':content['topic']\n",
    "            }\n",
    "            if content['topic_knn']:\n",
    "                tmp['old_label'] = tmp['label']\n",
    "                tmp['label'] = [content['topic_knn'][0][0]]\n",
    "            else:\n",
    "                tmp['old_label'] = tmp['label']\n",
    "            fwobj.write(json.dumps(tmp, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5f21c4-ff15-412d-97f6-fe75ea384998",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
