{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c24b51-0baf-4855-baac-3ee4010c944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys,os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ff23bc-1588-42e5-959e-a45d4b3d7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.extend(['/root/xiaoda/query_topic/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25da71ce-1bec-4327-acd7-c3dd78414f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "https://github.com/ondrejbohdal/meta-calibration/blob/main/Metrics/metrics.py\n",
    "\"\"\"\n",
    "\n",
    "class ECE(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(ECE, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels, mode='logits'):\n",
    "        if mode == 'logits':\n",
    "            softmaxes = F.softmax(logits, dim=1)\n",
    "        else:\n",
    "            softmaxes = logits\n",
    "        # softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        \n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cbfd143-9337-4fea-aad8-cf2851192471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senti_query /root/xiaoda/query_topic/risk_data_v5/senti_query_label.txt ===schema-path===\n",
      "{'label2id': {'负向': 0, '中性': 1, '正向': 2}, 'id2label': {0: '负向', 1: '中性', 2: '正向'}, 'label_index': 0} ==schema_type== senti_query\n",
      "senti /root/xiaoda/query_topic/risk_data_v5/senti_label.txt ===schema-path===\n",
      "{'label2id': {'负向': 0, '正向': 1}, 'id2label': {0: '负向', 1: '正向'}, 'label_index': 1} ==schema_type== senti\n",
      "bias /root/xiaoda/query_topic/risk_data_v5/bias_label.txt ===schema-path===\n",
      "{'label2id': {'偏见': 0, '正常': 1}, 'id2label': {0: '偏见', 1: '正常'}, 'label_index': 2} ==schema_type== bias\n",
      "ciron /root/xiaoda/query_topic/risk_data_v5/ciron_label.txt ===schema-path===\n",
      "{'label2id': {'讽刺': 0, '正常': 1}, 'id2label': {0: '讽刺', 1: '正常'}, 'label_index': 3} ==schema_type== ciron\n",
      "intent /root/xiaoda/query_topic/risk_data_v5/intention_label_v0.txt ===schema-path===\n",
      "{'label2id': {'主观评价/比较/判断': 0, '寻求建议/帮助': 1, '其它': 2}, 'id2label': {0: '主观评价/比较/判断', 1: '寻求建议/帮助', 2: '其它'}, 'label_index': 4} ==schema_type== intent\n",
      "offensive /root/xiaoda/query_topic/risk_data_v5/offensive_label.txt ===schema-path===\n",
      "{'label2id': {'冒犯': 0, '正常': 1}, 'id2label': {0: '冒犯', 1: '正常'}, 'label_index': 5} ==schema_type== offensive\n",
      "query_risk /root/xiaoda/query_topic/risk_data_v5/query_risk_label.txt ===schema-path===\n",
      "{'label2id': {'风险': 0, '个人信息': 1, '正常': 2}, 'id2label': {0: '风险', 1: '个人信息', 2: '正常'}, 'label_index': 6} ==schema_type== query_risk\n",
      "teenager /root/xiaoda/query_topic/risk_data_v5/teenager_label.txt ===schema-path===\n",
      "{'label2id': {'不良': 0, '正常': 1}, 'id2label': {0: '不良', 1: '正常'}, 'label_index': 7} ==schema_type== teenager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "01/04/2023 09:17:22 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizerFast\n",
    "import transformers\n",
    "from datetime import timedelta\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from nets.them_classifier import MyBaseModel, RobertaClassifier\n",
    "\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "\n",
    "cur_dir_path = '/root/xiaoda/query_topic/'\n",
    "\n",
    "def load_label(filepath):\n",
    "    label_list = []\n",
    "    with open(filepath, 'r') as frobj:\n",
    "        for line in frobj:\n",
    "            label_list.append(line.strip())\n",
    "        n_classes = len(label_list)\n",
    "\n",
    "        label2id = {}\n",
    "        id2label = {}\n",
    "        for idx, label in enumerate(label_list):\n",
    "            label2id[label] = idx\n",
    "            id2label[idx] = label\n",
    "        return label2id, id2label\n",
    "\n",
    "class RiskInfer(object):\n",
    "    def __init__(self, config_path):\n",
    "\n",
    "        import torch, os, sys\n",
    "\n",
    "        con = configparser.ConfigParser()\n",
    "        con_path = os.path.join(cur_dir_path, config_path)\n",
    "        con.read(con_path, encoding='utf8')\n",
    "\n",
    "        args_path = dict(dict(con.items('paths')), **dict(con.items(\"para\")))\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(args_path[\"model_path\"], do_lower_case=True)\n",
    "\n",
    "        from collections import OrderedDict\n",
    "        self.schema_dict = OrderedDict({})\n",
    "\n",
    "        for label_index, schema_info in enumerate(args_path[\"label_path\"].split(',')):\n",
    "            schema_type, schema_path = schema_info.split(':')\n",
    "            schema_path = os.path.join(cur_dir_path, schema_path)\n",
    "            print(schema_type, schema_path, '===schema-path===')\n",
    "            label2id, id2label = load_label(schema_path)\n",
    "            self.schema_dict[schema_type] = {\n",
    "                'label2id':label2id,\n",
    "                'id2label':id2label,\n",
    "                'label_index':label_index\n",
    "            }\n",
    "            print(self.schema_dict[schema_type], '==schema_type==', schema_type)\n",
    "        \n",
    "        output_path = os.path.join(cur_dir_path, args_path['output_path'])\n",
    "\n",
    "        from roformer import RoFormerModel, RoFormerConfig\n",
    "\n",
    "        config = RoFormerConfig.from_pretrained(args_path[\"model_path\"])\n",
    "        encoder = RoFormerModel(config=config)\n",
    "        \n",
    "        encoder_net = MyBaseModel(encoder, config)\n",
    "\n",
    "        self.device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        classifier_list = []\n",
    "\n",
    "        schema_list = list(self.schema_dict.keys())\n",
    "\n",
    "        for schema_key in schema_list:\n",
    "            classifier = RobertaClassifier(\n",
    "                hidden_size=config.hidden_size, \n",
    "                dropout_prob=con.getfloat('para', 'out_dropout_rate'),\n",
    "                num_labels=len(self.schema_dict[schema_key]['label2id']), \n",
    "                dropout_type=con.get('para', 'dropout_type'))\n",
    "            classifier_list.append(classifier)\n",
    "\n",
    "        classifier_list = nn.ModuleList(classifier_list)\n",
    "\n",
    "        class MultitaskClassifier(nn.Module):\n",
    "            def __init__(self, transformer, classifier_list):\n",
    "                super().__init__()\n",
    "\n",
    "                self.transformer = transformer\n",
    "                self.classifier_list = classifier_list\n",
    "\n",
    "            def forward(self, input_ids, input_mask, \n",
    "                        segment_ids=None, \n",
    "                        transformer_mode='mean_pooling', \n",
    "                        dt_idx=None):\n",
    "                hidden_states = self.transformer(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              return_mode=transformer_mode)\n",
    "                outputs_list = []\n",
    "                \n",
    "                for idx, classifier in enumerate(self.classifier_list):\n",
    "                    \n",
    "                    if dt_idx is not None and idx != dt_idx:\n",
    "                        continue\n",
    "                    \n",
    "                    ce_logits = classifier(hidden_states)\n",
    "                    outputs_list.append(ce_logits)\n",
    "                return outputs_list, hidden_states\n",
    "\n",
    "        self.net = MultitaskClassifier(encoder_net, classifier_list).to(self.device)\n",
    "\n",
    "        # eo = 9\n",
    "        # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw.focal'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_contrast_cls.pth.{}'.format(eo)), map_location=self.device)\n",
    "        # self.net.load_state_dict(ckpt)\n",
    "        # self.net.eval()\n",
    "        \n",
    "    def reload(self, model_path):\n",
    "        ckpt = torch.load(model_path, map_location=self.device)\n",
    "        self.net.load_state_dict(ckpt)\n",
    "        self.net.eval()\n",
    "\n",
    "    def predict(self, text):\n",
    "\n",
    "        \"\"\"抽取输入text所包含的类型\n",
    "        \"\"\"\n",
    "        encoder_txt = self.tokenizer.encode_plus(text, max_length=256)\n",
    "        input_ids = torch.tensor(encoder_txt[\"input_ids\"]).long().unsqueeze(0).to(self.device)\n",
    "        token_type_ids = torch.tensor(encoder_txt[\"token_type_ids\"]).unsqueeze(0).to(self.device)\n",
    "        attention_mask = torch.tensor(encoder_txt[\"attention_mask\"]).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        scores_dict = {}\n",
    "        with torch.no_grad():\n",
    "            [logits_list, \n",
    "            hidden_states] = self.net(input_ids, \n",
    "                attention_mask, token_type_ids, transformer_mode='cls')\n",
    "        for schema_type, logits in zip(list(self.schema_dict.keys()), logits_list):\n",
    "            scores = torch.nn.Softmax(dim=1)(logits)[0].data.cpu().numpy()\n",
    "            scores_dict[schema_type] = []\n",
    "            for index, score in enumerate(scores):\n",
    "                scores_dict[schema_type].append([self.schema_dict[schema_type]['id2label'][index], \n",
    "                                        float(score)])\n",
    "        return scores_dict\n",
    "    \n",
    "    def get_logitnorm(self, text):\n",
    "        \"\"\"抽取输入text所包含的类型\n",
    "        \"\"\"\n",
    "        encoder_txt = self.tokenizer.encode_plus(text, max_length=256)\n",
    "        input_ids = torch.tensor(encoder_txt[\"input_ids\"]).long().unsqueeze(0).to(self.device)\n",
    "        token_type_ids = torch.tensor(encoder_txt[\"token_type_ids\"]).unsqueeze(0).to(self.device)\n",
    "        attention_mask = torch.tensor(encoder_txt[\"attention_mask\"]).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        scores_dict = {}\n",
    "        logits_norm_list = []\n",
    "        with torch.no_grad():\n",
    "            [logits_list, \n",
    "            hidden_states] = self.net(input_ids, \n",
    "                attention_mask, token_type_ids, transformer_mode='cls')\n",
    "            for logits in logits_list:\n",
    "                logits_norm_list.append(logits/torch.norm(logits, p=2, dim=-1, keepdim=True) + 1e-7)\n",
    "        for schema_type, logit_norm in zip(list(self.schema_dict.keys()), logits_norm_list):\n",
    "            scores_dict[schema_type] = logit_norm[0].data.cpu().numpy()\n",
    "        return scores_dict\n",
    "            \n",
    "    \n",
    "    def predict_batch(self, text):\n",
    "        if isinstance(text, list):\n",
    "            text_list = text\n",
    "        else:\n",
    "            text_list = [text]\n",
    "        model_input = self.tokenizer(text_list, return_tensors=\"pt\",padding=True)\n",
    "        for key in model_input:\n",
    "            model_input[key] = model_input[key].to(self.device)\n",
    "        with torch.no_grad():\n",
    "            [logits_list, \n",
    "            hidden_states] = self.net(model_input['input_ids'], \n",
    "                model_input['attention_mask'], \n",
    "                model_input['token_type_ids'], transformer_mode='cls')\n",
    "        score_dict_list = []\n",
    "        for idx, text in enumerate(text_list):\n",
    "            scores_dict = {}\n",
    "            for schema_type, logits in zip(list(self.schema_dict.keys()), logits_list):\n",
    "                scores = torch.nn.Softmax(dim=1)(logits)[idx].data.cpu().numpy()\n",
    "                scores_dict[schema_type] = []\n",
    "                for index, score in enumerate(scores):\n",
    "                    scores_dict[schema_type].append([self.schema_dict[schema_type]['id2label'][index], \n",
    "                                            float(score)])\n",
    "            score_dict_list.append(scores_dict)\n",
    "        return score_dict_list\n",
    "\n",
    "# risk_api = RiskInfer('./risk_data/config.ini')\n",
    "risk_api = RiskInfer('./risk_data_v5/config.ini')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fad1e25-e3e7-4440-a3b9-4fb290a3a8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9965"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "l = 0\n",
    "reader = csv.reader(open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/Query风险分类_全部数据.csv'), delimiter=\"\\t\", quotechar=None)\n",
    "for idx, item in enumerate(reader):\n",
    "    # print(item)\n",
    "    l += 1\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf80f7-c2d9-4bda-80e6-c2c95245d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/albert.xht/pretrained_model_risk/corpus/efaqa-corpus-zh/efaqa-corpus-zh.utf8\", \"r\") as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        title = ''.join(re.split('[\\s,]', content['title'])[1:])\n",
    "        if len(title) >= 5:\n",
    "            if  s3_mapping[content['label']['s3']] in ['正在进行的自杀行为', '策划进行的自杀行为', '自残']:\n",
    "                tmp = {\n",
    "                    'title':title,\n",
    "                    'label':['风险']\n",
    "                }\n",
    "                print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb6923a2-fe55-4610-bf75-36fe3a90dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v5_intent_v2_3/multitask_cls.pth.4')\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v5_intent_v2-1_3//multitask_cls.pth.4')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v6_intent_v2-1_10/multitask_cls.pth.6')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v6_intent_v2-1_10_no_symbol/multitask_cls.pth.5')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/risk_classification/multitask_raw_filter_senti_query_risk_v7_intent_v2-1_10_no_symbol/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v8_intent_v2-1_10_no_symbol/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v8_intent_v2-1_10_no_symbol_v1/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v9_intent_v2-1_10_no_symbol_v1/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v10_intent_v2-1_10_no_symbol_senti_query_senta_balanced_logitclip/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v10_intent_v2-1_10_no_symbol_senti_query_senta_balanced_logitclip_v1/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v11_intent_v2-1_10_no_symbol_senti_query_senta_balanced_v1/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_balanced_v1/multitask_cls.pth.8')\n",
    "\n",
    "risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v12_intent_v2-1_10_no_symbol_senti_query_senta_balanced_v2/')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v6_no_offensive_intent_v2-1_10//multitask_cls.pth.6')\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v5_no_offensive_intent_v2-1_3/multitask_cls.pth.4')\n",
    "\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d055c9c7-e1ca-4e2e-89dd-c1a6f193da4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'senti_query': [['负向', 0.756915271282196],\n",
       "  ['中性', 0.20392245054244995],\n",
       "  ['正向', 0.039162278175354004]],\n",
       " 'senti': [['负向', 0.9995278120040894], ['正向', 0.00047222699504345655]],\n",
       " 'bias': [['偏见', 0.9707301259040833], ['正常', 0.029269874095916748]],\n",
       " 'ciron': [['讽刺', 0.8651314973831177], ['正常', 0.13486848771572113]],\n",
       " 'intent': [['主观评价/比较/判断', 0.06287194788455963],\n",
       "  ['寻求建议/帮助', 0.13903510570526123],\n",
       "  ['其它', 0.7980930209159851]],\n",
       " 'offensive': [['冒犯', 0.12341342121362686], ['正常', 0.8765866160392761]],\n",
       " 'query_risk': [['风险', 0.5953889489173889],\n",
       "  ['个人信息', 5.400699228630401e-05],\n",
       "  ['正常', 0.4045570194721222]],\n",
       " 'teenager': [['不良', 0.8138567805290222], ['正常', 0.18614326417446136]]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_api.predict('唉成都又出猛女了成都一名26岁女司机无证驾驶连闯红灯还')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a016e9d-7b74-40e4-b7e9-159a2be0a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_inference(input_path, output_path):\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "    import json, re\n",
    "\n",
    "    def risk_predict_batch(text):\n",
    "        if isinstance(text, list):\n",
    "            text_list = text\n",
    "        else:\n",
    "            text_list = [text]\n",
    "        result_list = risk_api.predict_batch(text_list)\n",
    "        return result_list\n",
    "    \n",
    "    print(input_path, '===input-path===')\n",
    "    print(output_path, '===output-path===')\n",
    "    \n",
    "    with open(output_path, 'w') as fwobj:\n",
    "        with open(input_path, 'r') as frobj:\n",
    "            queue = []\n",
    "            t = []\n",
    "            for line in tqdm(frobj):\n",
    "                content = json.loads(line.strip())\n",
    "                content['text'] = re.sub('请问', '', content['text'])\n",
    "                text = re.sub(r\"([，\\_《。》、？；：‘’＂“”【「】」·！@￥…（）—\\,\\<\\.\\>\\/\\?\\;\\:\\'\\\"\\[\\]\\{\\}\\~\\`\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\-\\=\\+])+\", \"\", content['text'])   # 合并正文中过多的空格\n",
    "                queue.append(text)\n",
    "                t.append(content)\n",
    "                if np.mod(len(queue), 128) == 0:\n",
    "                    probs = risk_predict_batch(queue)\n",
    "                    for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                        content = {\n",
    "                            'text':tt['text'],\n",
    "                            'topic':tt['label'],\n",
    "                            'score_list':prob_dict,\n",
    "                            # 'score_list': tt['score_list']\n",
    "                        }\n",
    "                        fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                    queue = []\n",
    "                    t = []\n",
    "            if queue:\n",
    "                probs = risk_predict_batch(queue)\n",
    "                for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                    content = {\n",
    "                        'text':tt['text'],\n",
    "                        'topic':tt['label'],\n",
    "                        'score_list':prob_dict,\n",
    "                        # 'score_list': tt['score_list']\n",
    "                    }\n",
    "                    fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0811b54-62f5-4990-a06b-13d041acf824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [00:00, 1057.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/albert.xht/xiaodao/topic_classification_v7/biake_qa_web_text_zh_train.json.positive.topic ===input-path===\n",
      "/data/albert.xht/xiaodao/topic_classification_v7/biake_qa_web_text_zh_train.json.positive.topic.v10 ===output-path===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25507it [00:23, 1074.57it/s]\n"
     ]
    }
   ],
   "source": [
    "input_path = '/data/albert.xht/xiaodao/topic_classification_v7/biake_qa_web_text_zh_train.json.positive.topic'\n",
    "output_path = '/data/albert.xht/xiaodao/topic_classification_v7/biake_qa_web_text_zh_train.json.positive.topic.v10'\n",
    "\n",
    "\n",
    "batch_inference(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e1f1486-5ed6-4dbd-bc85-8b4f2c3076f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [00:00, 1055.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/albert.xht/raw_chat_corpus/topic_classification_v4/embed_linear_small_white.json.topic ===input-path===\n",
      "/data/albert.xht/raw_chat_corpus/topic_classification_v4/embed_linear_small_white.json.topic.v10 ===output-path===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23116it [00:21, 1058.94it/s]\n"
     ]
    }
   ],
   "source": [
    "input_path = '/data/albert.xht/raw_chat_corpus/topic_classification_v4/embed_linear_small_white.json.topic'\n",
    "output_path = '/data/albert.xht/raw_chat_corpus/topic_classification_v4/embed_linear_small_white.json.topic.v10'\n",
    "\n",
    "\n",
    "batch_inference(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d6428-d95b-4353-9461-5220d76d5367",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.topic.knn.final'\n",
    "output_path = '/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk.v9.1'\n",
    "\n",
    "\n",
    "batch_inference(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbe1dff7-d2dc-4e9b-9386-ebdfec9e4dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.topic.knn.final ===input-path===\n",
      "/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk.v9.1 ===output-path===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2071401it [45:32, 758.09it/s]\n"
     ]
    }
   ],
   "source": [
    "input_path = '/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.topic.knn.final'\n",
    "output_path = '/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk.v9.1'\n",
    "\n",
    "\n",
    "batch_inference(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "884a652d-e1a0-4702-bd2b-979c4e0890e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [00:00, 959.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/albert.xht/xiaodao/query_risk_v10/biake_qa_web_text_zh_train.json.offensive.all ===input-path===\n",
      "/data/albert.xht/xiaodao/query_risk_v10/biake_qa_web_text_zh_train.json.offensive.all.v10.1 ===output-path===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18456it [00:17, 1072.16it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_path = '/data/albert.xht/xiaodao/query_risk_v10/biake_qa_web_text_zh_train.json.offensive.all'\n",
    "output_path = '/data/albert.xht/xiaodao/query_risk_v10/biake_qa_web_text_zh_train.json.offensive.all.v10.1'\n",
    "\n",
    "batch_inference(input_path, output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78f5eed3-f87a-4751-b53c-749b38682441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2071401it [04:34, 7542.81it/s] \n"
     ]
    }
   ],
   "source": [
    "black = []\n",
    "white = []\n",
    "import fast_json as json\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(output_path) as frobj:\n",
    "    for line in tqdm(frobj):\n",
    "        content = json.loads(line.strip())\n",
    "        if content['score_list']['query_risk'][0][1] > 0.5:\n",
    "            black.append(content)\n",
    "        else:\n",
    "            white.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62e47994-6552-42ee-85ba-335f5e5a90dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177560"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c8dd8ee-2986-4425-825f-3704c128264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_v1 = []\n",
    "black_white = []\n",
    "for d in black:\n",
    "    if d['score_list']['query_risk'][0][1] > 0.9:\n",
    "        black_v1.append(d)\n",
    "    else:\n",
    "        black_white.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "35798b55-7821-41d2-9ac0-7edd91a22899",
   "metadata": {},
   "outputs": [],
   "source": [
    "sssss = []\n",
    "for d in black_white:\n",
    "    p = []\n",
    "    for key in ['senti', 'offensive', 'teenager', 'senti_query', 'senti_query']:\n",
    "        if d['score_list'][key][0][1] < 0.3:\n",
    "            p.append(1)\n",
    "        else:\n",
    "            p.append(0)\n",
    "    if d['score_list']['query_risk'][0][1] < 0.3:\n",
    "        p.append(1)\n",
    "    else:\n",
    "        p.append(0)\n",
    "    if d['score_list']['query_risk'][1][1] < 0.3:\n",
    "        p.append(1)\n",
    "    else:\n",
    "        p.append(0)\n",
    "    if sum(p) >= 5:\n",
    "        sssss.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "499da36d-19c5-41ad-954f-05691be9a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk.v9.1.black', 'w') as fwobj:\n",
    "    for d in black_v1:\n",
    "        content = copy(d)\n",
    "        lssslsl = content.pop('score_list')\n",
    "        content['label'] = ['风险']\n",
    "        fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ad4b5-55e5-4032-b2b7-4b89657f4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "    for d in white:\n",
    "        if d['topic'][0] not in data_dict:\n",
    "            data_dict[d['topic'][0]] = []\n",
    "        data_dict[d['topic'][0]].append(d)\n",
    "    train_sample = []\n",
    "    import random\n",
    "    for key in data_dict:\n",
    "        random.shuffle(data_dict[key])\n",
    "        train_sample.extend(data_dict[key][:int(0.15*len(data_dict[key]))])\n",
    "        \n",
    "    from copy import copy\n",
    "    for d in tqdm(train_sample):\n",
    "        content = d.copy()\n",
    "        if content['topic'][0] in ['死亡', '毒品', '恐怖主义', '战争', '灵异事件', \n",
    "                                   '色情', '灵异灵修', 'LGBT', 'BDSM', '性侵犯', '性骚扰']:\n",
    "            continue\n",
    "        if content['topic'][0] in ['法律']:\n",
    "            if d['score_list']['senti'][0][1] < 0.5 and d['score_list']['offensive'][0][1] < 0.5:\n",
    "                content['label'] = ['正常']\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            content['label'] = ['正常']\n",
    "        p = content.pop('score_list')\n",
    "        content['source'] = 'query_white'\n",
    "        fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03c03fbc-34dd-4b7e-89dd-f3b4b224a273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97158/97158 [00:00<00:00, 297035.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "with open('/data/albert.xht/xiaodao/topic_classification_v7/biake_qa_web_text_zh_train.json.positive.v8', 'w') as fwobj:\n",
    "    ppp = 0\n",
    "    for d in tqdm(black_white):\n",
    "        # if d['score_list']['senti_query'][-1][1] >= 0.8 and d['score_list']['senti'][-1][1] >= 0.8:\n",
    "            # if d['topic'][0] in ['军事', '时事政治', '历史', '国家', '社会', '法律', '色情']:\n",
    "            #     continue\n",
    "            # if d['topic'][0] in [ '色情']:\n",
    "            #     continue\n",
    "        if d['topic'][0] in ['学习', '时尚', '宠物', '娱乐', '校园生活', '电子数码', '动漫']:\n",
    "            content = d.copy()\n",
    "            _del = content.pop('score_list')\n",
    "            fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "#                 else:\n",
    "#                     continue\n",
    "#             fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "        \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8a9e3081-3327-4522-a309-908bc73666cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_dict = {}\n",
    "from collections import Counter\n",
    "t = Counter()\n",
    "for d in white:\n",
    "    t[d['topic'][0]] += 1\n",
    "    if d['topic'][0] not in white_dict:\n",
    "        white_dict[d['topic'][0]] = []\n",
    "    white_dict[d['topic'][0]].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0cb75500-586b-4352-b25a-2626f8ff490e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'senti_query': [['负向', 0.007037341594696045],\n",
       "  ['中性', 0.2305670976638794],\n",
       "  ['正向', 0.7623955607414246]],\n",
       " 'senti': [['负向', 0.05454050004482269], ['正向', 0.9454594850540161]],\n",
       " 'bias': [['偏见', 0.026843402534723282], ['正常', 0.9731566309928894]],\n",
       " 'ciron': [['讽刺', 0.032426558434963226], ['正常', 0.9675734043121338]],\n",
       " 'intent': [['主观评价/比较/判断', 0.16399823129177094],\n",
       "  ['寻求建议/帮助', 0.2048383355140686],\n",
       "  ['其它', 0.631163477897644]],\n",
       " 'offensive': [['冒犯', 0.06728868931531906], ['正常', 0.9327113628387451]],\n",
       " 'query_risk': [['风险', 0.02225596271455288],\n",
       "  ['个人信息', 0.004046468064188957],\n",
       "  ['正常', 0.9736975431442261]],\n",
       " 'teenager': [['不良', 0.009918730705976486], ['正常', 0.990081250667572]]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_api.predict('说的好。亚洲人在那里也属于,少数族裔，但是被压迫的不行了')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "67236c16-3d55-4b99-8e63-7966c02c0113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[unused1]', '后的数据规范环境', '[unused2]', 'gsdhkjsgaf', '[unused2]', '[SEP]']"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.split('(\\\\[unused\\d+\\\\])', '[unused1]后的数据规范环境[unused2]gsdhkjsgaf[unused2][SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "d5e48192-3ca8-4424-94f9-d48c9bbd3746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [], 'token_type_ids': [], 'attention_mask': []}"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_api.tokenizer('', add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "586e1d4e-17fb-43f6-8c6c-eb6bc4fd4b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50175it [00:49, 1023.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30620/4041987884.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrisk_predict_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mprob_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     content = {\n",
      "\u001b[0;32m/tmp/ipykernel_30620/4041987884.py\u001b[0m in \u001b[0;36mrisk_predict_batch\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mresult_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrisk_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_30620/3636409198.py\u001b[0m in \u001b[0;36mpredict_batch\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mscores_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mschema_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0mscores_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mschema_type\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         for hook in itertools.chain(\n\u001b[0m\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                 self._forward_hooks.values()):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json, re\n",
    "\n",
    "def risk_predict_batch(text):\n",
    "    if isinstance(text, list):\n",
    "        text_list = text\n",
    "    else:\n",
    "        text_list = [text]\n",
    "    result_list = risk_api.predict_batch(text_list)\n",
    "    return result_list\n",
    "\n",
    "# with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk', 'w') as fwobj:\n",
    "# with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk_v5', 'w') as fwobj:\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk_v10_logitclip', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json', 'r') as frobj:\n",
    "        queue = []\n",
    "        t = []\n",
    "        for line in tqdm(frobj):\n",
    "            content = json.loads(line.strip())\n",
    "            content['text'] = re.sub('请问', '', content['text'])\n",
    "            queue.append(content['text'])\n",
    "            t.append(content)\n",
    "            if np.mod(len(queue), 512) == 0:\n",
    "                probs = risk_predict_batch(queue)\n",
    "                for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                    content = {\n",
    "                        'text':text,\n",
    "                        'topic':tt['label'],\n",
    "                        'score_list':prob_dict\n",
    "                    }\n",
    "                    fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                queue = []\n",
    "                t = []\n",
    "        if queue:\n",
    "            probs = risk_predict_batch(queue)\n",
    "            for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                content = {\n",
    "                    'text':text,\n",
    "                    'topic':tt['label'],\n",
    "                    'score_list':prob_dict\n",
    "                }\n",
    "                fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7ee70904-41cf-4aa4-8ecd-86bbe3b4823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15414it [00:14, 1069.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json, re\n",
    "\n",
    "def risk_predict_batch(text):\n",
    "    if isinstance(text, list):\n",
    "        text_list = text\n",
    "    else:\n",
    "        text_list = [text]\n",
    "    result_list = risk_api.predict_batch(text_list)\n",
    "    return result_list\n",
    "\n",
    "offensive = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.offensive.all', 'r') as frobj:\n",
    "    queue = []\n",
    "    t = []\n",
    "    for line in tqdm(frobj):\n",
    "        content = json.loads(line.strip())\n",
    "        content['text'] = re.sub('请问', '', content['text'])\n",
    "        queue.append(content['text'])\n",
    "        t.append(content)\n",
    "        if np.mod(len(queue), 512) == 0:\n",
    "            probs = risk_predict_batch(queue)\n",
    "            for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                content = {\n",
    "                    'text':text,\n",
    "                    'topic':tt['label'],\n",
    "                    'score_list':prob_dict\n",
    "                }\n",
    "                offensive.append(content)\n",
    "            queue = []\n",
    "            t = []\n",
    "    if queue:\n",
    "        probs = risk_predict_batch(queue)\n",
    "        for prob_dict, text, tt in zip(probs, queue, t):\n",
    "            content = {\n",
    "                'text':text,\n",
    "                'topic':tt['label'],\n",
    "                'score_list':prob_dict\n",
    "            }\n",
    "            offensive.append(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bfdece-5835-4d7c-80bc-373d2698a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.white', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json', 'r') as frobj:\n",
    "        data_dict = {}\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['text'] not in data_dict:\n",
    "                data_dict[content['text']] = []\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f93dbbc3-5517-4736-8cf1-b3b57a771f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json, re\n",
    "\n",
    "def risk_predict_batch(text):\n",
    "    if isinstance(text, list):\n",
    "        text_list = text\n",
    "    else:\n",
    "        text_list = [text]\n",
    "    result_list = risk_api.predict_batch(text_list)\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de843f4c-6f21-485b-b31c-5925c1e743a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_api.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889bd0b-0c26-4c80-8a75-2d962c79dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json, re\n",
    "\n",
    "def risk_predict_batch(text):\n",
    "    if isinstance(text, list):\n",
    "        text_list = text\n",
    "    else:\n",
    "        text_list = [text]\n",
    "    result_list = risk_api.predict_batch(text_list)\n",
    "    return result_list\n",
    "\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.bias_ciron', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json', 'r') as frobj:\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['label'][0] not in data_dict:\n",
    "                data_dict[content['label'][0]] = []\n",
    "            data_dict[content['label'][0]].append(content)\n",
    "\n",
    "    train_sample = []\n",
    "    import random\n",
    "    for key in data_dict:\n",
    "        random.shuffle(data_dict[key])\n",
    "        train_sample.extend(data_dict[key][:int(0.2*len(data_dict[key]))])\n",
    "    cnt = 1\n",
    "    queue = []\n",
    "    for content in tqdm(train_sample):\n",
    "        content['text'] = re.sub('请问', '', content['text'])\n",
    "        queue.append(content['text'])\n",
    "        if np.mod(len(queue), 256) == 0:\n",
    "            probs = risk_predict_batch(queue)\n",
    "            for prob_dict, text in zip(probs, queue):\n",
    "                score_list = []\n",
    "                for key in ['bias', 'ciron', 'teenager']:\n",
    "                    if prob_dict[key][0][1] > 0.9:\n",
    "                        score_list.append([key, float(prob_dict[key][0][1])])\n",
    "                key = 'query_risk'\n",
    "                if prob_dict[key][0][1] > 0.9:\n",
    "                    score_list.append([prob_dict[key][0][0], float(prob_dict[key][0][1])])\n",
    "                if prob_dict[key][1][1] > 0.9:\n",
    "                    score_list.append([prob_dict[key][1][0], float(prob_dict[key][1][1])])\n",
    "                if score_list:\n",
    "                    content = {\n",
    "                        'text':text,\n",
    "                        'label':['风险'],\n",
    "                        'score_list':score_list\n",
    "                    }\n",
    "                    fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "            queue = []\n",
    "    if queue:\n",
    "        probs = risk_predict_batch(queue)\n",
    "        for prob_dict, text in zip(probs, queue):\n",
    "            score_list = []\n",
    "            for key in ['bias', 'ciron', 'teenager']:\n",
    "                if prob_dict[key][0][1] > 0.9:\n",
    "                    score_list.append([key, float(prob_dict[key][0][1])])\n",
    "            key = 'query_risk'\n",
    "            if prob_dict[key][0][1] > 0.9:\n",
    "                score_list.append([prob_dict[key][0][0], float(prob_dict[key][0][1])])\n",
    "            if prob_dict[key][1][1] > 0.9:\n",
    "                score_list.append([prob_dict[key][1][0], float(prob_dict[key][1][1])])\n",
    "\n",
    "            if score_list:\n",
    "                content = {\n",
    "                    'text':text,\n",
    "                    'label':['风险'],\n",
    "                    'score_list':score_list\n",
    "                }\n",
    "                fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c16ed0d4-d106-45f3-9c69-63174922ba16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['偏见', 0.4076650142669678]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dict[key][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "848ec613-e7bb-488d-ac31-1b3b4107e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_intent_v1/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_mtdnn_ce_256/multitask_cls.pth.9')\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_contrast_intent_v1/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256_20/multitask_cls.pth.19')\n",
    "\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/query_risk_v3/multitask_raw_filter_senti_query_risk_v3/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "922a1706-eca4-49ef-a30f-ff70903cb260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56443it [07:27, 126.13it/s]\n",
      "56443it [07:29, 125.59it/s]\n",
      "56443it [07:25, 126.73it/s]\n",
      "56443it [07:25, 126.60it/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = [\n",
    "'/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256/multitask_cls.pth.9',\n",
    "'/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_intent_v1/multitask_cls.pth.9',\n",
    "'/data/albert.xht/xiaodao/risk_classification/multitask_mtdnn_ce_256/multitask_cls.pth.9',\n",
    "'/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256_20/multitask_cls.pth.19',\n",
    "]\n",
    "\n",
    "from tqdm import tqdm\n",
    "total_result = []\n",
    "for model in model_path:\n",
    "    result_list = []\n",
    "    risk_api.reload(model)\n",
    "    with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/疑似有风险query_from对话预训练数据-20221130.txt') as frobj:\n",
    "        for line in tqdm(frobj):\n",
    "            text = line.strip()\n",
    "            result = risk_api.predict(text)\n",
    "            result_list.append((text, result))\n",
    "    total_result.append(result_list)\n",
    "\n",
    "result_matrix = []\n",
    "for i in range(len(total_result[0])):\n",
    "    p = []\n",
    "    for tmp in total_result:\n",
    "        item = tmp[i]\n",
    "        for key in ['senti', 'bias', 'ciron', 'offensive', 'teenager', 'query_risk']:\n",
    "            if item[1][key][0][1] > 0.6:\n",
    "                p.append(1)\n",
    "            else:\n",
    "                p.append(0)\n",
    "    result_matrix.append(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "730555ae-2ca3-4c8c-8a88-86e8ca26f4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a1ad192a-4cb4-46b9-8ae9-9620b9e2e3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56443it [08:00, 117.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "result_list = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/疑似有风险query_from对话预训练数据-20221130.txt') as frobj:\n",
    "    for line in tqdm(frobj):\n",
    "        text = line.strip()\n",
    "        result = risk_api.predict(text)\n",
    "        result_list.append((text, result))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "0c20e17f-6b80-4c13-ab5d-ca54f63c1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_matrix = []\n",
    "for item in result_list:\n",
    "    p = []\n",
    "    for key in ['senti', 'bias', 'ciron', 'offensive', 'teenager']:\n",
    "        if item[1][key][0][1] > 0.59:\n",
    "            p.append(1)\n",
    "        else:\n",
    "            p.append(0)\n",
    "    result_matrix.append(p)\n",
    "        \n",
    "        \n",
    "# result_matrix = []\n",
    "# for item in result_list:\n",
    "#     p = []\n",
    "#     for key in ['senti', 'bias', 'ciron', 'offensive', 'teenager', 'query_risk']:\n",
    "#         if item[1][key][0][1] >= 0.6:\n",
    "#             p.append(1)\n",
    "#         else:\n",
    "#             p.append(0)\n",
    "#     result_matrix.append(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "cb6c7ddd-52ea-481e-88a4-90a16ef8e4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36067"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_matrix = np.array(result_matrix)\n",
    "votes = np.sum(result_matrix, axis=-1)\n",
    "labels = np.array(votes >= 6).astype(np.int)\n",
    "sum(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "01825f5e-623c-4b7b-88e2-25a1d2da9278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56443, 2)\n",
      "(56443, 2)\n",
      "(56443, 2)\n",
      "(56443, 2)\n",
      "(56443, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "result_matrix = np.array(result_matrix)\n",
    "\n",
    "def SIMPLE(result_matrix):\n",
    "    votes = np.sum(result_matrix, axis=-1)\n",
    "    labels = np.array(votes >= 6).astype(np.int)\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0, ccp_alpha=0.1)\n",
    "    \n",
    "    for i in range(5):\n",
    "        result = clf.fit(result_matrix, labels)\n",
    "        probs = clf.predict_proba(result_matrix)\n",
    "        print(probs.shape)\n",
    "        labels = np.argmax(probs, axis=-1)\n",
    "    return probs\n",
    "\n",
    "\n",
    "probs = SIMPLE(result_matrix)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "7b11c013-2682-44a7-8891-676e2f417832",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = []\n",
    "clean = []\n",
    "for idx in range(probs.shape[0]):\n",
    "    if probs[idx,1] >= 0.8:\n",
    "        ff.append((idx, result_list[idx], probs[idx]))\n",
    "    else:\n",
    "        clean.append((idx, result_list[idx], probs[idx]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dffa0dcb-cebe-4e4b-99b3-502f0a605aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24721it [00:22, 1076.00it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/query_risk_corpus.json.risk', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/query_risk_corpus.json', 'r') as frobj:\n",
    "        queue = []\n",
    "        t = []\n",
    "        for line in tqdm(frobj):\n",
    "            content = json.loads(line.strip())\n",
    "            # content['text'] = re.sub('请问', '', content['text'])\n",
    "            queue.append(content['text'])\n",
    "            t.append(content)\n",
    "            if np.mod(len(queue), 512) == 0:\n",
    "                probs = risk_predict_batch(queue)\n",
    "                for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                    content = {\n",
    "                        'text':text,\n",
    "                        'topic':tt['label'],\n",
    "                        'score_list':prob_dict\n",
    "                    }\n",
    "                    fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                queue = []\n",
    "                t = []\n",
    "        if queue:\n",
    "            probs = risk_predict_batch(queue)\n",
    "            for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                content = {\n",
    "                    'text':text,\n",
    "                    'topic':tt['label'],\n",
    "                    'score_list':prob_dict\n",
    "                }\n",
    "                fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "7d8131b4-0222-4fd2-bf2f-70e9a664a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/query_risk_corpus.json', 'w') as fwobj:\n",
    "    for item in ff:\n",
    "        tmp = {\n",
    "            'text':item[1][0],\n",
    "            'label':['风险']\n",
    "        }\n",
    "        fwobj.write(json.dumps(tmp, ensure_ascii=False)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f2892662-d000-4901-a6c4-7db24e582c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = [] \n",
    "positive = []\n",
    "for item in result_list:\n",
    "    if item[1]['senti'][0][1] >= 0.7 or item[1]['bias'][0][1] >= 0.8 or item[1]['ciron'][0][1] >= 0.8 or item[1]['offensive'][0][1] >= 0.8:\n",
    "        candidate.append(item)\n",
    "    else:\n",
    "        positive.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e0f7dfb-0767-486b-9d82-394f3f01eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "offensive = []\n",
    "with open('/data/albert.xht/sentiment/dev/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive.append(content)\n",
    "        \n",
    "offensive_test = []\n",
    "with open('/data/albert.xht/sentiment/test/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive_test.append(content)\n",
    "\n",
    "        \n",
    "cdia_bias = []\n",
    "with open('/data/albert.xht/sentiment/dev/cdial_bias.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        cdia_bias.append(content)\n",
    "        \n",
    "senti_copr = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_copr.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_copr.append(content)\n",
    "        \n",
    "ciron = []\n",
    "with open('/data/albert.xht/sentiment/dev/chinese_ciron.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        ciron.append(content)\n",
    "\n",
    "senti_smp = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smp_usual.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smp.append(content)\n",
    "        \n",
    "senti_smpecisa = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smpecisa.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smpecisa.append(content)\n",
    "\n",
    "        \n",
    "senti_query = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_valid.json.filter.0.7') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_query.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56a49dd8-fe1a-4fae-b310-627ddf85ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def eval_all(data, model, key):\n",
    "    pred = []\n",
    "    gold = []\n",
    "    pred_score = []\n",
    "    for item in tqdm(data):\n",
    "        gold.append(item['label'][0])\n",
    "        if isinstance(item['text'], list):\n",
    "            text = \"\\n\".join(item['text'])\n",
    "        else:\n",
    "            text = item['text']\n",
    "        text = re.sub(r\"([，\\_《。》、？；：‘’＂“”【「】」·！@￥…（）—\\,\\<\\.\\>\\/\\?\\;\\:\\'\\\"\\[\\]\\{\\}\\~\\`\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\-\\=\\+])+\", \"\", text)   # 合并正文中过多的空格\n",
    "\n",
    "        result = model.predict(text)\n",
    "        score = sorted(result[key], key=lambda u:u[1], reverse=True)\n",
    "        pred.append(score[0][0])\n",
    "        pred_score.append(result[key])\n",
    "    print(classification_report(gold, pred, digits=4))\n",
    "    return pred, gold, pred_score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bef11639-006f-4482-a104-1fc2e8d1b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluation_ece(pred_score, gold):\n",
    "    pred_score_l = []\n",
    "    mapping_dict = {}\n",
    "    for item in pred_score:\n",
    "        pred_score_l.append([])\n",
    "        for idx, p in enumerate(item):\n",
    "            if p[0] not in mapping_dict:\n",
    "                mapping_dict[p[0]] = idx\n",
    "            pred_score_l[-1].append(p[1])\n",
    "    pred_score_l = torch.tensor(pred_score_l)\n",
    "    gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "\n",
    "    ece_fn = ECE(n_bins=15)\n",
    "    print(ece_fn(pred_score_l, gold_l, mode='probs'), '==ece==')\n",
    "# pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "# evaluation_ece(pred_score, gold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "794ca494-16bf-438b-b074-6413f0ef1fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'冒犯': 0, '正常': 1}\n",
      "tensor([0.1119]) ==ece==\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22222f61-41b9-463f-9e00-9f1068e5cee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['正常', 0.9768216013908386]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "181c5de9-6e52-4eaf-b83a-d56f7cd98ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3797b0ad-bfdb-4593-9ea4-a42c2ef8cda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'正常'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a0b3183-0619-4df4-8d4b-19b0c43e6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model_path):\n",
    "    risk_api.reload(model_path)\n",
    "    print('===offensive===')\n",
    "    pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===cdia-bias===')\n",
    "    pred, gold, pred_score = eval_all(cdia_bias, risk_api, 'bias')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===ciron===')\n",
    "    pred, gold, pred_score = eval_all(ciron, risk_api, 'ciron')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===chsenti===')\n",
    "    pred, gold, pred_score = eval_all(senti_copr, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smpecisa===')\n",
    "    pred, gold, pred_score = eval_all(senti_smpecisa, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smp===')\n",
    "    pred, gold, pred_score = eval_all(senti_smp, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_query===')\n",
    "    pred, gold, pred_score = eval_all(senti_query, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc4a276d-2a26-4c01-8cb8-c92e928a3bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:25<00:00, 119.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  主观评价/比较/判断     0.9211    0.9867    0.9528       603\n",
      "          其它     0.9908    0.9743    0.9825      2219\n",
      "     寻求建议/帮助     0.9186    0.8876    0.9029       178\n",
      "\n",
      "    accuracy                         0.9717      3000\n",
      "   macro avg     0.9435    0.9496    0.9460      3000\n",
      "weighted avg     0.9725    0.9717    0.9718      3000\n",
      "\n",
      "tensor([0.0111]) ==ece==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2/multitask_cls.pth.9')\n",
    "\n",
    "# # risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_query_risk_20221222/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2_5_aug/multitask_cls.pth.4')\n",
    "risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v10_intent_v2-1_10_no_symbol_senti_query_senta_balanced_logitclip_v1/multitask_cls.pth.9')\n",
    "\n",
    "intent_v2 = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/xiaoda/intention_data_v2/dev.txt') as frobj:\n",
    "    for line in frobj:\n",
    "        intent_v2.append(json.loads(line.strip()))\n",
    "pred, gold, pred_score = eval_all(intent_v2, risk_api, 'intent')\n",
    "evaluation_ece(pred_score, gold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10c6dcf8-97f9-4b5d-aaa5-2689a7dbb91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20641/20641 [02:54<00:00, 118.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.5534    0.2285    0.3235      5514\n",
      "          风险     0.7684    0.9328    0.8426     15127\n",
      "\n",
      "    accuracy                         0.7446     20641\n",
      "   macro avg     0.6609    0.5806    0.5830     20641\n",
      "weighted avg     0.7109    0.7446    0.7039     20641\n",
      "\n",
      "tensor([0.1919]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v10_intent_v2-1_10_no_symbol_senti_query_senta_balanced_logitclip_v1/multitask_cls.pth.9')\n",
    "\n",
    "risk_query = []\n",
    "with open('/data/albert.xht/xiaodao/query_risk_v11/offensive_select_labeled.txt') as frobj:\n",
    "    for line in frobj:\n",
    "        risk_query.append(json.loads(line.strip()))\n",
    "pred, gold, pred_score = eval_all(risk_query, risk_api, 'query_risk')\n",
    "evaluation_ece(pred_score, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ccfcddc-f2b3-49ac-8ad0-2d40f39e69bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 3000/3000 [00:25<00:00, 118.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  主观评价/比较/判断     0.9183    0.9884    0.9521       603\n",
      "          其它     0.9899    0.9716    0.9807      2219\n",
      "     寻求建议/帮助     0.8902    0.8652    0.8775       178\n",
      "\n",
      "    accuracy                         0.9687      3000\n",
      "   macro avg     0.9328    0.9417    0.9367      3000\n",
      "weighted avg     0.9696    0.9687    0.9688      3000\n",
      "\n",
      "tensor([0.0188]) ==ece==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "intent_v2 = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/xiaoda/intention_data_v2/dev.txt') as frobj:\n",
    "    for line in frobj:\n",
    "        intent_v2.append(json.loads(line.strip()))\n",
    "pred, gold, pred_score = eval_all(intent_v2, risk_api, 'intent')\n",
    "evaluation_ece(pred_score, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d2f0a6f-407e-4180-afa5-9a9b8fa345bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'senti_query': [['负向', 0.748834490776062],\n",
       "  ['中性', 0.1530851274728775],\n",
       "  ['正向', 0.09808038920164108]],\n",
       " 'senti': [['负向', 0.9947615265846252], ['正向', 0.0052385409362614155]],\n",
       " 'bias': [['偏见', 0.0014122501015663147], ['正常', 0.9985877275466919]],\n",
       " 'ciron': [['讽刺', 1.7454854969400913e-05], ['正常', 0.9999825954437256]],\n",
       " 'intent': [['主观评价/比较/判断', 0.01418764516711235],\n",
       "  ['寻求建议/帮助', 0.0049115875735878944],\n",
       "  ['其它', 0.9809007048606873]],\n",
       " 'offensive': [['冒犯', 0.012532699853181839], ['正常', 0.987467348575592]],\n",
       " 'query_risk': [['风险', 0.0017439085058867931],\n",
       "  ['个人信息', 0.0008314871229231358],\n",
       "  ['正常', 0.9974246025085449]],\n",
       " 'teenager': [['不良', 0.07456959038972855], ['正常', 0.9254303574562073]]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_api.predict('笑死我是什么感觉')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a98ebb-c331-4a98-94b6-c4900cc72bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v5_intent_v2_3/multitask_cls.pth.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84d023db-629d-45ba-b1eb-715b68847eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/5304 [00:00<00:45, 116.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:45<00:00, 116.38it/s]\n",
      "  0%|          | 12/2829 [00:00<00:24, 112.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7303    0.8613    0.7904      2106\n",
      "          正常     0.8965    0.7905    0.8401      3198\n",
      "\n",
      "    accuracy                         0.8186      5304\n",
      "   macro avg     0.8134    0.8259    0.8153      5304\n",
      "weighted avg     0.8305    0.8186    0.8204      5304\n",
      "\n",
      "tensor([0.0965]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:24<00:00, 116.02it/s]\n",
      "  1%|▏         | 12/875 [00:00<00:07, 117.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5202    0.6448    0.5759       718\n",
      "          正常     0.8685    0.7977    0.8316      2111\n",
      "\n",
      "    accuracy                         0.7589      2829\n",
      "   macro avg     0.6944    0.7213    0.7037      2829\n",
      "weighted avg     0.7801    0.7589    0.7667      2829\n",
      "\n",
      "tensor([0.1289]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:07<00:00, 117.49it/s]\n",
      "  1%|          | 12/1200 [00:00<00:10, 115.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9390    0.9089    0.9237       779\n",
      "          讽刺     0.4132    0.5208    0.4608        96\n",
      "\n",
      "    accuracy                         0.8663       875\n",
      "   macro avg     0.6761    0.7148    0.6923       875\n",
      "weighted avg     0.8813    0.8663    0.8729       875\n",
      "\n",
      "tensor([0.0541]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.52it/s]\n",
      "  0%|          | 12/2529 [00:00<00:21, 117.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9183    0.9292    0.9237       593\n",
      "          负向     0.9300    0.9193    0.9246       607\n",
      "\n",
      "    accuracy                         0.9242      1200\n",
      "   macro avg     0.9242    0.9242    0.9242      1200\n",
      "weighted avg     0.9242    0.9242    0.9242      1200\n",
      "\n",
      "tensor([0.0321]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:21<00:00, 118.50it/s]\n",
      "  0%|          | 12/2844 [00:00<00:23, 118.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8015    0.8102    0.8058      1201\n",
      "          负向     0.8266    0.8185    0.8226      1328\n",
      "\n",
      "    accuracy                         0.8146      2529\n",
      "   macro avg     0.8140    0.8143    0.8142      2529\n",
      "weighted avg     0.8147    0.8146    0.8146      2529\n",
      "\n",
      "tensor([0.1175]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:24<00:00, 117.36it/s]\n",
      "  0%|          | 12/50509 [00:00<07:05, 118.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8383    0.8934    0.8650      1126\n",
      "          负向     0.9270    0.8871    0.9066      1718\n",
      "\n",
      "    accuracy                         0.8896      2844\n",
      "   macro avg     0.8827    0.8903    0.8858      2844\n",
      "weighted avg     0.8919    0.8896    0.8901      2844\n",
      "\n",
      "tensor([0.0691]) ==ece==\n",
      "===senti_query===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 20181/50509 [02:51<04:18, 117.51it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_56725/3931817400.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v10_intent_v2-1_10_no_symbol_senti_query_senta_balanced_logitclip_v1/multitask_cls.pth.9'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_56725/3217327212.py\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===senti_query==='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msenti_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'senti'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_56725/1846423510.py\u001b[0m in \u001b[0;36meval_all\u001b[0;34m(data, model, key)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"([，\\_《。》、？；：‘’＂“”【「】」·！@￥…（）—\\,\\<\\.\\>\\/\\?\\;\\:\\'\\\"\\[\\]\\{\\}\\~\\`\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\-\\=\\+])+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 合并正文中过多的空格\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_56725/387664356.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             [logits_list, \n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                 attention_mask, token_type_ids, transformer_mode='cls')\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mschema_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_56725/387664356.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_mask, segment_ids, transformer_mode, dt_idx)\u001b[0m\n\u001b[1;32m     95\u001b[0m                         \u001b[0mtransformer_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_pooling'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                         dt_idx=None):\n\u001b[0;32m---> 97\u001b[0;31m                 hidden_states = self.transformer(input_ids=input_ids,\n\u001b[0m\u001b[1;32m     98\u001b[0m                               \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                               \u001b[0msegment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/xiaoda/query_topic/nets/them_classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_mask, segment_ids, return_mode)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cls'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1111\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    726\u001b[0m                 )\n\u001b[1;32m    727\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    729\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, sinusoidal_pos, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    637\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2926\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2928\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v10_intent_v2-1_10_no_symbol_senti_query_senta_balanced_logitclip_v1/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4116d43-9495-43d6-bb69-7355b780047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v10_intent_v2-1_10_no_symbol_senti_query_senta_balanced_logitclip/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c78050ab-618a-4d5c-bf4e-e7dcdcad9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v9_intent_v2-1_10_no_symbol_v1/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c29b8019-e251-44c9-94e4-a61f9a91a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v6_intent_v2-1_10_no_symbol/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d241c474-bcd8-4c0f-ab73-cd54c3078912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v5_no_offensive_intent_v2-1_3/multitask_cls.pth.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d63066c-26d5-45d4-91e6-fa641a592d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/multitask_raw_filter_senti_query_risk_v5_intent_v2-1_3/multitask_cls.pth.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da1db8e-837f-4609-adfc-566ba2583b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [], range(1, 0))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0, 1), random.sample(list(range(1, 2)), k=0), range(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0f5c9b8-2e59-4186-a9c1-d3736d6738d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:43<00:00, 121.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7306    0.8523    0.7868      2106\n",
      "          正常     0.8908    0.7930    0.8390      3198\n",
      "\n",
      "    accuracy                         0.8166      5304\n",
      "   macro avg     0.8107    0.8227    0.8129      5304\n",
      "weighted avg     0.8272    0.8166    0.8183      5304\n",
      "\n",
      "tensor([0.1362]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:23<00:00, 120.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5761    0.5376    0.5562       718\n",
      "          正常     0.8462    0.8655    0.8557      2111\n",
      "\n",
      "    accuracy                         0.7823      2829\n",
      "   macro avg     0.7112    0.7015    0.7060      2829\n",
      "weighted avg     0.7777    0.7823    0.7797      2829\n",
      "\n",
      "tensor([0.0758]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:07<00:00, 122.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9246    0.9602    0.9421       779\n",
      "          讽刺     0.5303    0.3646    0.4321        96\n",
      "\n",
      "    accuracy                         0.8949       875\n",
      "   macro avg     0.7275    0.6624    0.6871       875\n",
      "weighted avg     0.8813    0.8949    0.8861       875\n",
      "\n",
      "tensor([0.0579]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 118.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9480    0.9528    0.9504       593\n",
      "          负向     0.9536    0.9489    0.9513       607\n",
      "\n",
      "    accuracy                         0.9508      1200\n",
      "   macro avg     0.9508    0.9509    0.9508      1200\n",
      "weighted avg     0.9508    0.9508    0.9508      1200\n",
      "\n",
      "tensor([0.0192]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 122.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.7700    0.8501    0.8081      1201\n",
      "          负向     0.8504    0.7703    0.8084      1328\n",
      "\n",
      "    accuracy                         0.8082      2529\n",
      "   macro avg     0.8102    0.8102    0.8082      2529\n",
      "weighted avg     0.8122    0.8082    0.8082      2529\n",
      "\n",
      "tensor([0.1563]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:23<00:00, 121.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8057    0.8988    0.8497      1126\n",
      "          负向     0.9282    0.8580    0.8917      1718\n",
      "\n",
      "    accuracy                         0.8741      2844\n",
      "   macro avg     0.8670    0.8784    0.8707      2844\n",
      "weighted avg     0.8797    0.8741    0.8751      2844\n",
      "\n",
      "tensor([0.0911]) ==ece==\n",
      "===senti_query===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 30108/50509 [04:09<02:48, 120.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_68088/1052261655.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2_5_aug/multitask_cls.pth.4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_68088/3217327212.py\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===senti_query==='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msenti_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'senti'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_68088/4130490020.py\u001b[0m in \u001b[0;36meval_all\u001b[0;34m(data, model, key)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_68088/878510297.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             [logits_list, \n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                 attention_mask, token_type_ids, transformer_mode='cls')\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mschema_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_68088/878510297.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_mask, segment_ids, transformer_mode, dt_idx)\u001b[0m\n\u001b[1;32m     95\u001b[0m                         \u001b[0mtransformer_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_pooling'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                         dt_idx=None):\n\u001b[0;32m---> 97\u001b[0;31m                 hidden_states = self.transformer(input_ids=input_ids,\n\u001b[0m\u001b[1;32m     98\u001b[0m                               \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                               \u001b[0msegment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/xiaoda/query_topic/nets/them_classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_mask, segment_ids, return_mode)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cls'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1111\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    726\u001b[0m                 )\n\u001b[1;32m    727\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    729\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, sinusoidal_pos, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         )\n\u001b[0;32m--> 586\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, sinusoidal_pos, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     ):\n\u001b[0;32m--> 506\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    507\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, sinusoidal_pos, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         outputs = (\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mcontext_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcontext_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         )\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2_5_aug/multitask_cls.pth.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c763a78-8c46-4d58-8632-ed678351854c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:47<00:00, 111.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7309    0.8680    0.7936      2106\n",
      "          正常     0.9008    0.7896    0.8415      3198\n",
      "\n",
      "    accuracy                         0.8207      5304\n",
      "   macro avg     0.8159    0.8288    0.8176      5304\n",
      "weighted avg     0.8334    0.8207    0.8225      5304\n",
      "\n",
      "tensor([0.1185]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:23<00:00, 122.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5839    0.5139    0.5467       718\n",
      "          正常     0.8411    0.8754    0.8579      2111\n",
      "\n",
      "    accuracy                         0.7837      2829\n",
      "   macro avg     0.7125    0.6947    0.7023      2829\n",
      "weighted avg     0.7758    0.7837    0.7789      2829\n",
      "\n",
      "tensor([0.0372]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:07<00:00, 124.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9191    0.9628    0.9404       779\n",
      "          讽刺     0.5085    0.3125    0.3871        96\n",
      "\n",
      "    accuracy                         0.8914       875\n",
      "   macro avg     0.7138    0.6376    0.6638       875\n",
      "weighted avg     0.8741    0.8914    0.8797       875\n",
      "\n",
      "tensor([0.0317]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 121.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9305    0.9477    0.9390       593\n",
      "          负向     0.9480    0.9308    0.9393       607\n",
      "\n",
      "    accuracy                         0.9392      1200\n",
      "   macro avg     0.9392    0.9393    0.9392      1200\n",
      "weighted avg     0.9393    0.9392    0.9392      1200\n",
      "\n",
      "tensor([0.0284]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 124.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.7702    0.8510    0.8085      1201\n",
      "          负向     0.8511    0.7703    0.8087      1328\n",
      "\n",
      "    accuracy                         0.8086      2529\n",
      "   macro avg     0.8106    0.8106    0.8086      2529\n",
      "weighted avg     0.8127    0.8086    0.8086      2529\n",
      "\n",
      "tensor([0.1475]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:23<00:00, 123.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8225    0.9014    0.8602      1126\n",
      "          负向     0.9311    0.8725    0.9008      1718\n",
      "\n",
      "    accuracy                         0.8840      2844\n",
      "   macro avg     0.8768    0.8870    0.8805      2844\n",
      "weighted avg     0.8881    0.8840    0.8847      2844\n",
      "\n",
      "tensor([0.0719]) ==ece==\n",
      "===senti_query===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39435/50509 [05:17<01:29, 124.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58631/2128993976.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2/multitask_cls.pth.8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_58631/3217327212.py\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===senti_query==='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msenti_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'senti'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_58631/4130490020.py\u001b[0m in \u001b[0;36meval_all\u001b[0;34m(data, model, key)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_58631/878510297.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             [logits_list, \n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                 attention_mask, token_type_ids, transformer_mode='cls')\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mschema_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_58631/878510297.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_mask, segment_ids, transformer_mode, dt_idx)\u001b[0m\n\u001b[1;32m     95\u001b[0m                         \u001b[0mtransformer_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_pooling'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                         dt_idx=None):\n\u001b[0;32m---> 97\u001b[0;31m                 hidden_states = self.transformer(input_ids=input_ids,\n\u001b[0m\u001b[1;32m     98\u001b[0m                               \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                               \u001b[0msegment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/xiaoda/query_topic/nets/them_classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_mask, segment_ids, return_mode)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cls'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1111\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    726\u001b[0m                 )\n\u001b[1;32m    727\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    729\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, sinusoidal_pos, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         )\n\u001b[0;32m--> 586\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, sinusoidal_pos, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     ):\n\u001b[0;32m--> 506\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    507\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, sinusoidal_pos, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0;31m# rotary key_layer & value_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2/multitask_cls.pth.8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce62f6d0-bbae-47d4-b570-2799bdeec8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:43<00:00, 122.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7344    0.8599    0.7922      2106\n",
      "          正常     0.8961    0.7952    0.8426      3198\n",
      "\n",
      "    accuracy                         0.8209      5304\n",
      "   macro avg     0.8152    0.8276    0.8174      5304\n",
      "weighted avg     0.8319    0.8209    0.8226      5304\n",
      "\n",
      "tensor([0.1135]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:23<00:00, 122.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5700    0.4930    0.5288       718\n",
      "          正常     0.8351    0.8735    0.8539      2111\n",
      "\n",
      "    accuracy                         0.7770      2829\n",
      "   macro avg     0.7026    0.6833    0.6913      2829\n",
      "weighted avg     0.7679    0.7770    0.7714      2829\n",
      "\n",
      "tensor([0.0479]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:07<00:00, 122.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9168    0.9615    0.9386       779\n",
      "          讽刺     0.4828    0.2917    0.3636        96\n",
      "\n",
      "    accuracy                         0.8880       875\n",
      "   macro avg     0.6998    0.6266    0.6511       875\n",
      "weighted avg     0.8692    0.8880    0.8755       875\n",
      "\n",
      "tensor([0.0333]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 119.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9316    0.9410    0.9362       593\n",
      "          负向     0.9418    0.9325    0.9371       607\n",
      "\n",
      "    accuracy                         0.9367      1200\n",
      "   macro avg     0.9367    0.9367    0.9367      1200\n",
      "weighted avg     0.9367    0.9367    0.9367      1200\n",
      "\n",
      "tensor([0.0270]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 122.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.7767    0.8543    0.8136      1201\n",
      "          负向     0.8551    0.7779    0.8147      1328\n",
      "\n",
      "    accuracy                         0.8142      2529\n",
      "   macro avg     0.8159    0.8161    0.8142      2529\n",
      "weighted avg     0.8179    0.8142    0.8142      2529\n",
      "\n",
      "tensor([0.1410]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:23<00:00, 122.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8195    0.9032    0.8593      1126\n",
      "          负向     0.9320    0.8696    0.8997      1718\n",
      "\n",
      "    accuracy                         0.8829      2844\n",
      "   macro avg     0.8758    0.8864    0.8795      2844\n",
      "weighted avg     0.8875    0.8829    0.8837      2844\n",
      "\n",
      "tensor([0.0736]) ==ece==\n",
      "===senti_query===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50509/50509 [06:45<00:00, 124.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9686    0.9721    0.9704     28251\n",
      "          负向     0.9645    0.9600    0.9622     22258\n",
      "\n",
      "    accuracy                         0.9668     50509\n",
      "   macro avg     0.9665    0.9661    0.9663     50509\n",
      "weighted avg     0.9668    0.9668    0.9668     50509\n",
      "\n",
      "tensor([0.0188]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_query_risk_20221222/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8331128b-2671-4129-9a7a-4781b657b020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 123.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7448    0.8538    0.7956      2106\n",
      "          正常     0.8934    0.8074    0.8482      3198\n",
      "\n",
      "    accuracy                         0.8258      5304\n",
      "   macro avg     0.8191    0.8306    0.8219      5304\n",
      "weighted avg     0.8344    0.8258    0.8273      5304\n",
      "\n",
      "tensor([0.1187]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 123.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5665    0.5752    0.5708       718\n",
      "          正常     0.8548    0.8503    0.8525      2111\n",
      "\n",
      "    accuracy                         0.7805      2829\n",
      "   macro avg     0.7106    0.7128    0.7117      2829\n",
      "weighted avg     0.7816    0.7805    0.7810      2829\n",
      "\n",
      "tensor([0.0452]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:07<00:00, 124.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9299    0.9371    0.9335       779\n",
      "          讽刺     0.4556    0.4271    0.4409        96\n",
      "\n",
      "    accuracy                         0.8811       875\n",
      "   macro avg     0.6927    0.6821    0.6872       875\n",
      "weighted avg     0.8779    0.8811    0.8795       875\n",
      "\n",
      "tensor([0.0460]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 120.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9282    0.9595    0.9436       593\n",
      "          负向     0.9591    0.9275    0.9430       607\n",
      "\n",
      "    accuracy                         0.9433      1200\n",
      "   macro avg     0.9437    0.9435    0.9433      1200\n",
      "weighted avg     0.9438    0.9433    0.9433      1200\n",
      "\n",
      "tensor([0.0386]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 124.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.7543    0.8485    0.7986      1201\n",
      "          负向     0.8455    0.7500    0.7949      1328\n",
      "\n",
      "    accuracy                         0.7968      2529\n",
      "   macro avg     0.7999    0.7992    0.7967      2529\n",
      "weighted avg     0.8022    0.7968    0.7966      2529\n",
      "\n",
      "tensor([0.1659]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:23<00:00, 123.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8233    0.8899    0.8553      1126\n",
      "          负向     0.9238    0.8749    0.8987      1718\n",
      "\n",
      "    accuracy                         0.8808      2844\n",
      "   macro avg     0.8736    0.8824    0.8770      2844\n",
      "weighted avg     0.8840    0.8808    0.8815      2844\n",
      "\n",
      "tensor([0.0784]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/query_risk_v3/multitask_raw_filter_senti_query_risk_v3/multitask_cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3a0e43c1-6b45-4755-bdec-c6bc93910aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 124.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7084    0.8837    0.7864      2106\n",
      "          正常     0.9085    0.7605    0.8279      3198\n",
      "\n",
      "    accuracy                         0.8094      5304\n",
      "   macro avg     0.8084    0.8221    0.8072      5304\n",
      "weighted avg     0.8290    0.8094    0.8114      5304\n",
      "\n",
      "tensor([0.1319]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 124.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5622    0.6045    0.5826       718\n",
      "          正常     0.8619    0.8399    0.8508      2111\n",
      "\n",
      "    accuracy                         0.7801      2829\n",
      "   macro avg     0.7121    0.7222    0.7167      2829\n",
      "weighted avg     0.7859    0.7801    0.7827      2829\n",
      "\n",
      "tensor([0.0458]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 125.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9287    0.9538    0.9411       779\n",
      "          讽刺     0.5200    0.4062    0.4561        96\n",
      "\n",
      "    accuracy                         0.8937       875\n",
      "   macro avg     0.7244    0.6800    0.6986       875\n",
      "weighted avg     0.8839    0.8937    0.8879       875\n",
      "\n",
      "tensor([0.0358]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 122.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9112    0.9174    0.9143       593\n",
      "          负向     0.9187    0.9127    0.9157       607\n",
      "\n",
      "    accuracy                         0.9150      1200\n",
      "   macro avg     0.9150    0.9150    0.9150      1200\n",
      "weighted avg     0.9150    0.9150    0.9150      1200\n",
      "\n",
      "tensor([0.0297]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 126.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8326    0.7868    0.8091      1201\n",
      "          负向     0.8164    0.8569    0.8361      1328\n",
      "\n",
      "    accuracy                         0.8236      2529\n",
      "   macro avg     0.8245    0.8219    0.8226      2529\n",
      "weighted avg     0.8241    0.8236    0.8233      2529\n",
      "\n",
      "tensor([0.0308]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 126.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8724    0.8321    0.8518      1126\n",
      "          负向     0.8932    0.9203    0.9065      1718\n",
      "\n",
      "    accuracy                         0.8854      2844\n",
      "   macro avg     0.8828    0.8762    0.8792      2844\n",
      "weighted avg     0.8850    0.8854    0.8849      2844\n",
      "\n",
      "tensor([0.0111]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256_20/multitask_cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c81a54a-1768-4454-9e04-7f9c8c52673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7050    0.8794    0.7826      2106\n",
      "          正常     0.9051    0.7577    0.8249      3198\n",
      "\n",
      "    accuracy                         0.8060      5304\n",
      "   macro avg     0.8051    0.8185    0.8037      5304\n",
      "weighted avg     0.8257    0.8060    0.8081      5304\n",
      "\n",
      "tensor([0.1119]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:25<00:00, 111.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.6208    0.4903    0.5479       718\n",
      "          正常     0.8382    0.8982    0.8671      2111\n",
      "\n",
      "    accuracy                         0.7946      2829\n",
      "   macro avg     0.7295    0.6942    0.7075      2829\n",
      "weighted avg     0.7830    0.7946    0.7861      2829\n",
      "\n",
      "tensor([0.0231]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:08<00:00, 98.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9255    0.9730    0.9487       779\n",
      "          讽刺     0.6250    0.3646    0.4605        96\n",
      "\n",
      "    accuracy                         0.9063       875\n",
      "   macro avg     0.7753    0.6688    0.7046       875\n",
      "weighted avg     0.8925    0.9063    0.8951       875\n",
      "\n",
      "tensor([0.0363]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:12<00:00, 96.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8838    0.9106    0.8970       593\n",
      "          负向     0.9100    0.8830    0.8963       607\n",
      "\n",
      "    accuracy                         0.8967      1200\n",
      "   macro avg     0.8969    0.8968    0.8967      1200\n",
      "weighted avg     0.8971    0.8967    0.8967      1200\n",
      "\n",
      "tensor([0.0226]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:22<00:00, 111.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8053    0.8160    0.8106      1201\n",
      "          负向     0.8316    0.8215    0.8265      1328\n",
      "\n",
      "    accuracy                         0.8189      2529\n",
      "   macro avg     0.8184    0.8188    0.8186      2529\n",
      "weighted avg     0.8191    0.8189    0.8190      2529\n",
      "\n",
      "tensor([0.0208]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 125.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8540    0.8366    0.8452      1126\n",
      "          负向     0.8943    0.9063    0.9003      1718\n",
      "\n",
      "    accuracy                         0.8787      2844\n",
      "   macro avg     0.8742    0.8714    0.8727      2844\n",
      "weighted avg     0.8784    0.8787    0.8785      2844\n",
      "\n",
      "tensor([0.0247]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_intent_v1/multitask_cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1c4efc0-473c-4613-ac20-62c9d193c161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7068    0.8746    0.7818      2106\n",
      "          正常     0.9021    0.7611    0.8256      3198\n",
      "\n",
      "    accuracy                         0.8062      5304\n",
      "   macro avg     0.8045    0.8179    0.8037      5304\n",
      "weighted avg     0.8246    0.8062    0.8082      5304\n",
      "\n",
      "tensor([0.0195]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 125.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5951    0.4749    0.5283       718\n",
      "          正常     0.8329    0.8901    0.8605      2111\n",
      "\n",
      "    accuracy                         0.7847      2829\n",
      "   macro avg     0.7140    0.6825    0.6944      2829\n",
      "weighted avg     0.7725    0.7847    0.7762      2829\n",
      "\n",
      "tensor([0.1170]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 125.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9230    0.9692    0.9455       779\n",
      "          讽刺     0.5789    0.3438    0.4314        96\n",
      "\n",
      "    accuracy                         0.9006       875\n",
      "   macro avg     0.7510    0.6565    0.6884       875\n",
      "weighted avg     0.8852    0.9006    0.8891       875\n",
      "\n",
      "tensor([0.1106]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 121.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8807    0.9089    0.8946       593\n",
      "          负向     0.9082    0.8797    0.8937       607\n",
      "\n",
      "    accuracy                         0.8942      1200\n",
      "   macro avg     0.8944    0.8943    0.8942      1200\n",
      "weighted avg     0.8946    0.8942    0.8942      1200\n",
      "\n",
      "tensor([0.1561]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 126.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8163    0.8251    0.8207      1201\n",
      "          负向     0.8403    0.8321    0.8362      1328\n",
      "\n",
      "    accuracy                         0.8288      2529\n",
      "   macro avg     0.8283    0.8286    0.8284      2529\n",
      "weighted avg     0.8289    0.8288    0.8288      2529\n",
      "\n",
      "tensor([0.1556]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 125.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8627    0.8313    0.8467      1126\n",
      "          负向     0.8920    0.9133    0.9025      1718\n",
      "\n",
      "    accuracy                         0.8808      2844\n",
      "   macro avg     0.8773    0.8723    0.8746      2844\n",
      "weighted avg     0.8804    0.8808    0.8804      2844\n",
      "\n",
      "tensor([0.1674]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_focal/multitask_cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc5ba38e-db17-4e3d-b05c-caabe86f0e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 124.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7034    0.8818    0.7826      2106\n",
      "          正常     0.9065    0.7552    0.8240      3198\n",
      "\n",
      "    accuracy                         0.8054      5304\n",
      "   macro avg     0.8050    0.8185    0.8033      5304\n",
      "weighted avg     0.8259    0.8054    0.8075      5304\n",
      "\n",
      "tensor([0.1129]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 125.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.6035    0.4833    0.5367       718\n",
      "          正常     0.8354    0.8920    0.8628      2111\n",
      "\n",
      "    accuracy                         0.7883      2829\n",
      "   macro avg     0.7194    0.6876    0.6998      2829\n",
      "weighted avg     0.7765    0.7883    0.7800      2829\n",
      "\n",
      "tensor([0.0261]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 126.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9126    0.9653    0.9382       779\n",
      "          讽刺     0.4706    0.2500    0.3265        96\n",
      "\n",
      "    accuracy                         0.8869       875\n",
      "   macro avg     0.6916    0.6077    0.6324       875\n",
      "weighted avg     0.8641    0.8869    0.8711       875\n",
      "\n",
      "tensor([0.0374]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 122.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8831    0.9174    0.8999       593\n",
      "          负向     0.9161    0.8814    0.8984       607\n",
      "\n",
      "    accuracy                         0.8992      1200\n",
      "   macro avg     0.8996    0.8994    0.8992      1200\n",
      "weighted avg     0.8998    0.8992    0.8992      1200\n",
      "\n",
      "tensor([0.0285]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:19<00:00, 127.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8099    0.8301    0.8199      1201\n",
      "          负向     0.8428    0.8238    0.8332      1328\n",
      "\n",
      "    accuracy                         0.8268      2529\n",
      "   macro avg     0.8264    0.8270    0.8266      2529\n",
      "weighted avg     0.8272    0.8268    0.8269      2529\n",
      "\n",
      "tensor([0.0214]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 126.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8552    0.8393    0.8472      1126\n",
      "          负向     0.8959    0.9069    0.9014      1718\n",
      "\n",
      "    accuracy                         0.8801      2844\n",
      "   macro avg     0.8756    0.8731    0.8743      2844\n",
      "weighted avg     0.8798    0.8801    0.8799      2844\n",
      "\n",
      "tensor([0.0243]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_balanced_intent_v1//multitask_cls.pth.9')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d330603c-fb51-4465-b010-b852348536cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7314    0.8661    0.7930      2106\n",
      "          正常     0.8996    0.7905    0.8415      3198\n",
      "\n",
      "    accuracy                         0.8205      5304\n",
      "   macro avg     0.8155    0.8283    0.8173      5304\n",
      "weighted avg     0.8328    0.8205    0.8223      5304\n",
      "\n",
      "tensor([0.0103]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 124.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5877    0.4944    0.5371       718\n",
      "          正常     0.8369    0.8820    0.8589      2111\n",
      "\n",
      "    accuracy                         0.7837      2829\n",
      "   macro avg     0.7123    0.6882    0.6980      2829\n",
      "weighted avg     0.7736    0.7837    0.7772      2829\n",
      "\n",
      "tensor([0.1111]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:07<00:00, 114.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9174    0.9692    0.9426       779\n",
      "          讽刺     0.5385    0.2917    0.3784        96\n",
      "\n",
      "    accuracy                         0.8949       875\n",
      "   macro avg     0.7279    0.6304    0.6605       875\n",
      "weighted avg     0.8758    0.8949    0.8807       875\n",
      "\n",
      "tensor([0.1099]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 116.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8941    0.9258    0.9097       593\n",
      "          负向     0.9249    0.8929    0.9086       607\n",
      "\n",
      "    accuracy                         0.9092      1200\n",
      "   macro avg     0.9095    0.9094    0.9092      1200\n",
      "weighted avg     0.9097    0.9092    0.9092      1200\n",
      "\n",
      "tensor([0.1246]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 125.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8103    0.8218    0.8160      1201\n",
      "          负向     0.8368    0.8261    0.8314      1328\n",
      "\n",
      "    accuracy                         0.8240      2529\n",
      "   macro avg     0.8236    0.8239    0.8237      2529\n",
      "weighted avg     0.8242    0.8240    0.8241      2529\n",
      "\n",
      "tensor([0.1440]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 124.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8532    0.8464    0.8498      1126\n",
      "          负向     0.8998    0.9045    0.9022      1718\n",
      "\n",
      "    accuracy                         0.8815      2844\n",
      "   macro avg     0.8765    0.8754    0.8760      2844\n",
      "weighted avg     0.8814    0.8815    0.8814      2844\n",
      "\n",
      "tensor([0.1548]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_focal_128/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "192980fd-608d-418a-baf2-e03061767e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7074    0.8770    0.7831      2106\n",
      "          正常     0.9038    0.7611    0.8263      3198\n",
      "\n",
      "    accuracy                         0.8071      5304\n",
      "   macro avg     0.8056    0.8191    0.8047      5304\n",
      "weighted avg     0.8258    0.8071    0.8092      5304\n",
      "\n",
      "tensor([0.1762]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 124.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5777    0.5125    0.5432       718\n",
      "          正常     0.8403    0.8726    0.8561      2111\n",
      "\n",
      "    accuracy                         0.7812      2829\n",
      "   macro avg     0.7090    0.6926    0.6997      2829\n",
      "weighted avg     0.7737    0.7812    0.7767      2829\n",
      "\n",
      "tensor([0.1900]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 125.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9294    0.9461    0.9377       779\n",
      "          讽刺     0.4878    0.4167    0.4494        96\n",
      "\n",
      "    accuracy                         0.8880       875\n",
      "   macro avg     0.7086    0.6814    0.6935       875\n",
      "weighted avg     0.8809    0.8880    0.8841       875\n",
      "\n",
      "tensor([0.1048]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 121.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9314    0.9157    0.9235       593\n",
      "          负向     0.9190    0.9341    0.9265       607\n",
      "\n",
      "    accuracy                         0.9250      1200\n",
      "   macro avg     0.9252    0.9249    0.9250      1200\n",
      "weighted avg     0.9251    0.9250    0.9250      1200\n",
      "\n",
      "tensor([0.0596]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 125.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8183    0.8285    0.8233      1201\n",
      "          负向     0.8431    0.8336    0.8383      1328\n",
      "\n",
      "    accuracy                         0.8312      2529\n",
      "   macro avg     0.8307    0.8310    0.8308      2529\n",
      "weighted avg     0.8313    0.8312    0.8312      2529\n",
      "\n",
      "tensor([0.1288]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 126.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8613    0.8437    0.8524      1126\n",
      "          负向     0.8989    0.9109    0.9049      1718\n",
      "\n",
      "    accuracy                         0.8843      2844\n",
      "   macro avg     0.8801    0.8773    0.8786      2844\n",
      "weighted avg     0.8840    0.8843    0.8841      2844\n",
      "\n",
      "tensor([0.0493]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_contrast_balanced_intent_v1/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef2307e5-3160-4342-8598-af7711f6c221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7229    0.8756    0.7919      2106\n",
      "          正常     0.9048    0.7789    0.8372      3198\n",
      "\n",
      "    accuracy                         0.8173      5304\n",
      "   macro avg     0.8138    0.8273    0.8145      5304\n",
      "weighted avg     0.8326    0.8173    0.8192      5304\n",
      "\n",
      "tensor([0.1323]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 126.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5892    0.5153    0.5498       718\n",
      "          正常     0.8419    0.8778    0.8595      2111\n",
      "\n",
      "    accuracy                         0.7858      2829\n",
      "   macro avg     0.7155    0.6966    0.7046      2829\n",
      "weighted avg     0.7778    0.7858    0.7809      2829\n",
      "\n",
      "tensor([0.0623]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 126.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9188    0.9589    0.9384       779\n",
      "          讽刺     0.4839    0.3125    0.3797        96\n",
      "\n",
      "    accuracy                         0.8880       875\n",
      "   macro avg     0.7013    0.6357    0.6591       875\n",
      "weighted avg     0.8711    0.8880    0.8771       875\n",
      "\n",
      "tensor([0.0520]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 122.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9129    0.9191    0.9160       593\n",
      "          负向     0.9204    0.9143    0.9174       607\n",
      "\n",
      "    accuracy                         0.9167      1200\n",
      "   macro avg     0.9166    0.9167    0.9167      1200\n",
      "weighted avg     0.9167    0.9167    0.9167      1200\n",
      "\n",
      "tensor([0.0421]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:19<00:00, 126.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8085    0.8085    0.8085      1201\n",
      "          负向     0.8268    0.8268    0.8268      1328\n",
      "\n",
      "    accuracy                         0.8181      2529\n",
      "   macro avg     0.8177    0.8177    0.8177      2529\n",
      "weighted avg     0.8181    0.8181    0.8181      2529\n",
      "\n",
      "tensor([0.0537]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 124.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8543    0.8330    0.8435      1126\n",
      "          负向     0.8923    0.9069    0.8995      1718\n",
      "\n",
      "    accuracy                         0.8776      2844\n",
      "   macro avg     0.8733    0.8700    0.8715      2844\n",
      "weighted avg     0.8773    0.8776    0.8774      2844\n",
      "\n",
      "tensor([0.0230]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_mtdnn_ce_256/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0e06bba0-2c4c-4a2e-b842-67823dced661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7248    0.8590    0.7862      2106\n",
      "          正常     0.8942    0.7852    0.8362      3198\n",
      "\n",
      "    accuracy                         0.8145      5304\n",
      "   macro avg     0.8095    0.8221    0.8112      5304\n",
      "weighted avg     0.8269    0.8145    0.8163      5304\n",
      "\n",
      "tensor([0.0393]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 124.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5753    0.5056    0.5382       718\n",
      "          正常     0.8385    0.8730    0.8554      2111\n",
      "\n",
      "    accuracy                         0.7798      2829\n",
      "   macro avg     0.7069    0.6893    0.6968      2829\n",
      "weighted avg     0.7717    0.7798    0.7749      2829\n",
      "\n",
      "tensor([0.0811]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 125.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9243    0.9564    0.9401       779\n",
      "          讽刺     0.5072    0.3646    0.4242        96\n",
      "\n",
      "    accuracy                         0.8914       875\n",
      "   macro avg     0.7158    0.6605    0.6822       875\n",
      "weighted avg     0.8786    0.8914    0.8835       875\n",
      "\n",
      "tensor([0.0768]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 121.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9132    0.9224    0.9178       593\n",
      "          负向     0.9235    0.9143    0.9189       607\n",
      "\n",
      "    accuracy                         0.9183      1200\n",
      "   macro avg     0.9183    0.9184    0.9183      1200\n",
      "weighted avg     0.9184    0.9183    0.9183      1200\n",
      "\n",
      "tensor([0.0882]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 125.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8040    0.8027    0.8033      1201\n",
      "          负向     0.8218    0.8230    0.8224      1328\n",
      "\n",
      "    accuracy                         0.8134      2529\n",
      "   macro avg     0.8129    0.8129    0.8129      2529\n",
      "weighted avg     0.8134    0.8134    0.8134      2529\n",
      "\n",
      "tensor([0.0975]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 124.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8523    0.8250    0.8384      1126\n",
      "          负向     0.8877    0.9063    0.8969      1718\n",
      "\n",
      "    accuracy                         0.8741      2844\n",
      "   macro avg     0.8700    0.8657    0.8677      2844\n",
      "weighted avg     0.8737    0.8741    0.8738      2844\n",
      "\n",
      "tensor([0.1215]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_mtdnn_focal_256/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c84059c2-9bc9-4978-b772-d4bb5b37b7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6417/6417 [00:51<00:00, 124.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.9025    0.9264    0.9143      3208\n",
      "          正常     0.9245    0.9000    0.9120      3209\n",
      "\n",
      "    accuracy                         0.9132      6417\n",
      "   macro avg     0.9135    0.9132    0.9132      6417\n",
      "weighted avg     0.9135    0.9132    0.9132      6417\n",
      "\n",
      "tensor([0.0343]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 124.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5808    0.5153    0.5461       718\n",
      "          正常     0.8412    0.8735    0.8571      2111\n",
      "\n",
      "    accuracy                         0.7826      2829\n",
      "   macro avg     0.7110    0.6944    0.7016      2829\n",
      "weighted avg     0.7752    0.7826    0.7782      2829\n",
      "\n",
      "tensor([0.0418]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 126.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9220    0.9718    0.9462       779\n",
      "          讽刺     0.5926    0.3333    0.4267        96\n",
      "\n",
      "    accuracy                         0.9017       875\n",
      "   macro avg     0.7573    0.6525    0.6865       875\n",
      "weighted avg     0.8859    0.9017    0.8892       875\n",
      "\n",
      "tensor([0.0266]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 122.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9028    0.9241    0.9133       593\n",
      "          负向     0.9241    0.9028    0.9133       607\n",
      "\n",
      "    accuracy                         0.9133      1200\n",
      "   macro avg     0.9135    0.9135    0.9133      1200\n",
      "weighted avg     0.9136    0.9133    0.9133      1200\n",
      "\n",
      "tensor([0.0361]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:19<00:00, 126.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8196    0.8285    0.8240      1201\n",
      "          负向     0.8433    0.8351    0.8392      1328\n",
      "\n",
      "    accuracy                         0.8319      2529\n",
      "   macro avg     0.8315    0.8318    0.8316      2529\n",
      "weighted avg     0.8321    0.8319    0.8320      2529\n",
      "\n",
      "tensor([0.0217]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 126.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8630    0.8446    0.8537      1126\n",
      "          负向     0.8995    0.9121    0.9058      1718\n",
      "\n",
      "    accuracy                         0.8854      2844\n",
      "   macro avg     0.8813    0.8783    0.8797      2844\n",
      "weighted avg     0.8851    0.8854    0.8852      2844\n",
      "\n",
      "tensor([0.0128]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256/multitask_cls.pth.9')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f16c2c92-d5c2-460f-932a-edf2f2495adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6417/6417 [00:51<00:00, 125.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.9075    0.9261    0.9167      3208\n",
      "          正常     0.9246    0.9056    0.9150      3209\n",
      "\n",
      "    accuracy                         0.9158      6417\n",
      "   macro avg     0.9160    0.9159    0.9158      6417\n",
      "weighted avg     0.9160    0.9158    0.9158      6417\n",
      "\n",
      "tensor([0.0770]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:25<00:00, 109.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5963    0.4958    0.5414       718\n",
      "          正常     0.8378    0.8858    0.8612      2111\n",
      "\n",
      "    accuracy                         0.7869      2829\n",
      "   macro avg     0.7171    0.6908    0.7013      2829\n",
      "weighted avg     0.7765    0.7869    0.7800      2829\n",
      "\n",
      "tensor([0.1125]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 126.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9221    0.9576    0.9395       779\n",
      "          讽刺     0.5000    0.3438    0.4074        96\n",
      "\n",
      "    accuracy                         0.8903       875\n",
      "   macro avg     0.7111    0.6507    0.6735       875\n",
      "weighted avg     0.8758    0.8903    0.8812       875\n",
      "\n",
      "tensor([0.1056]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 122.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8992    0.9174    0.9082       593\n",
      "          负向     0.9176    0.8995    0.9085       607\n",
      "\n",
      "    accuracy                         0.9083      1200\n",
      "   macro avg     0.9084    0.9084    0.9083      1200\n",
      "weighted avg     0.9085    0.9083    0.9083      1200\n",
      "\n",
      "tensor([0.1026]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:19<00:00, 127.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8167    0.8127    0.8147      1201\n",
      "          负向     0.8313    0.8351    0.8332      1328\n",
      "\n",
      "    accuracy                         0.8244      2529\n",
      "   macro avg     0.8240    0.8239    0.8239      2529\n",
      "weighted avg     0.8244    0.8244    0.8244      2529\n",
      "\n",
      "tensor([0.1432]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 126.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8662    0.8393    0.8525      1126\n",
      "          负向     0.8967    0.9150    0.9058      1718\n",
      "\n",
      "    accuracy                         0.8850      2844\n",
      "   macro avg     0.8815    0.8771    0.8791      2844\n",
      "weighted avg     0.8846    0.8850    0.8847      2844\n",
      "\n",
      "tensor([0.1520]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_focal_256/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e3af45a-5bf4-485e-99c4-1519de0f35d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7202    0.8371    0.7743      2106\n",
      "          正常     0.8799    0.7858    0.8302      3198\n",
      "\n",
      "    accuracy                         0.8062      5304\n",
      "   macro avg     0.8000    0.8115    0.8022      5304\n",
      "weighted avg     0.8165    0.8062    0.8080      5304\n",
      "\n",
      "tensor([0.0912]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 125.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.6115    0.3245    0.4240       718\n",
      "          正常     0.8019    0.9299    0.8612      2111\n",
      "\n",
      "    accuracy                         0.7762      2829\n",
      "   macro avg     0.7067    0.6272    0.6426      2829\n",
      "weighted avg     0.7536    0.7762    0.7502      2829\n",
      "\n",
      "tensor([0.0236]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 126.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.8976    0.9795    0.9368       779\n",
      "          讽刺     0.3600    0.0938    0.1488        96\n",
      "\n",
      "    accuracy                         0.8823       875\n",
      "   macro avg     0.6288    0.5366    0.5428       875\n",
      "weighted avg     0.8387    0.8823    0.8503       875\n",
      "\n",
      "tensor([0.0214]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 121.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8849    0.8820    0.8834       593\n",
      "          负向     0.8851    0.8880    0.8865       607\n",
      "\n",
      "    accuracy                         0.8850      1200\n",
      "   macro avg     0.8850    0.8850    0.8850      1200\n",
      "weighted avg     0.8850    0.8850    0.8850      1200\n",
      "\n",
      "tensor([0.0228]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:19<00:00, 126.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.7964    0.8010    0.7987      1201\n",
      "          负向     0.8191    0.8148    0.8169      1328\n",
      "\n",
      "    accuracy                         0.8082      2529\n",
      "   macro avg     0.8077    0.8079    0.8078      2529\n",
      "weighted avg     0.8083    0.8082    0.8082      2529\n",
      "\n",
      "tensor([0.0255]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 126.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8475    0.8144    0.8306      1126\n",
      "          负向     0.8814    0.9040    0.8925      1718\n",
      "\n",
      "    accuracy                         0.8685      2844\n",
      "   macro avg     0.8644    0.8592    0.8616      2844\n",
      "weighted avg     0.8680    0.8685    0.8680      2844\n",
      "\n",
      "tensor([0.0368]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_contrast_intent_v1/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d21ccffe-66ff-4772-88de-6ab24412153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ece_fn = ECE(n_bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32cc476b-9973-4b61-8b05-85cdca4a3e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1104])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict = {\n",
    "    '冒犯':0,\n",
    "    '正常':1\n",
    "}\n",
    "\n",
    "gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "pred_score_l = torch.tensor([[item[0][1], item[1][1]] for item in pred_score])\n",
    "\n",
    "ece_fn(pred_score_l, gold_l, mode='probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f8d4490-f58a-441f-95fa-f38238cc70bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0198])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict = {\n",
    "    '负向':0,\n",
    "    '正向':1\n",
    "}\n",
    "\n",
    "gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "pred_score_l = torch.tensor([[item[0][1], item[1][1]] for item in pred_score])\n",
    "\n",
    "ece_fn(pred_score_l, gold_l, mode='probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32e811-a4a8-4415-b2d5-ef3d3c89ffd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
