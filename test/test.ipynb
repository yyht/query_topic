{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c24b51-0baf-4855-baac-3ee4010c944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys,os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ff23bc-1588-42e5-959e-a45d4b3d7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.extend(['/root/xiaoda/query_topic/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25da71ce-1bec-4327-acd7-c3dd78414f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "https://github.com/ondrejbohdal/meta-calibration/blob/main/Metrics/metrics.py\n",
    "\"\"\"\n",
    "\n",
    "class ECE(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(ECE, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels, mode='logits'):\n",
    "        if mode == 'logits':\n",
    "            softmaxes = F.softmax(logits, dim=1)\n",
    "        else:\n",
    "            softmaxes = logits\n",
    "        # softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        \n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cbfd143-9337-4fea-aad8-cf2851192471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senti_query /root/xiaoda/query_topic/risk_data_v5/senti_query_label.txt ===schema-path===\n",
      "{'label2id': {'负向': 0, '中性': 1, '正向': 2}, 'id2label': {0: '负向', 1: '中性', 2: '正向'}, 'label_index': 0} ==schema_type== senti_query\n",
      "senti /root/xiaoda/query_topic/risk_data_v5/senti_label.txt ===schema-path===\n",
      "{'label2id': {'负向': 0, '正向': 1}, 'id2label': {0: '负向', 1: '正向'}, 'label_index': 1} ==schema_type== senti\n",
      "bias /root/xiaoda/query_topic/risk_data_v5/bias_label.txt ===schema-path===\n",
      "{'label2id': {'偏见': 0, '正常': 1}, 'id2label': {0: '偏见', 1: '正常'}, 'label_index': 2} ==schema_type== bias\n",
      "ciron /root/xiaoda/query_topic/risk_data_v5/ciron_label.txt ===schema-path===\n",
      "{'label2id': {'讽刺': 0, '正常': 1}, 'id2label': {0: '讽刺', 1: '正常'}, 'label_index': 3} ==schema_type== ciron\n",
      "intent /root/xiaoda/query_topic/risk_data_v5/intention_label_v0.txt ===schema-path===\n",
      "{'label2id': {'主观评价/比较/判断': 0, '寻求建议/帮助': 1, '其它': 2}, 'id2label': {0: '主观评价/比较/判断', 1: '寻求建议/帮助', 2: '其它'}, 'label_index': 4} ==schema_type== intent\n",
      "offensive /root/xiaoda/query_topic/risk_data_v5/offensive_label.txt ===schema-path===\n",
      "{'label2id': {'冒犯': 0, '正常': 1}, 'id2label': {0: '冒犯', 1: '正常'}, 'label_index': 5} ==schema_type== offensive\n",
      "query_risk /root/xiaoda/query_topic/risk_data_v5/query_risk_label.txt ===schema-path===\n",
      "{'label2id': {'风险': 0, '个人信息': 1, '正常': 2}, 'id2label': {0: '风险', 1: '个人信息', 2: '正常'}, 'label_index': 6} ==schema_type== query_risk\n",
      "teenager /root/xiaoda/query_topic/risk_data_v5/teenager_label.txt ===schema-path===\n",
      "{'label2id': {'不良': 0, '正常': 1}, 'id2label': {0: '不良', 1: '正常'}, 'label_index': 7} ==schema_type== teenager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/27/2022 08:18:06 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/27/2022 08:18:06 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/27/2022 08:18:06 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/27/2022 08:18:06 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/27/2022 08:18:06 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/27/2022 08:18:06 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/27/2022 08:18:06 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/27/2022 08:18:06 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizerFast\n",
    "import transformers\n",
    "from datetime import timedelta\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from nets.them_classifier import MyBaseModel, RobertaClassifier\n",
    "\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "\n",
    "cur_dir_path = '/root/xiaoda/query_topic/'\n",
    "\n",
    "def load_label(filepath):\n",
    "    label_list = []\n",
    "    with open(filepath, 'r') as frobj:\n",
    "        for line in frobj:\n",
    "            label_list.append(line.strip())\n",
    "        n_classes = len(label_list)\n",
    "\n",
    "        label2id = {}\n",
    "        id2label = {}\n",
    "        for idx, label in enumerate(label_list):\n",
    "            label2id[label] = idx\n",
    "            id2label[idx] = label\n",
    "        return label2id, id2label\n",
    "\n",
    "class RiskInfer(object):\n",
    "    def __init__(self, config_path):\n",
    "\n",
    "        import torch, os, sys\n",
    "\n",
    "        con = configparser.ConfigParser()\n",
    "        con_path = os.path.join(cur_dir_path, config_path)\n",
    "        con.read(con_path, encoding='utf8')\n",
    "\n",
    "        args_path = dict(dict(con.items('paths')), **dict(con.items(\"para\")))\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(args_path[\"model_path\"], do_lower_case=True)\n",
    "\n",
    "        from collections import OrderedDict\n",
    "        self.schema_dict = OrderedDict({})\n",
    "\n",
    "        for label_index, schema_info in enumerate(args_path[\"label_path\"].split(',')):\n",
    "            schema_type, schema_path = schema_info.split(':')\n",
    "            schema_path = os.path.join(cur_dir_path, schema_path)\n",
    "            print(schema_type, schema_path, '===schema-path===')\n",
    "            label2id, id2label = load_label(schema_path)\n",
    "            self.schema_dict[schema_type] = {\n",
    "                'label2id':label2id,\n",
    "                'id2label':id2label,\n",
    "                'label_index':label_index\n",
    "            }\n",
    "            print(self.schema_dict[schema_type], '==schema_type==', schema_type)\n",
    "        \n",
    "        output_path = os.path.join(cur_dir_path, args_path['output_path'])\n",
    "\n",
    "        from roformer import RoFormerModel, RoFormerConfig\n",
    "\n",
    "        config = RoFormerConfig.from_pretrained(args_path[\"model_path\"])\n",
    "        encoder = RoFormerModel(config=config)\n",
    "        \n",
    "        encoder_net = MyBaseModel(encoder, config)\n",
    "\n",
    "        self.device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        classifier_list = []\n",
    "\n",
    "        schema_list = list(self.schema_dict.keys())\n",
    "\n",
    "        for schema_key in schema_list:\n",
    "            classifier = RobertaClassifier(\n",
    "                hidden_size=config.hidden_size, \n",
    "                dropout_prob=con.getfloat('para', 'out_dropout_rate'),\n",
    "                num_labels=len(self.schema_dict[schema_key]['label2id']), \n",
    "                dropout_type=con.get('para', 'dropout_type'))\n",
    "            classifier_list.append(classifier)\n",
    "\n",
    "        classifier_list = nn.ModuleList(classifier_list)\n",
    "\n",
    "        class MultitaskClassifier(nn.Module):\n",
    "            def __init__(self, transformer, classifier_list):\n",
    "                super().__init__()\n",
    "\n",
    "                self.transformer = transformer\n",
    "                self.classifier_list = classifier_list\n",
    "\n",
    "            def forward(self, input_ids, input_mask, \n",
    "                        segment_ids=None, \n",
    "                        transformer_mode='mean_pooling', \n",
    "                        dt_idx=None):\n",
    "                hidden_states = self.transformer(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              return_mode=transformer_mode)\n",
    "                outputs_list = []\n",
    "                \n",
    "                for idx, classifier in enumerate(self.classifier_list):\n",
    "                    \n",
    "                    if dt_idx is not None and idx != dt_idx:\n",
    "                        continue\n",
    "                    \n",
    "                    ce_logits = classifier(hidden_states)\n",
    "                    outputs_list.append(ce_logits)\n",
    "                return outputs_list, hidden_states\n",
    "\n",
    "        self.net = MultitaskClassifier(encoder_net, classifier_list).to(self.device)\n",
    "\n",
    "        # eo = 9\n",
    "        # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw.focal'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_contrast_cls.pth.{}'.format(eo)), map_location=self.device)\n",
    "        # self.net.load_state_dict(ckpt)\n",
    "        # self.net.eval()\n",
    "        \n",
    "    def reload(self, model_path):\n",
    "        ckpt = torch.load(model_path, map_location=self.device)\n",
    "        self.net.load_state_dict(ckpt)\n",
    "        self.net.eval()\n",
    "\n",
    "    def predict(self, text):\n",
    "\n",
    "        \"\"\"抽取输入text所包含的类型\n",
    "        \"\"\"\n",
    "        encoder_txt = self.tokenizer.encode_plus(text, max_length=256)\n",
    "        input_ids = torch.tensor(encoder_txt[\"input_ids\"]).long().unsqueeze(0).to(self.device)\n",
    "        token_type_ids = torch.tensor(encoder_txt[\"token_type_ids\"]).unsqueeze(0).to(self.device)\n",
    "        attention_mask = torch.tensor(encoder_txt[\"attention_mask\"]).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        scores_dict = {}\n",
    "        with torch.no_grad():\n",
    "            [logits_list, \n",
    "            hidden_states] = self.net(input_ids, \n",
    "                attention_mask, token_type_ids, transformer_mode='cls')\n",
    "        for schema_type, logits in zip(list(self.schema_dict.keys()), logits_list):\n",
    "            scores = torch.nn.Softmax(dim=1)(logits)[0].data.cpu().numpy()\n",
    "            scores_dict[schema_type] = []\n",
    "            for index, score in enumerate(scores):\n",
    "                scores_dict[schema_type].append([self.schema_dict[schema_type]['id2label'][index], \n",
    "                                        float(score)])\n",
    "        return scores_dict\n",
    "    \n",
    "    def predict_batch(self, text):\n",
    "        if isinstance(text, list):\n",
    "            text_list = text\n",
    "        else:\n",
    "            text_list = [text]\n",
    "        model_input = self.tokenizer(text_list, return_tensors=\"pt\",padding=True)\n",
    "        for key in model_input:\n",
    "            model_input[key] = model_input[key].to(self.device)\n",
    "        with torch.no_grad():\n",
    "            [logits_list, \n",
    "            hidden_states] = self.net(model_input['input_ids'], \n",
    "                model_input['attention_mask'], \n",
    "                model_input['token_type_ids'], transformer_mode='cls')\n",
    "        score_dict_list = []\n",
    "        for idx, text in enumerate(text_list):\n",
    "            scores_dict = {}\n",
    "            for schema_type, logits in zip(list(self.schema_dict.keys()), logits_list):\n",
    "                scores = torch.nn.Softmax(dim=1)(logits)[idx].data.cpu().numpy()\n",
    "                scores_dict[schema_type] = []\n",
    "                for index, score in enumerate(scores):\n",
    "                    scores_dict[schema_type].append([self.schema_dict[schema_type]['id2label'][index], \n",
    "                                            float(score)])\n",
    "            score_dict_list.append(scores_dict)\n",
    "        return score_dict_list\n",
    "\n",
    "# risk_api = RiskInfer('./risk_data/config.ini')\n",
    "risk_api = RiskInfer('./risk_data_v5/config.ini')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fad1e25-e3e7-4440-a3b9-4fb290a3a8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9965"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "l = 0\n",
    "reader = csv.reader(open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/Query风险分类_全部数据.csv'), delimiter=\"\\t\", quotechar=None)\n",
    "for idx, item in enumerate(reader):\n",
    "    # print(item)\n",
    "    l += 1\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf80f7-c2d9-4bda-80e6-c2c95245d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/albert.xht/pretrained_model_risk/corpus/efaqa-corpus-zh/efaqa-corpus-zh.utf8\", \"r\") as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        title = ''.join(re.split('[\\s,]', content['title'])[1:])\n",
    "        if len(title) >= 5:\n",
    "            if  s3_mapping[content['label']['s3']] in ['正在进行的自杀行为', '策划进行的自杀行为', '自残']:\n",
    "                tmp = {\n",
    "                    'title':title,\n",
    "                    'label':['风险']\n",
    "                }\n",
    "                print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb6923a2-fe55-4610-bf75-36fe3a90dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v5_intent_v2_3/multitask_cls.pth.4')\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v5_intent_v2-1_3//multitask_cls.pth.4')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v6_intent_v2-1_10/multitask_cls.pth.6')\n",
    "\n",
    "risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v6_intent_v2-1_10_no_symbol/multitask_cls.pth.5')\n",
    "\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v6_no_offensive_intent_v2-1_10//multitask_cls.pth.6')\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v5_no_offensive_intent_v2-1_3/multitask_cls.pth.4')\n",
    "\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a016e9d-7b74-40e4-b7e9-159a2be0a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_inference(input_path, output_path):\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "    import json, re\n",
    "\n",
    "    def risk_predict_batch(text):\n",
    "        if isinstance(text, list):\n",
    "            text_list = text\n",
    "        else:\n",
    "            text_list = [text]\n",
    "        result_list = risk_api.predict_batch(text_list)\n",
    "        return result_list\n",
    "    \n",
    "    print(input_path, '===input-path===')\n",
    "    print(output_path, '===output-path===')\n",
    "    \n",
    "    with open(output_path, 'w') as fwobj:\n",
    "        with open(input_path, 'r') as frobj:\n",
    "            queue = []\n",
    "            t = []\n",
    "            for line in tqdm(frobj):\n",
    "                content = json.loads(line.strip())\n",
    "                content['text'] = re.sub('请问', '', content['text'])\n",
    "                text = re.sub(r\"([，\\_《。》、？；：‘’＂“”【「】」·！@￥…（）—\\,\\<\\.\\>\\/\\?\\;\\:\\'\\\"\\[\\]\\{\\}\\~\\`\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\-\\=\\+])+\", \"\", content['text'])   # 合并正文中过多的空格\n",
    "                queue.append(text)\n",
    "                t.append(content)\n",
    "                if np.mod(len(queue), 512) == 0:\n",
    "                    probs = risk_predict_batch(queue)\n",
    "                    for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                        content = {\n",
    "                            'text':tt['text'],\n",
    "                            'topic':tt['label'],\n",
    "                            'score_list':prob_dict,\n",
    "                            # 'score_list': tt['score_list']\n",
    "                        }\n",
    "                        fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                    queue = []\n",
    "                    t = []\n",
    "            if queue:\n",
    "                probs = risk_predict_batch(queue)\n",
    "                for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                    content = {\n",
    "                        'text':tt['text'],\n",
    "                        'topic':tt['label'],\n",
    "                        'score_list':prob_dict,\n",
    "                        # 'score_list': tt['score_list']\n",
    "                    }\n",
    "                    fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbe1dff7-d2dc-4e9b-9386-ebdfec9e4dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json ===input-path===\n",
      "/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk.v6 ===output-path===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2071401it [29:41, 1162.82it/s]\n"
     ]
    }
   ],
   "source": [
    "input_path = '/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json'\n",
    "output_path = '/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk.v6'\n",
    "\n",
    "\n",
    "batch_inference(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78f5eed3-f87a-4751-b53c-749b38682441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2071401it [01:29, 23231.96it/s]\n"
     ]
    }
   ],
   "source": [
    "black = []\n",
    "white = []\n",
    "\n",
    "with open(output_path) as frobj:\n",
    "    for line in tqdm(frobj):\n",
    "        content = json.loads(line.strip())\n",
    "        if content['score_list']['query_risk'][0][1] > 0.9:\n",
    "            black.append(content)\n",
    "        else:\n",
    "            white.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "633c6525-33ca-4899-93d0-877ccb241ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '现代医学已经发展到了什么恐怖的水平？',\n",
       "  'topic': ['健康'],\n",
       "  'score_list': {'senti_query': [['负向', 0.7500477433204651],\n",
       "    ['中性', 0.2268967479467392],\n",
       "    ['正向', 0.02305549569427967]],\n",
       "   'senti': [['负向', 0.9985207915306091], ['正向', 0.0014792227884754539]],\n",
       "   'bias': [['偏见', 0.0899629145860672], ['正常', 0.910037100315094]],\n",
       "   'ciron': [['讽刺', 0.13127018511295319], ['正常', 0.868729829788208]],\n",
       "   'intent': [['主观评价/比较/判断', 0.11349240690469742],\n",
       "    ['寻求建议/帮助', 0.001357473200187087],\n",
       "    ['其它', 0.8851500749588013]],\n",
       "   'offensive': [['冒犯', 0.9177260398864746], ['正常', 0.08227396011352539]],\n",
       "   'query_risk': [['风险', 0.9998883008956909],\n",
       "    ['个人信息', 4.695604275184451e-06],\n",
       "    ['正常', 0.00010706200555432588]],\n",
       "   'teenager': [['不良', 0.27327635884284973], ['正常', 0.7267236113548279]]}},\n",
       " {'text': '同样作为亚洲经济强国的韩国和日本，为什么在文化输出方面能力上后者远远强于前者？',\n",
       "  'topic': ['国家'],\n",
       "  'score_list': {'senti_query': [['负向', 0.0009883948368951678],\n",
       "    ['中性', 0.02751978300511837],\n",
       "    ['正向', 0.9714917540550232]],\n",
       "   'senti': [['负向', 0.18635600805282593], ['正向', 0.8136439919471741]],\n",
       "   'bias': [['偏见', 0.07156478613615036], ['正常', 0.928435206413269]],\n",
       "   'ciron': [['讽刺', 0.27409228682518005], ['正常', 0.7259076833724976]],\n",
       "   'intent': [['主观评价/比较/判断', 0.9999698400497437],\n",
       "    ['寻求建议/帮助', 1.0468299478816334e-05],\n",
       "    ['其它', 1.9684413928189315e-05]],\n",
       "   'offensive': [['冒犯', 0.044655609875917435], ['正常', 0.9553444385528564]],\n",
       "   'query_risk': [['风险', 0.9959877133369446],\n",
       "    ['个人信息', 8.077738311840221e-05],\n",
       "    ['正常', 0.003931485582143068]],\n",
       "   'teenager': [['不良', 0.05053727328777313], ['正常', 0.9494627714157104]]}},\n",
       " {'text': '用「国人若有权，人人皆是贪」来反驳说贪官多的人，正确吗？',\n",
       "  'topic': ['时事政治'],\n",
       "  'score_list': {'senti_query': [['负向', 0.9154496192932129],\n",
       "    ['中性', 0.0785006582736969],\n",
       "    ['正向', 0.006049764808267355]],\n",
       "   'senti': [['负向', 0.9975728392601013], ['正向', 0.0024271090514957905]],\n",
       "   'bias': [['偏见', 0.2646411955356598], ['正常', 0.7353588342666626]],\n",
       "   'ciron': [['讽刺', 0.7949758172035217], ['正常', 0.20502419769763947]],\n",
       "   'intent': [['主观评价/比较/判断', 0.33192336559295654],\n",
       "    ['寻求建议/帮助', 0.6672881841659546],\n",
       "    ['其它', 0.0007884444203227758]],\n",
       "   'offensive': [['冒犯', 0.9353055953979492], ['正常', 0.0646943598985672]],\n",
       "   'query_risk': [['风险', 0.9982208609580994],\n",
       "    ['个人信息', 5.332939690561034e-05],\n",
       "    ['正常', 0.001725824666209519]],\n",
       "   'teenager': [['不良', 0.6352533102035522], ['正常', 0.364746630191803]]}},\n",
       " {'text': '如何看待「曝光一个上戏学生，他用airbnb毁了我整个家」事件？',\n",
       "  'topic': ['法律'],\n",
       "  'score_list': {'senti_query': [['负向', 0.9982466697692871],\n",
       "    ['中性', 0.001672834507189691],\n",
       "    ['正向', 8.05719246272929e-05]],\n",
       "   'senti': [['负向', 0.9988334774971008], ['正向', 0.0011664811754599214]],\n",
       "   'bias': [['偏见', 0.039184629917144775], ['正常', 0.9608153700828552]],\n",
       "   'ciron': [['讽刺', 0.27312982082366943], ['正常', 0.7268701791763306]],\n",
       "   'intent': [['主观评价/比较/判断', 0.9998568296432495],\n",
       "    ['寻求建议/帮助', 3.007725354109425e-05],\n",
       "    ['其它', 0.00011313513823552057]],\n",
       "   'offensive': [['冒犯', 0.7529451251029968], ['正常', 0.24705487489700317]],\n",
       "   'query_risk': [['风险', 0.9954233765602112],\n",
       "    ['个人信息', 4.363837433629669e-05],\n",
       "    ['正常', 0.004532995633780956]],\n",
       "   'teenager': [['不良', 0.3574434518814087], ['正常', 0.6425565481185913]]}},\n",
       " {'text': '大家如何看待新闻《中国人被IS杀害:韩国人忽悠中国90后赴巴传教》？',\n",
       "  'topic': ['宗教'],\n",
       "  'score_list': {'senti_query': [['负向', 0.9974353909492493],\n",
       "    ['中性', 0.0025002318434417248],\n",
       "    ['正向', 6.44336614641361e-05]],\n",
       "   'senti': [['负向', 0.9961677193641663], ['正向', 0.0038322010077536106]],\n",
       "   'bias': [['偏见', 0.3687199354171753], ['正常', 0.6312801241874695]],\n",
       "   'ciron': [['讽刺', 0.4151408076286316], ['正常', 0.5848592519760132]],\n",
       "   'intent': [['主观评价/比较/判断', 0.9997580647468567],\n",
       "    ['寻求建议/帮助', 0.00023612813674844801],\n",
       "    ['其它', 5.837776825501351e-06]],\n",
       "   'offensive': [['冒犯', 0.9928230047225952], ['正常', 0.0071769459173083305]],\n",
       "   'query_risk': [['风险', 0.9997017979621887],\n",
       "    ['个人信息', 0.00023068727750796825],\n",
       "    ['正常', 6.740294338669628e-05]],\n",
       "   'teenager': [['不良', 0.3870946764945984], ['正常', 0.6129053235054016]]}},\n",
       " {'text': '为什么在网络上口碑不佳的华为，现实中的销量却相当好？',\n",
       "  'topic': ['电脑/网络'],\n",
       "  'score_list': {'senti_query': [['负向', 0.28289759159088135],\n",
       "    ['中性', 0.5045647621154785],\n",
       "    ['正向', 0.21253769099712372]],\n",
       "   'senti': [['负向', 0.755582332611084], ['正向', 0.2444176971912384]],\n",
       "   'bias': [['偏见', 0.23455344140529633], ['正常', 0.7654466032981873]],\n",
       "   'ciron': [['讽刺', 0.3283149003982544], ['正常', 0.6716850996017456]],\n",
       "   'intent': [['主观评价/比较/判断', 0.996800422668457],\n",
       "    ['寻求建议/帮助', 0.003088641446083784],\n",
       "    ['其它', 0.00011088130122516304]],\n",
       "   'offensive': [['冒犯', 0.2234550416469574], ['正常', 0.7765449285507202]],\n",
       "   'query_risk': [['风险', 0.9856501221656799],\n",
       "    ['个人信息', 0.00022764308960177004],\n",
       "    ['正常', 0.01412232592701912]],\n",
       "   'teenager': [['不良', 0.24436403810977936], ['正常', 0.7556359767913818]]}},\n",
       " {'text': '如何评价歼8系列战机？',\n",
       "  'topic': ['军事'],\n",
       "  'score_list': {'senti_query': [['负向', 9.12424293346703e-05],\n",
       "    ['中性', 0.00222346861846745],\n",
       "    ['正向', 0.9976853132247925]],\n",
       "   'senti': [['负向', 0.12898457050323486], ['正向', 0.8710154891014099]],\n",
       "   'bias': [['偏见', 0.2973909378051758], ['正常', 0.7026090025901794]],\n",
       "   'ciron': [['讽刺', 0.04959198459982872], ['正常', 0.9504079818725586]],\n",
       "   'intent': [['主观评价/比较/判断', 0.999961256980896],\n",
       "    ['寻求建议/帮助', 2.2738289771950804e-05],\n",
       "    ['其它', 1.59246501425514e-05]],\n",
       "   'offensive': [['冒犯', 0.08888380229473114], ['正常', 0.9111162424087524]],\n",
       "   'query_risk': [['风险', 0.994978129863739],\n",
       "    ['个人信息', 0.00020288299128878862],\n",
       "    ['正常', 0.0048190755769610405]],\n",
       "   'teenager': [['不良', 0.12417486310005188], ['正常', 0.8758251667022705]]}},\n",
       " {'text': '日本人看到《血战钢锯岭》是什么体验？',\n",
       "  'topic': ['影视'],\n",
       "  'score_list': {'senti_query': [['负向', 0.020481029525399208],\n",
       "    ['中性', 0.26255959272384644],\n",
       "    ['正向', 0.7169593572616577]],\n",
       "   'senti': [['负向', 0.9674106240272522], ['正向', 0.03258943185210228]],\n",
       "   'bias': [['偏见', 0.05311315506696701], ['正常', 0.9468868374824524]],\n",
       "   'ciron': [['讽刺', 0.1891174018383026], ['正常', 0.810882568359375]],\n",
       "   'intent': [['主观评价/比较/判断', 0.01718316413462162],\n",
       "    ['寻求建议/帮助', 4.739181895274669e-05],\n",
       "    ['其它', 0.9827693700790405]],\n",
       "   'offensive': [['冒犯', 0.046665776520967484], ['正常', 0.9533342123031616]],\n",
       "   'query_risk': [['风险', 0.9890215992927551],\n",
       "    ['个人信息', 4.356405042926781e-05],\n",
       "    ['正常', 0.010934907011687756]],\n",
       "   'teenager': [['不良', 0.10416848957538605], ['正常', 0.8958315849304199]]}},\n",
       " {'text': '为什么只要提到东突恐怖分子就能和土耳其扯上关系？土耳其在中东极端组织中的作用到底是什么？',\n",
       "  'topic': ['国家'],\n",
       "  'score_list': {'senti_query': [['负向', 0.9115643501281738],\n",
       "    ['中性', 0.08677444607019424],\n",
       "    ['正向', 0.001661231741309166]],\n",
       "   'senti': [['负向', 0.9989359974861145], ['正向', 0.0010640262626111507]],\n",
       "   'bias': [['偏见', 0.2669690251350403], ['正常', 0.7330309152603149]],\n",
       "   'ciron': [['讽刺', 0.5066074728965759], ['正常', 0.4933924973011017]],\n",
       "   'intent': [['主观评价/比较/判断', 0.53594571352005],\n",
       "    ['寻求建议/帮助', 0.365390419960022],\n",
       "    ['其它', 0.09866393357515335]],\n",
       "   'offensive': [['冒犯', 0.997826874256134], ['正常', 0.00217312085442245]],\n",
       "   'query_risk': [['风险', 0.9998751878738403],\n",
       "    ['个人信息', 0.00011511531920405105],\n",
       "    ['正常', 9.64657920121681e-06]],\n",
       "   'teenager': [['不良', 0.5321708917617798], ['正常', 0.4678290784358978]]}},\n",
       " {'text': '为何对此次王菲谢霆锋的复活网上骂声一片？',\n",
       "  'topic': ['娱乐'],\n",
       "  'score_list': {'senti_query': [['负向', 0.9951606392860413],\n",
       "    ['中性', 0.004487998317927122],\n",
       "    ['正向', 0.00035133998608216643]],\n",
       "   'senti': [['负向', 0.9965305924415588], ['正向', 0.003469458781182766]],\n",
       "   'bias': [['偏见', 0.012910661287605762], ['正常', 0.9870893359184265]],\n",
       "   'ciron': [['讽刺', 0.03845899924635887], ['正常', 0.9615410566329956]],\n",
       "   'intent': [['主观评价/比较/判断', 0.9815438985824585],\n",
       "    ['寻求建议/帮助', 0.008040621876716614],\n",
       "    ['其它', 0.010415439493954182]],\n",
       "   'offensive': [['冒犯', 0.12746883928775787], ['正常', 0.8725311756134033]],\n",
       "   'query_risk': [['风险', 0.9802093505859375],\n",
       "    ['个人信息', 8.5998690337874e-05],\n",
       "    ['正常', 0.01970464549958706]],\n",
       "   'teenager': [['不良', 0.30340221524238586], ['正常', 0.6965978145599365]]}}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8a9e3081-3327-4522-a309-908bc73666cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_dict = {}\n",
    "from collections import Counter\n",
    "t = Counter()\n",
    "for d in white:\n",
    "    t[d['topic'][0]] += 1\n",
    "    if d['topic'][0] not in white_dict:\n",
    "        white_dict[d['topic'][0]] = []\n",
    "    white_dict[d['topic'][0]].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0cb75500-586b-4352-b25a-2626f8ff490e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'senti_query': [['负向', 0.9854410290718079],\n",
       "  ['中性', 0.014096961356699467],\n",
       "  ['正向', 0.0004620045074261725]],\n",
       " 'senti': [['负向', 0.9976153373718262], ['正向', 0.002384644001722336]],\n",
       " 'bias': [['偏见', 0.03199134021997452], ['正常', 0.9680086374282837]],\n",
       " 'ciron': [['讽刺', 0.26645970344543457], ['正常', 0.7335402369499207]],\n",
       " 'intent': [['主观评价/比较/判断', 0.05716642737388611],\n",
       "  ['寻求建议/帮助', 0.011795553378760815],\n",
       "  ['其它', 0.9310380220413208]],\n",
       " 'offensive': [['冒犯', 0.6193205714225769], ['正常', 0.3806794583797455]],\n",
       " 'query_risk': [['风险', 0.9945979118347168],\n",
       "  ['个人信息', 6.596983439521864e-05],\n",
       "  ['正常', 0.00533616216853261]],\n",
       " 'teenager': [['不良', 0.10363443195819855], ['正常', 0.8963655233383179]]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_api.predict('美国的参议员为什么不交给众议院来选举')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "67236c16-3d55-4b99-8e63-7966c02c0113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[unused1]', '后的数据规范环境', '[unused2]', 'gsdhkjsgaf', '[unused2]', '[SEP]']"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.split('(\\\\[unused\\d+\\\\])', '[unused1]后的数据规范环境[unused2]gsdhkjsgaf[unused2][SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "d5e48192-3ca8-4424-94f9-d48c9bbd3746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [], 'token_type_ids': [], 'attention_mask': []}"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_api.tokenizer('', add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "586e1d4e-17fb-43f6-8c6c-eb6bc4fd4b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2071401it [30:34, 1129.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json, re\n",
    "\n",
    "def risk_predict_batch(text):\n",
    "    if isinstance(text, list):\n",
    "        text_list = text\n",
    "    else:\n",
    "        text_list = [text]\n",
    "    result_list = risk_api.predict_batch(text_list)\n",
    "    return result_list\n",
    "\n",
    "# with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk', 'w') as fwobj:\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.all_risk_v5', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json', 'r') as frobj:\n",
    "        queue = []\n",
    "        t = []\n",
    "        for line in tqdm(frobj):\n",
    "            content = json.loads(line.strip())\n",
    "            content['text'] = re.sub('请问', '', content['text'])\n",
    "            queue.append(content['text'])\n",
    "            t.append(content)\n",
    "            if np.mod(len(queue), 512) == 0:\n",
    "                probs = risk_predict_batch(queue)\n",
    "                for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                    content = {\n",
    "                        'text':text,\n",
    "                        'topic':tt['label'],\n",
    "                        'score_list':prob_dict\n",
    "                    }\n",
    "                    fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                queue = []\n",
    "                t = []\n",
    "        if queue:\n",
    "            probs = risk_predict_batch(queue)\n",
    "            for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                content = {\n",
    "                    'text':text,\n",
    "                    'topic':tt['label'],\n",
    "                    'score_list':prob_dict\n",
    "                }\n",
    "                fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7ee70904-41cf-4aa4-8ecd-86bbe3b4823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15414it [00:14, 1069.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json, re\n",
    "\n",
    "def risk_predict_batch(text):\n",
    "    if isinstance(text, list):\n",
    "        text_list = text\n",
    "    else:\n",
    "        text_list = [text]\n",
    "    result_list = risk_api.predict_batch(text_list)\n",
    "    return result_list\n",
    "\n",
    "offensive = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.offensive.all', 'r') as frobj:\n",
    "    queue = []\n",
    "    t = []\n",
    "    for line in tqdm(frobj):\n",
    "        content = json.loads(line.strip())\n",
    "        content['text'] = re.sub('请问', '', content['text'])\n",
    "        queue.append(content['text'])\n",
    "        t.append(content)\n",
    "        if np.mod(len(queue), 512) == 0:\n",
    "            probs = risk_predict_batch(queue)\n",
    "            for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                content = {\n",
    "                    'text':text,\n",
    "                    'topic':tt['label'],\n",
    "                    'score_list':prob_dict\n",
    "                }\n",
    "                offensive.append(content)\n",
    "            queue = []\n",
    "            t = []\n",
    "    if queue:\n",
    "        probs = risk_predict_batch(queue)\n",
    "        for prob_dict, text, tt in zip(probs, queue, t):\n",
    "            content = {\n",
    "                'text':text,\n",
    "                'topic':tt['label'],\n",
    "                'score_list':prob_dict\n",
    "            }\n",
    "            offensive.append(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bfdece-5835-4d7c-80bc-373d2698a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.white', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json', 'r') as frobj:\n",
    "        data_dict = {}\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['text'] not in data_dict:\n",
    "                data_dict[content['text']] = []\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f93dbbc3-5517-4736-8cf1-b3b57a771f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json, re\n",
    "\n",
    "def risk_predict_batch(text):\n",
    "    if isinstance(text, list):\n",
    "        text_list = text\n",
    "    else:\n",
    "        text_list = [text]\n",
    "    result_list = risk_api.predict_batch(text_list)\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de843f4c-6f21-485b-b31c-5925c1e743a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_api.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889bd0b-0c26-4c80-8a75-2d962c79dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json, re\n",
    "\n",
    "def risk_predict_batch(text):\n",
    "    if isinstance(text, list):\n",
    "        text_list = text\n",
    "    else:\n",
    "        text_list = [text]\n",
    "    result_list = risk_api.predict_batch(text_list)\n",
    "    return result_list\n",
    "\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.bias_ciron', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json', 'r') as frobj:\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['label'][0] not in data_dict:\n",
    "                data_dict[content['label'][0]] = []\n",
    "            data_dict[content['label'][0]].append(content)\n",
    "\n",
    "    train_sample = []\n",
    "    import random\n",
    "    for key in data_dict:\n",
    "        random.shuffle(data_dict[key])\n",
    "        train_sample.extend(data_dict[key][:int(0.2*len(data_dict[key]))])\n",
    "    cnt = 1\n",
    "    queue = []\n",
    "    for content in tqdm(train_sample):\n",
    "        content['text'] = re.sub('请问', '', content['text'])\n",
    "        queue.append(content['text'])\n",
    "        if np.mod(len(queue), 256) == 0:\n",
    "            probs = risk_predict_batch(queue)\n",
    "            for prob_dict, text in zip(probs, queue):\n",
    "                score_list = []\n",
    "                for key in ['bias', 'ciron', 'teenager']:\n",
    "                    if prob_dict[key][0][1] > 0.9:\n",
    "                        score_list.append([key, float(prob_dict[key][0][1])])\n",
    "                key = 'query_risk'\n",
    "                if prob_dict[key][0][1] > 0.9:\n",
    "                    score_list.append([prob_dict[key][0][0], float(prob_dict[key][0][1])])\n",
    "                if prob_dict[key][1][1] > 0.9:\n",
    "                    score_list.append([prob_dict[key][1][0], float(prob_dict[key][1][1])])\n",
    "                if score_list:\n",
    "                    content = {\n",
    "                        'text':text,\n",
    "                        'label':['风险'],\n",
    "                        'score_list':score_list\n",
    "                    }\n",
    "                    fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "            queue = []\n",
    "    if queue:\n",
    "        probs = risk_predict_batch(queue)\n",
    "        for prob_dict, text in zip(probs, queue):\n",
    "            score_list = []\n",
    "            for key in ['bias', 'ciron', 'teenager']:\n",
    "                if prob_dict[key][0][1] > 0.9:\n",
    "                    score_list.append([key, float(prob_dict[key][0][1])])\n",
    "            key = 'query_risk'\n",
    "            if prob_dict[key][0][1] > 0.9:\n",
    "                score_list.append([prob_dict[key][0][0], float(prob_dict[key][0][1])])\n",
    "            if prob_dict[key][1][1] > 0.9:\n",
    "                score_list.append([prob_dict[key][1][0], float(prob_dict[key][1][1])])\n",
    "\n",
    "            if score_list:\n",
    "                content = {\n",
    "                    'text':text,\n",
    "                    'label':['风险'],\n",
    "                    'score_list':score_list\n",
    "                }\n",
    "                fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c16ed0d4-d106-45f3-9c69-63174922ba16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['偏见', 0.4076650142669678]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dict[key][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "848ec613-e7bb-488d-ac31-1b3b4107e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_intent_v1/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_mtdnn_ce_256/multitask_cls.pth.9')\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_contrast_intent_v1/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256_20/multitask_cls.pth.19')\n",
    "\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/query_risk_v3/multitask_raw_filter_senti_query_risk_v3/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "922a1706-eca4-49ef-a30f-ff70903cb260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56443it [07:27, 126.13it/s]\n",
      "56443it [07:29, 125.59it/s]\n",
      "56443it [07:25, 126.73it/s]\n",
      "56443it [07:25, 126.60it/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = [\n",
    "'/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256/multitask_cls.pth.9',\n",
    "'/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_intent_v1/multitask_cls.pth.9',\n",
    "'/data/albert.xht/xiaodao/risk_classification/multitask_mtdnn_ce_256/multitask_cls.pth.9',\n",
    "'/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256_20/multitask_cls.pth.19',\n",
    "]\n",
    "\n",
    "from tqdm import tqdm\n",
    "total_result = []\n",
    "for model in model_path:\n",
    "    result_list = []\n",
    "    risk_api.reload(model)\n",
    "    with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/疑似有风险query_from对话预训练数据-20221130.txt') as frobj:\n",
    "        for line in tqdm(frobj):\n",
    "            text = line.strip()\n",
    "            result = risk_api.predict(text)\n",
    "            result_list.append((text, result))\n",
    "    total_result.append(result_list)\n",
    "\n",
    "result_matrix = []\n",
    "for i in range(len(total_result[0])):\n",
    "    p = []\n",
    "    for tmp in total_result:\n",
    "        item = tmp[i]\n",
    "        for key in ['senti', 'bias', 'ciron', 'offensive', 'teenager', 'query_risk']:\n",
    "            if item[1][key][0][1] > 0.6:\n",
    "                p.append(1)\n",
    "            else:\n",
    "                p.append(0)\n",
    "    result_matrix.append(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "730555ae-2ca3-4c8c-8a88-86e8ca26f4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a1ad192a-4cb4-46b9-8ae9-9620b9e2e3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56443it [08:00, 117.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "result_list = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/疑似有风险query_from对话预训练数据-20221130.txt') as frobj:\n",
    "    for line in tqdm(frobj):\n",
    "        text = line.strip()\n",
    "        result = risk_api.predict(text)\n",
    "        result_list.append((text, result))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "0c20e17f-6b80-4c13-ab5d-ca54f63c1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_matrix = []\n",
    "for item in result_list:\n",
    "    p = []\n",
    "    for key in ['senti', 'bias', 'ciron', 'offensive', 'teenager']:\n",
    "        if item[1][key][0][1] > 0.59:\n",
    "            p.append(1)\n",
    "        else:\n",
    "            p.append(0)\n",
    "    result_matrix.append(p)\n",
    "        \n",
    "        \n",
    "# result_matrix = []\n",
    "# for item in result_list:\n",
    "#     p = []\n",
    "#     for key in ['senti', 'bias', 'ciron', 'offensive', 'teenager', 'query_risk']:\n",
    "#         if item[1][key][0][1] >= 0.6:\n",
    "#             p.append(1)\n",
    "#         else:\n",
    "#             p.append(0)\n",
    "#     result_matrix.append(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "cb6c7ddd-52ea-481e-88a4-90a16ef8e4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36067"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_matrix = np.array(result_matrix)\n",
    "votes = np.sum(result_matrix, axis=-1)\n",
    "labels = np.array(votes >= 6).astype(np.int)\n",
    "sum(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "01825f5e-623c-4b7b-88e2-25a1d2da9278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56443, 2)\n",
      "(56443, 2)\n",
      "(56443, 2)\n",
      "(56443, 2)\n",
      "(56443, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "result_matrix = np.array(result_matrix)\n",
    "\n",
    "def SIMPLE(result_matrix):\n",
    "    votes = np.sum(result_matrix, axis=-1)\n",
    "    labels = np.array(votes >= 6).astype(np.int)\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0, ccp_alpha=0.1)\n",
    "    \n",
    "    for i in range(5):\n",
    "        result = clf.fit(result_matrix, labels)\n",
    "        probs = clf.predict_proba(result_matrix)\n",
    "        print(probs.shape)\n",
    "        labels = np.argmax(probs, axis=-1)\n",
    "    return probs\n",
    "\n",
    "\n",
    "probs = SIMPLE(result_matrix)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "7b11c013-2682-44a7-8891-676e2f417832",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = []\n",
    "clean = []\n",
    "for idx in range(probs.shape[0]):\n",
    "    if probs[idx,1] >= 0.8:\n",
    "        ff.append((idx, result_list[idx], probs[idx]))\n",
    "    else:\n",
    "        clean.append((idx, result_list[idx], probs[idx]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dffa0dcb-cebe-4e4b-99b3-502f0a605aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24721it [00:22, 1076.00it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/query_risk_corpus.json.risk', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/query_risk_corpus.json', 'r') as frobj:\n",
    "        queue = []\n",
    "        t = []\n",
    "        for line in tqdm(frobj):\n",
    "            content = json.loads(line.strip())\n",
    "            # content['text'] = re.sub('请问', '', content['text'])\n",
    "            queue.append(content['text'])\n",
    "            t.append(content)\n",
    "            if np.mod(len(queue), 512) == 0:\n",
    "                probs = risk_predict_batch(queue)\n",
    "                for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                    content = {\n",
    "                        'text':text,\n",
    "                        'topic':tt['label'],\n",
    "                        'score_list':prob_dict\n",
    "                    }\n",
    "                    fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                queue = []\n",
    "                t = []\n",
    "        if queue:\n",
    "            probs = risk_predict_batch(queue)\n",
    "            for prob_dict, text, tt in zip(probs, queue, t):\n",
    "                content = {\n",
    "                    'text':text,\n",
    "                    'topic':tt['label'],\n",
    "                    'score_list':prob_dict\n",
    "                }\n",
    "                fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "7d8131b4-0222-4fd2-bf2f-70e9a664a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/albert.xht/raw_chat_corpus/model_risk_xiaoda/query_risk_corpus.json', 'w') as fwobj:\n",
    "    for item in ff:\n",
    "        tmp = {\n",
    "            'text':item[1][0],\n",
    "            'label':['风险']\n",
    "        }\n",
    "        fwobj.write(json.dumps(tmp, ensure_ascii=False)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f2892662-d000-4901-a6c4-7db24e582c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = [] \n",
    "positive = []\n",
    "for item in result_list:\n",
    "    if item[1]['senti'][0][1] >= 0.7 or item[1]['bias'][0][1] >= 0.8 or item[1]['ciron'][0][1] >= 0.8 or item[1]['offensive'][0][1] >= 0.8:\n",
    "        candidate.append(item)\n",
    "    else:\n",
    "        positive.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e0f7dfb-0767-486b-9d82-394f3f01eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "offensive = []\n",
    "with open('/data/albert.xht/sentiment/dev/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive.append(content)\n",
    "        \n",
    "offensive_test = []\n",
    "with open('/data/albert.xht/sentiment/test/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive_test.append(content)\n",
    "\n",
    "        \n",
    "cdia_bias = []\n",
    "with open('/data/albert.xht/sentiment/dev/cdial_bias.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        cdia_bias.append(content)\n",
    "        \n",
    "senti_copr = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_copr.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_copr.append(content)\n",
    "        \n",
    "ciron = []\n",
    "with open('/data/albert.xht/sentiment/dev/chinese_ciron.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        ciron.append(content)\n",
    "\n",
    "senti_smp = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smp_usual.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smp.append(content)\n",
    "        \n",
    "senti_smpecisa = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smpecisa.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smpecisa.append(content)\n",
    "\n",
    "        \n",
    "senti_query = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_valid.json.filter.0.7') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_query.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56a49dd8-fe1a-4fae-b310-627ddf85ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def eval_all(data, model, key):\n",
    "    pred = []\n",
    "    gold = []\n",
    "    pred_score = []\n",
    "    for item in tqdm(data):\n",
    "        gold.append(item['label'][0])\n",
    "        if isinstance(item['text'], list):\n",
    "            text = \"\\n\".join(item['text'])\n",
    "        else:\n",
    "            text = item['text']\n",
    "        text = re.sub(r\"([，\\_《。》、？；：‘’＂“”【「】」·！@￥…（）—\\,\\<\\.\\>\\/\\?\\;\\:\\'\\\"\\[\\]\\{\\}\\~\\`\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\-\\=\\+])+\", \"\", text)   # 合并正文中过多的空格\n",
    "\n",
    "        result = model.predict(text)\n",
    "        score = sorted(result[key], key=lambda u:u[1], reverse=True)\n",
    "        pred.append(score[0][0])\n",
    "        pred_score.append(result[key])\n",
    "    print(classification_report(gold, pred, digits=4))\n",
    "    return pred, gold, pred_score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bef11639-006f-4482-a104-1fc2e8d1b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluation_ece(pred_score, gold):\n",
    "    pred_score_l = []\n",
    "    mapping_dict = {}\n",
    "    for item in pred_score:\n",
    "        pred_score_l.append([])\n",
    "        for idx, p in enumerate(item):\n",
    "            if p[0] not in mapping_dict:\n",
    "                mapping_dict[p[0]] = idx\n",
    "            pred_score_l[-1].append(p[1])\n",
    "    pred_score_l = torch.tensor(pred_score_l)\n",
    "    gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "\n",
    "    ece_fn = ECE(n_bins=15)\n",
    "    print(ece_fn(pred_score_l, gold_l, mode='probs'), '==ece==')\n",
    "# pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "# evaluation_ece(pred_score, gold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "794ca494-16bf-438b-b074-6413f0ef1fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'冒犯': 0, '正常': 1}\n",
      "tensor([0.1119]) ==ece==\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22222f61-41b9-463f-9e00-9f1068e5cee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['正常', 0.9768216013908386]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "181c5de9-6e52-4eaf-b83a-d56f7cd98ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3797b0ad-bfdb-4593-9ea4-a42c2ef8cda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'正常'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a0b3183-0619-4df4-8d4b-19b0c43e6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model_path):\n",
    "    risk_api.reload(model_path)\n",
    "    print('===offensive===')\n",
    "    pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===cdia-bias===')\n",
    "    pred, gold, pred_score = eval_all(cdia_bias, risk_api, 'bias')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===ciron===')\n",
    "    pred, gold, pred_score = eval_all(ciron, risk_api, 'ciron')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===chsenti===')\n",
    "    pred, gold, pred_score = eval_all(senti_copr, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smpecisa===')\n",
    "    pred, gold, pred_score = eval_all(senti_smpecisa, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smp===')\n",
    "    pred, gold, pred_score = eval_all(senti_smp, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_query===')\n",
    "    pred, gold, pred_score = eval_all(senti_query, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc4a276d-2a26-4c01-8cb8-c92e928a3bea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_103634/1096843400.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfrobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mintent_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintent_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'intent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_all' is not defined"
     ]
    }
   ],
   "source": [
    "risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2/multitask_cls.pth.9')\n",
    "\n",
    "# risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_query_risk_20221222/multitask_cls.pth.9')\n",
    "\n",
    "risk_api.reload('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2_5_aug/multitask_cls.pth.4')\n",
    "\n",
    "intent_v2 = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/xiaoda/intention_data_v2/dev.txt') as frobj:\n",
    "    for line in frobj:\n",
    "        intent_v2.append(json.loads(line.strip()))\n",
    "pred, gold, pred_score = eval_all(intent_v2, risk_api, 'intent')\n",
    "evaluation_ece(pred_score, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ccfcddc-f2b3-49ac-8ad0-2d40f39e69bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:25<00:00, 118.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  主观评价/比较/判断     0.9307    0.9801    0.9548       603\n",
      "          其它     0.9922    0.9734    0.9827      2219\n",
      "     寻求建议/帮助     0.9043    0.9551    0.9290       178\n",
      "\n",
      "    accuracy                         0.9737      3000\n",
      "   macro avg     0.9424    0.9695    0.9555      3000\n",
      "weighted avg     0.9746    0.9737    0.9739      3000\n",
      "\n",
      "tensor([0.0159]) ==ece==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "intent_v2 = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/xiaoda/intention_data_v2/dev.txt') as frobj:\n",
    "    for line in frobj:\n",
    "        intent_v2.append(json.loads(line.strip()))\n",
    "pred, gold, pred_score = eval_all(intent_v2, risk_api, 'intent')\n",
    "evaluation_ece(pred_score, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d2f0a6f-407e-4180-afa5-9a9b8fa345bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'senti_query': [['负向', 0.39223232865333557],\n",
       "  ['中性', 0.4583439230918884],\n",
       "  ['正向', 0.149423748254776]],\n",
       " 'senti': [['负向', 0.700639545917511], ['正向', 0.2993604242801666]],\n",
       " 'bias': [['偏见', 0.19105122983455658], ['正常', 0.808948814868927]],\n",
       " 'ciron': [['讽刺', 0.07068543881177902], ['正常', 0.9293144941329956]],\n",
       " 'intent': [['主观评价/比较/判断', 0.00011481617548270151],\n",
       "  ['寻求建议/帮助', 0.0017586412141099572],\n",
       "  ['其它', 0.9981265664100647]],\n",
       " 'offensive': [['冒犯', 0.05265172943472862], ['正常', 0.9473482966423035]],\n",
       " 'query_risk': [['风险', 0.026251530274748802],\n",
       "  ['个人信息', 6.0953414504183456e-05],\n",
       "  ['正常', 0.9736875295639038]],\n",
       " 'teenager': [['不良', 0.06425187736749649], ['正常', 0.9357481598854065]]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_api.predict('外卖骑手来不及送餐赶紧闯红灯')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a98ebb-c331-4a98-94b6-c4900cc72bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v5_intent_v2_3/multitask_cls.pth.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c29b8019-e251-44c9-94e4-a61f9a91a78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/5304 [00:00<00:45, 115.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:45<00:00, 116.86it/s]\n",
      "  0%|          | 12/2829 [00:00<00:23, 118.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7299    0.8557    0.7878      2106\n",
      "          正常     0.8928    0.7914    0.8391      3198\n",
      "\n",
      "    accuracy                         0.8169      5304\n",
      "   macro avg     0.8113    0.8235    0.8134      5304\n",
      "weighted avg     0.8281    0.8169    0.8187      5304\n",
      "\n",
      "tensor([0.1097]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:24<00:00, 117.26it/s]\n",
      "  1%|▏         | 12/875 [00:00<00:07, 118.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.6130    0.4610    0.5262       718\n",
      "          正常     0.8309    0.9010    0.8645      2111\n",
      "\n",
      "    accuracy                         0.7893      2829\n",
      "   macro avg     0.7219    0.6810    0.6954      2829\n",
      "weighted avg     0.7756    0.7893    0.7787      2829\n",
      "\n",
      "tensor([0.0190]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:07<00:00, 117.66it/s]\n",
      "  1%|          | 12/1200 [00:00<00:10, 115.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9154    0.9718    0.9427       779\n",
      "          讽刺     0.5417    0.2708    0.3611        96\n",
      "\n",
      "    accuracy                         0.8949       875\n",
      "   macro avg     0.7285    0.6213    0.6519       875\n",
      "weighted avg     0.8744    0.8949    0.8789       875\n",
      "\n",
      "tensor([0.0228]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.88it/s]\n",
      "  0%|          | 12/2529 [00:00<00:21, 118.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9036    0.9325    0.9178       593\n",
      "          负向     0.9320    0.9028    0.9172       607\n",
      "\n",
      "    accuracy                         0.9175      1200\n",
      "   macro avg     0.9178    0.9177    0.9175      1200\n",
      "weighted avg     0.9179    0.9175    0.9175      1200\n",
      "\n",
      "tensor([0.0235]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:21<00:00, 118.16it/s]\n",
      "  0%|          | 12/2844 [00:00<00:23, 118.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.7885    0.8226    0.8052      1201\n",
      "          负向     0.8331    0.8005    0.8164      1328\n",
      "\n",
      "    accuracy                         0.8110      2529\n",
      "   macro avg     0.8108    0.8115    0.8108      2529\n",
      "weighted avg     0.8119    0.8110    0.8111      2529\n",
      "\n",
      "tensor([0.1149]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:24<00:00, 117.54it/s]\n",
      "  0%|          | 12/50509 [00:00<07:03, 119.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8116    0.9067    0.8565      1126\n",
      "          负向     0.9338    0.8620    0.8965      1718\n",
      "\n",
      "    accuracy                         0.8797      2844\n",
      "   macro avg     0.8727    0.8844    0.8765      2844\n",
      "weighted avg     0.8854    0.8797    0.8807      2844\n",
      "\n",
      "tensor([0.0631]) ==ece==\n",
      "===senti_query===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 8365/50509 [01:10<05:55, 118.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25041/2988547817.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v6_intent_v2-1_10_no_symbol/multitask_cls.pth.9'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_25041/3217327212.py\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===senti_query==='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msenti_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'senti'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25041/1846423510.py\u001b[0m in \u001b[0;36meval_all\u001b[0;34m(data, model, key)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"([，\\_《。》、？；：‘’＂“”【「】」·！@￥…（）—\\,\\<\\.\\>\\/\\?\\;\\:\\'\\\"\\[\\]\\{\\}\\~\\`\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\-\\=\\+])+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 合并正文中过多的空格\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25041/3636409198.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             [logits_list, \n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                 attention_mask, token_type_ids, transformer_mode='cls')\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mschema_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25041/3636409198.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_mask, segment_ids, transformer_mode, dt_idx)\u001b[0m\n\u001b[1;32m     95\u001b[0m                         \u001b[0mtransformer_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_pooling'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                         dt_idx=None):\n\u001b[0;32m---> 97\u001b[0;31m                 hidden_states = self.transformer(input_ids=input_ids,\n\u001b[0m\u001b[1;32m     98\u001b[0m                               \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                               \u001b[0msegment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/xiaoda/query_topic/nets/them_classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_mask, segment_ids, return_mode)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cls'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1111\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    690\u001b[0m         )\n\u001b[1;32m    691\u001b[0m         \u001b[0;31m# [sequence_length, embed_size_per_head] -> sin & cos [batch_size, num_heads, sequence_length, embed_size_per_head // 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         sinusoidal_pos = self.embed_positions(hidden_states.shape[1], past_key_values_length)[\n\u001b[0m\u001b[1;32m    693\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         ].chunk(2, dim=-1)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, seq_len, past_key_values_length)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         )\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    145\u001b[0m         return F.embedding(\n\u001b[1;32m    146\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v6_intent_v2-1_10_no_symbol/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d241c474-bcd8-4c0f-ab73-cd54c3078912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v5_no_offensive_intent_v2-1_3/multitask_cls.pth.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d63066c-26d5-45d4-91e6-fa641a592d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation('/data/albert.xht/xiaodao/multitask_raw_filter_senti_query_risk_v5_intent_v2-1_3/multitask_cls.pth.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da1db8e-837f-4609-adfc-566ba2583b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [], range(1, 0))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0, 1), random.sample(list(range(1, 2)), k=0), range(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0f5c9b8-2e59-4186-a9c1-d3736d6738d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:43<00:00, 121.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7306    0.8523    0.7868      2106\n",
      "          正常     0.8908    0.7930    0.8390      3198\n",
      "\n",
      "    accuracy                         0.8166      5304\n",
      "   macro avg     0.8107    0.8227    0.8129      5304\n",
      "weighted avg     0.8272    0.8166    0.8183      5304\n",
      "\n",
      "tensor([0.1362]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:23<00:00, 120.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5761    0.5376    0.5562       718\n",
      "          正常     0.8462    0.8655    0.8557      2111\n",
      "\n",
      "    accuracy                         0.7823      2829\n",
      "   macro avg     0.7112    0.7015    0.7060      2829\n",
      "weighted avg     0.7777    0.7823    0.7797      2829\n",
      "\n",
      "tensor([0.0758]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:07<00:00, 122.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9246    0.9602    0.9421       779\n",
      "          讽刺     0.5303    0.3646    0.4321        96\n",
      "\n",
      "    accuracy                         0.8949       875\n",
      "   macro avg     0.7275    0.6624    0.6871       875\n",
      "weighted avg     0.8813    0.8949    0.8861       875\n",
      "\n",
      "tensor([0.0579]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 118.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9480    0.9528    0.9504       593\n",
      "          负向     0.9536    0.9489    0.9513       607\n",
      "\n",
      "    accuracy                         0.9508      1200\n",
      "   macro avg     0.9508    0.9509    0.9508      1200\n",
      "weighted avg     0.9508    0.9508    0.9508      1200\n",
      "\n",
      "tensor([0.0192]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 122.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.7700    0.8501    0.8081      1201\n",
      "          负向     0.8504    0.7703    0.8084      1328\n",
      "\n",
      "    accuracy                         0.8082      2529\n",
      "   macro avg     0.8102    0.8102    0.8082      2529\n",
      "weighted avg     0.8122    0.8082    0.8082      2529\n",
      "\n",
      "tensor([0.1563]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:23<00:00, 121.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8057    0.8988    0.8497      1126\n",
      "          负向     0.9282    0.8580    0.8917      1718\n",
      "\n",
      "    accuracy                         0.8741      2844\n",
      "   macro avg     0.8670    0.8784    0.8707      2844\n",
      "weighted avg     0.8797    0.8741    0.8751      2844\n",
      "\n",
      "tensor([0.0911]) ==ece==\n",
      "===senti_query===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 30108/50509 [04:09<02:48, 120.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_68088/1052261655.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2_5_aug/multitask_cls.pth.4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_68088/3217327212.py\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===senti_query==='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msenti_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'senti'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_68088/4130490020.py\u001b[0m in \u001b[0;36meval_all\u001b[0;34m(data, model, key)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_68088/878510297.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             [logits_list, \n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                 attention_mask, token_type_ids, transformer_mode='cls')\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mschema_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_68088/878510297.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_mask, segment_ids, transformer_mode, dt_idx)\u001b[0m\n\u001b[1;32m     95\u001b[0m                         \u001b[0mtransformer_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_pooling'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                         dt_idx=None):\n\u001b[0;32m---> 97\u001b[0;31m                 hidden_states = self.transformer(input_ids=input_ids,\n\u001b[0m\u001b[1;32m     98\u001b[0m                               \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                               \u001b[0msegment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/xiaoda/query_topic/nets/them_classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_mask, segment_ids, return_mode)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cls'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1111\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    726\u001b[0m                 )\n\u001b[1;32m    727\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    729\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, sinusoidal_pos, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         )\n\u001b[0;32m--> 586\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, sinusoidal_pos, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     ):\n\u001b[0;32m--> 506\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    507\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, sinusoidal_pos, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         outputs = (\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mcontext_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcontext_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         )\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2_5_aug/multitask_cls.pth.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c763a78-8c46-4d58-8632-ed678351854c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:47<00:00, 111.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7309    0.8680    0.7936      2106\n",
      "          正常     0.9008    0.7896    0.8415      3198\n",
      "\n",
      "    accuracy                         0.8207      5304\n",
      "   macro avg     0.8159    0.8288    0.8176      5304\n",
      "weighted avg     0.8334    0.8207    0.8225      5304\n",
      "\n",
      "tensor([0.1185]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:23<00:00, 122.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5839    0.5139    0.5467       718\n",
      "          正常     0.8411    0.8754    0.8579      2111\n",
      "\n",
      "    accuracy                         0.7837      2829\n",
      "   macro avg     0.7125    0.6947    0.7023      2829\n",
      "weighted avg     0.7758    0.7837    0.7789      2829\n",
      "\n",
      "tensor([0.0372]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:07<00:00, 124.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9191    0.9628    0.9404       779\n",
      "          讽刺     0.5085    0.3125    0.3871        96\n",
      "\n",
      "    accuracy                         0.8914       875\n",
      "   macro avg     0.7138    0.6376    0.6638       875\n",
      "weighted avg     0.8741    0.8914    0.8797       875\n",
      "\n",
      "tensor([0.0317]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 121.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9305    0.9477    0.9390       593\n",
      "          负向     0.9480    0.9308    0.9393       607\n",
      "\n",
      "    accuracy                         0.9392      1200\n",
      "   macro avg     0.9392    0.9393    0.9392      1200\n",
      "weighted avg     0.9393    0.9392    0.9392      1200\n",
      "\n",
      "tensor([0.0284]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 124.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.7702    0.8510    0.8085      1201\n",
      "          负向     0.8511    0.7703    0.8087      1328\n",
      "\n",
      "    accuracy                         0.8086      2529\n",
      "   macro avg     0.8106    0.8106    0.8086      2529\n",
      "weighted avg     0.8127    0.8086    0.8086      2529\n",
      "\n",
      "tensor([0.1475]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:23<00:00, 123.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8225    0.9014    0.8602      1126\n",
      "          负向     0.9311    0.8725    0.9008      1718\n",
      "\n",
      "    accuracy                         0.8840      2844\n",
      "   macro avg     0.8768    0.8870    0.8805      2844\n",
      "weighted avg     0.8881    0.8840    0.8847      2844\n",
      "\n",
      "tensor([0.0719]) ==ece==\n",
      "===senti_query===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39435/50509 [05:17<01:29, 124.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58631/2128993976.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2/multitask_cls.pth.8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_58631/3217327212.py\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===senti_query==='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msenti_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'senti'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_58631/4130490020.py\u001b[0m in \u001b[0;36meval_all\u001b[0;34m(data, model, key)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_58631/878510297.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             [logits_list, \n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                 attention_mask, token_type_ids, transformer_mode='cls')\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mschema_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_58631/878510297.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_mask, segment_ids, transformer_mode, dt_idx)\u001b[0m\n\u001b[1;32m     95\u001b[0m                         \u001b[0mtransformer_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_pooling'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                         dt_idx=None):\n\u001b[0;32m---> 97\u001b[0;31m                 hidden_states = self.transformer(input_ids=input_ids,\n\u001b[0m\u001b[1;32m     98\u001b[0m                               \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                               \u001b[0msegment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/xiaoda/query_topic/nets/them_classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_mask, segment_ids, return_mode)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cls'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1111\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    726\u001b[0m                 )\n\u001b[1;32m    727\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    729\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, sinusoidal_pos, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         )\n\u001b[0;32m--> 586\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, sinusoidal_pos, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     ):\n\u001b[0;32m--> 506\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    507\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/roformer/modeling_roformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, sinusoidal_pos, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0;31m# rotary key_layer & value_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_filter_senti_query_risk_v4_intent_v2/multitask_cls.pth.8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce62f6d0-bbae-47d4-b570-2799bdeec8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:43<00:00, 122.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7344    0.8599    0.7922      2106\n",
      "          正常     0.8961    0.7952    0.8426      3198\n",
      "\n",
      "    accuracy                         0.8209      5304\n",
      "   macro avg     0.8152    0.8276    0.8174      5304\n",
      "weighted avg     0.8319    0.8209    0.8226      5304\n",
      "\n",
      "tensor([0.1135]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:23<00:00, 122.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5700    0.4930    0.5288       718\n",
      "          正常     0.8351    0.8735    0.8539      2111\n",
      "\n",
      "    accuracy                         0.7770      2829\n",
      "   macro avg     0.7026    0.6833    0.6913      2829\n",
      "weighted avg     0.7679    0.7770    0.7714      2829\n",
      "\n",
      "tensor([0.0479]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:07<00:00, 122.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9168    0.9615    0.9386       779\n",
      "          讽刺     0.4828    0.2917    0.3636        96\n",
      "\n",
      "    accuracy                         0.8880       875\n",
      "   macro avg     0.6998    0.6266    0.6511       875\n",
      "weighted avg     0.8692    0.8880    0.8755       875\n",
      "\n",
      "tensor([0.0333]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 119.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9316    0.9410    0.9362       593\n",
      "          负向     0.9418    0.9325    0.9371       607\n",
      "\n",
      "    accuracy                         0.9367      1200\n",
      "   macro avg     0.9367    0.9367    0.9367      1200\n",
      "weighted avg     0.9367    0.9367    0.9367      1200\n",
      "\n",
      "tensor([0.0270]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 122.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.7767    0.8543    0.8136      1201\n",
      "          负向     0.8551    0.7779    0.8147      1328\n",
      "\n",
      "    accuracy                         0.8142      2529\n",
      "   macro avg     0.8159    0.8161    0.8142      2529\n",
      "weighted avg     0.8179    0.8142    0.8142      2529\n",
      "\n",
      "tensor([0.1410]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:23<00:00, 122.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8195    0.9032    0.8593      1126\n",
      "          负向     0.9320    0.8696    0.8997      1718\n",
      "\n",
      "    accuracy                         0.8829      2844\n",
      "   macro avg     0.8758    0.8864    0.8795      2844\n",
      "weighted avg     0.8875    0.8829    0.8837      2844\n",
      "\n",
      "tensor([0.0736]) ==ece==\n",
      "===senti_query===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50509/50509 [06:45<00:00, 124.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9686    0.9721    0.9704     28251\n",
      "          负向     0.9645    0.9600    0.9622     22258\n",
      "\n",
      "    accuracy                         0.9668     50509\n",
      "   macro avg     0.9665    0.9661    0.9663     50509\n",
      "weighted avg     0.9668    0.9668    0.9668     50509\n",
      "\n",
      "tensor([0.0188]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_query_risk_20221222/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8331128b-2671-4129-9a7a-4781b657b020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 123.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7448    0.8538    0.7956      2106\n",
      "          正常     0.8934    0.8074    0.8482      3198\n",
      "\n",
      "    accuracy                         0.8258      5304\n",
      "   macro avg     0.8191    0.8306    0.8219      5304\n",
      "weighted avg     0.8344    0.8258    0.8273      5304\n",
      "\n",
      "tensor([0.1187]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 123.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5665    0.5752    0.5708       718\n",
      "          正常     0.8548    0.8503    0.8525      2111\n",
      "\n",
      "    accuracy                         0.7805      2829\n",
      "   macro avg     0.7106    0.7128    0.7117      2829\n",
      "weighted avg     0.7816    0.7805    0.7810      2829\n",
      "\n",
      "tensor([0.0452]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:07<00:00, 124.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9299    0.9371    0.9335       779\n",
      "          讽刺     0.4556    0.4271    0.4409        96\n",
      "\n",
      "    accuracy                         0.8811       875\n",
      "   macro avg     0.6927    0.6821    0.6872       875\n",
      "weighted avg     0.8779    0.8811    0.8795       875\n",
      "\n",
      "tensor([0.0460]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 120.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9282    0.9595    0.9436       593\n",
      "          负向     0.9591    0.9275    0.9430       607\n",
      "\n",
      "    accuracy                         0.9433      1200\n",
      "   macro avg     0.9437    0.9435    0.9433      1200\n",
      "weighted avg     0.9438    0.9433    0.9433      1200\n",
      "\n",
      "tensor([0.0386]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 124.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.7543    0.8485    0.7986      1201\n",
      "          负向     0.8455    0.7500    0.7949      1328\n",
      "\n",
      "    accuracy                         0.7968      2529\n",
      "   macro avg     0.7999    0.7992    0.7967      2529\n",
      "weighted avg     0.8022    0.7968    0.7966      2529\n",
      "\n",
      "tensor([0.1659]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:23<00:00, 123.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8233    0.8899    0.8553      1126\n",
      "          负向     0.9238    0.8749    0.8987      1718\n",
      "\n",
      "    accuracy                         0.8808      2844\n",
      "   macro avg     0.8736    0.8824    0.8770      2844\n",
      "weighted avg     0.8840    0.8808    0.8815      2844\n",
      "\n",
      "tensor([0.0784]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/query_risk_v3/multitask_raw_filter_senti_query_risk_v3/multitask_cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3a0e43c1-6b45-4755-bdec-c6bc93910aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 124.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7084    0.8837    0.7864      2106\n",
      "          正常     0.9085    0.7605    0.8279      3198\n",
      "\n",
      "    accuracy                         0.8094      5304\n",
      "   macro avg     0.8084    0.8221    0.8072      5304\n",
      "weighted avg     0.8290    0.8094    0.8114      5304\n",
      "\n",
      "tensor([0.1319]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 124.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5622    0.6045    0.5826       718\n",
      "          正常     0.8619    0.8399    0.8508      2111\n",
      "\n",
      "    accuracy                         0.7801      2829\n",
      "   macro avg     0.7121    0.7222    0.7167      2829\n",
      "weighted avg     0.7859    0.7801    0.7827      2829\n",
      "\n",
      "tensor([0.0458]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 125.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9287    0.9538    0.9411       779\n",
      "          讽刺     0.5200    0.4062    0.4561        96\n",
      "\n",
      "    accuracy                         0.8937       875\n",
      "   macro avg     0.7244    0.6800    0.6986       875\n",
      "weighted avg     0.8839    0.8937    0.8879       875\n",
      "\n",
      "tensor([0.0358]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 122.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9112    0.9174    0.9143       593\n",
      "          负向     0.9187    0.9127    0.9157       607\n",
      "\n",
      "    accuracy                         0.9150      1200\n",
      "   macro avg     0.9150    0.9150    0.9150      1200\n",
      "weighted avg     0.9150    0.9150    0.9150      1200\n",
      "\n",
      "tensor([0.0297]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 126.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8326    0.7868    0.8091      1201\n",
      "          负向     0.8164    0.8569    0.8361      1328\n",
      "\n",
      "    accuracy                         0.8236      2529\n",
      "   macro avg     0.8245    0.8219    0.8226      2529\n",
      "weighted avg     0.8241    0.8236    0.8233      2529\n",
      "\n",
      "tensor([0.0308]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 126.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8724    0.8321    0.8518      1126\n",
      "          负向     0.8932    0.9203    0.9065      1718\n",
      "\n",
      "    accuracy                         0.8854      2844\n",
      "   macro avg     0.8828    0.8762    0.8792      2844\n",
      "weighted avg     0.8850    0.8854    0.8849      2844\n",
      "\n",
      "tensor([0.0111]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256_20/multitask_cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c81a54a-1768-4454-9e04-7f9c8c52673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7050    0.8794    0.7826      2106\n",
      "          正常     0.9051    0.7577    0.8249      3198\n",
      "\n",
      "    accuracy                         0.8060      5304\n",
      "   macro avg     0.8051    0.8185    0.8037      5304\n",
      "weighted avg     0.8257    0.8060    0.8081      5304\n",
      "\n",
      "tensor([0.1119]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:25<00:00, 111.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.6208    0.4903    0.5479       718\n",
      "          正常     0.8382    0.8982    0.8671      2111\n",
      "\n",
      "    accuracy                         0.7946      2829\n",
      "   macro avg     0.7295    0.6942    0.7075      2829\n",
      "weighted avg     0.7830    0.7946    0.7861      2829\n",
      "\n",
      "tensor([0.0231]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:08<00:00, 98.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9255    0.9730    0.9487       779\n",
      "          讽刺     0.6250    0.3646    0.4605        96\n",
      "\n",
      "    accuracy                         0.9063       875\n",
      "   macro avg     0.7753    0.6688    0.7046       875\n",
      "weighted avg     0.8925    0.9063    0.8951       875\n",
      "\n",
      "tensor([0.0363]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:12<00:00, 96.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8838    0.9106    0.8970       593\n",
      "          负向     0.9100    0.8830    0.8963       607\n",
      "\n",
      "    accuracy                         0.8967      1200\n",
      "   macro avg     0.8969    0.8968    0.8967      1200\n",
      "weighted avg     0.8971    0.8967    0.8967      1200\n",
      "\n",
      "tensor([0.0226]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:22<00:00, 111.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8053    0.8160    0.8106      1201\n",
      "          负向     0.8316    0.8215    0.8265      1328\n",
      "\n",
      "    accuracy                         0.8189      2529\n",
      "   macro avg     0.8184    0.8188    0.8186      2529\n",
      "weighted avg     0.8191    0.8189    0.8190      2529\n",
      "\n",
      "tensor([0.0208]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 125.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8540    0.8366    0.8452      1126\n",
      "          负向     0.8943    0.9063    0.9003      1718\n",
      "\n",
      "    accuracy                         0.8787      2844\n",
      "   macro avg     0.8742    0.8714    0.8727      2844\n",
      "weighted avg     0.8784    0.8787    0.8785      2844\n",
      "\n",
      "tensor([0.0247]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_intent_v1/multitask_cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1c4efc0-473c-4613-ac20-62c9d193c161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7068    0.8746    0.7818      2106\n",
      "          正常     0.9021    0.7611    0.8256      3198\n",
      "\n",
      "    accuracy                         0.8062      5304\n",
      "   macro avg     0.8045    0.8179    0.8037      5304\n",
      "weighted avg     0.8246    0.8062    0.8082      5304\n",
      "\n",
      "tensor([0.0195]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 125.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5951    0.4749    0.5283       718\n",
      "          正常     0.8329    0.8901    0.8605      2111\n",
      "\n",
      "    accuracy                         0.7847      2829\n",
      "   macro avg     0.7140    0.6825    0.6944      2829\n",
      "weighted avg     0.7725    0.7847    0.7762      2829\n",
      "\n",
      "tensor([0.1170]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 125.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9230    0.9692    0.9455       779\n",
      "          讽刺     0.5789    0.3438    0.4314        96\n",
      "\n",
      "    accuracy                         0.9006       875\n",
      "   macro avg     0.7510    0.6565    0.6884       875\n",
      "weighted avg     0.8852    0.9006    0.8891       875\n",
      "\n",
      "tensor([0.1106]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 121.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8807    0.9089    0.8946       593\n",
      "          负向     0.9082    0.8797    0.8937       607\n",
      "\n",
      "    accuracy                         0.8942      1200\n",
      "   macro avg     0.8944    0.8943    0.8942      1200\n",
      "weighted avg     0.8946    0.8942    0.8942      1200\n",
      "\n",
      "tensor([0.1561]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 126.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8163    0.8251    0.8207      1201\n",
      "          负向     0.8403    0.8321    0.8362      1328\n",
      "\n",
      "    accuracy                         0.8288      2529\n",
      "   macro avg     0.8283    0.8286    0.8284      2529\n",
      "weighted avg     0.8289    0.8288    0.8288      2529\n",
      "\n",
      "tensor([0.1556]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 125.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8627    0.8313    0.8467      1126\n",
      "          负向     0.8920    0.9133    0.9025      1718\n",
      "\n",
      "    accuracy                         0.8808      2844\n",
      "   macro avg     0.8773    0.8723    0.8746      2844\n",
      "weighted avg     0.8804    0.8808    0.8804      2844\n",
      "\n",
      "tensor([0.1674]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_focal/multitask_cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc5ba38e-db17-4e3d-b05c-caabe86f0e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 124.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7034    0.8818    0.7826      2106\n",
      "          正常     0.9065    0.7552    0.8240      3198\n",
      "\n",
      "    accuracy                         0.8054      5304\n",
      "   macro avg     0.8050    0.8185    0.8033      5304\n",
      "weighted avg     0.8259    0.8054    0.8075      5304\n",
      "\n",
      "tensor([0.1129]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 125.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.6035    0.4833    0.5367       718\n",
      "          正常     0.8354    0.8920    0.8628      2111\n",
      "\n",
      "    accuracy                         0.7883      2829\n",
      "   macro avg     0.7194    0.6876    0.6998      2829\n",
      "weighted avg     0.7765    0.7883    0.7800      2829\n",
      "\n",
      "tensor([0.0261]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 126.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9126    0.9653    0.9382       779\n",
      "          讽刺     0.4706    0.2500    0.3265        96\n",
      "\n",
      "    accuracy                         0.8869       875\n",
      "   macro avg     0.6916    0.6077    0.6324       875\n",
      "weighted avg     0.8641    0.8869    0.8711       875\n",
      "\n",
      "tensor([0.0374]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 122.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8831    0.9174    0.8999       593\n",
      "          负向     0.9161    0.8814    0.8984       607\n",
      "\n",
      "    accuracy                         0.8992      1200\n",
      "   macro avg     0.8996    0.8994    0.8992      1200\n",
      "weighted avg     0.8998    0.8992    0.8992      1200\n",
      "\n",
      "tensor([0.0285]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:19<00:00, 127.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8099    0.8301    0.8199      1201\n",
      "          负向     0.8428    0.8238    0.8332      1328\n",
      "\n",
      "    accuracy                         0.8268      2529\n",
      "   macro avg     0.8264    0.8270    0.8266      2529\n",
      "weighted avg     0.8272    0.8268    0.8269      2529\n",
      "\n",
      "tensor([0.0214]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 126.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8552    0.8393    0.8472      1126\n",
      "          负向     0.8959    0.9069    0.9014      1718\n",
      "\n",
      "    accuracy                         0.8801      2844\n",
      "   macro avg     0.8756    0.8731    0.8743      2844\n",
      "weighted avg     0.8798    0.8801    0.8799      2844\n",
      "\n",
      "tensor([0.0243]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_balanced_intent_v1//multitask_cls.pth.9')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d330603c-fb51-4465-b010-b852348536cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7314    0.8661    0.7930      2106\n",
      "          正常     0.8996    0.7905    0.8415      3198\n",
      "\n",
      "    accuracy                         0.8205      5304\n",
      "   macro avg     0.8155    0.8283    0.8173      5304\n",
      "weighted avg     0.8328    0.8205    0.8223      5304\n",
      "\n",
      "tensor([0.0103]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 124.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5877    0.4944    0.5371       718\n",
      "          正常     0.8369    0.8820    0.8589      2111\n",
      "\n",
      "    accuracy                         0.7837      2829\n",
      "   macro avg     0.7123    0.6882    0.6980      2829\n",
      "weighted avg     0.7736    0.7837    0.7772      2829\n",
      "\n",
      "tensor([0.1111]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:07<00:00, 114.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9174    0.9692    0.9426       779\n",
      "          讽刺     0.5385    0.2917    0.3784        96\n",
      "\n",
      "    accuracy                         0.8949       875\n",
      "   macro avg     0.7279    0.6304    0.6605       875\n",
      "weighted avg     0.8758    0.8949    0.8807       875\n",
      "\n",
      "tensor([0.1099]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 116.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8941    0.9258    0.9097       593\n",
      "          负向     0.9249    0.8929    0.9086       607\n",
      "\n",
      "    accuracy                         0.9092      1200\n",
      "   macro avg     0.9095    0.9094    0.9092      1200\n",
      "weighted avg     0.9097    0.9092    0.9092      1200\n",
      "\n",
      "tensor([0.1246]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 125.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8103    0.8218    0.8160      1201\n",
      "          负向     0.8368    0.8261    0.8314      1328\n",
      "\n",
      "    accuracy                         0.8240      2529\n",
      "   macro avg     0.8236    0.8239    0.8237      2529\n",
      "weighted avg     0.8242    0.8240    0.8241      2529\n",
      "\n",
      "tensor([0.1440]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 124.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8532    0.8464    0.8498      1126\n",
      "          负向     0.8998    0.9045    0.9022      1718\n",
      "\n",
      "    accuracy                         0.8815      2844\n",
      "   macro avg     0.8765    0.8754    0.8760      2844\n",
      "weighted avg     0.8814    0.8815    0.8814      2844\n",
      "\n",
      "tensor([0.1548]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_focal_128/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "192980fd-608d-418a-baf2-e03061767e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7074    0.8770    0.7831      2106\n",
      "          正常     0.9038    0.7611    0.8263      3198\n",
      "\n",
      "    accuracy                         0.8071      5304\n",
      "   macro avg     0.8056    0.8191    0.8047      5304\n",
      "weighted avg     0.8258    0.8071    0.8092      5304\n",
      "\n",
      "tensor([0.1762]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 124.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5777    0.5125    0.5432       718\n",
      "          正常     0.8403    0.8726    0.8561      2111\n",
      "\n",
      "    accuracy                         0.7812      2829\n",
      "   macro avg     0.7090    0.6926    0.6997      2829\n",
      "weighted avg     0.7737    0.7812    0.7767      2829\n",
      "\n",
      "tensor([0.1900]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 125.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9294    0.9461    0.9377       779\n",
      "          讽刺     0.4878    0.4167    0.4494        96\n",
      "\n",
      "    accuracy                         0.8880       875\n",
      "   macro avg     0.7086    0.6814    0.6935       875\n",
      "weighted avg     0.8809    0.8880    0.8841       875\n",
      "\n",
      "tensor([0.1048]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 121.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9314    0.9157    0.9235       593\n",
      "          负向     0.9190    0.9341    0.9265       607\n",
      "\n",
      "    accuracy                         0.9250      1200\n",
      "   macro avg     0.9252    0.9249    0.9250      1200\n",
      "weighted avg     0.9251    0.9250    0.9250      1200\n",
      "\n",
      "tensor([0.0596]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 125.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8183    0.8285    0.8233      1201\n",
      "          负向     0.8431    0.8336    0.8383      1328\n",
      "\n",
      "    accuracy                         0.8312      2529\n",
      "   macro avg     0.8307    0.8310    0.8308      2529\n",
      "weighted avg     0.8313    0.8312    0.8312      2529\n",
      "\n",
      "tensor([0.1288]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 126.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8613    0.8437    0.8524      1126\n",
      "          负向     0.8989    0.9109    0.9049      1718\n",
      "\n",
      "    accuracy                         0.8843      2844\n",
      "   macro avg     0.8801    0.8773    0.8786      2844\n",
      "weighted avg     0.8840    0.8843    0.8841      2844\n",
      "\n",
      "tensor([0.0493]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_contrast_balanced_intent_v1/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef2307e5-3160-4342-8598-af7711f6c221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7229    0.8756    0.7919      2106\n",
      "          正常     0.9048    0.7789    0.8372      3198\n",
      "\n",
      "    accuracy                         0.8173      5304\n",
      "   macro avg     0.8138    0.8273    0.8145      5304\n",
      "weighted avg     0.8326    0.8173    0.8192      5304\n",
      "\n",
      "tensor([0.1323]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 126.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5892    0.5153    0.5498       718\n",
      "          正常     0.8419    0.8778    0.8595      2111\n",
      "\n",
      "    accuracy                         0.7858      2829\n",
      "   macro avg     0.7155    0.6966    0.7046      2829\n",
      "weighted avg     0.7778    0.7858    0.7809      2829\n",
      "\n",
      "tensor([0.0623]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 126.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9188    0.9589    0.9384       779\n",
      "          讽刺     0.4839    0.3125    0.3797        96\n",
      "\n",
      "    accuracy                         0.8880       875\n",
      "   macro avg     0.7013    0.6357    0.6591       875\n",
      "weighted avg     0.8711    0.8880    0.8771       875\n",
      "\n",
      "tensor([0.0520]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 122.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9129    0.9191    0.9160       593\n",
      "          负向     0.9204    0.9143    0.9174       607\n",
      "\n",
      "    accuracy                         0.9167      1200\n",
      "   macro avg     0.9166    0.9167    0.9167      1200\n",
      "weighted avg     0.9167    0.9167    0.9167      1200\n",
      "\n",
      "tensor([0.0421]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:19<00:00, 126.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8085    0.8085    0.8085      1201\n",
      "          负向     0.8268    0.8268    0.8268      1328\n",
      "\n",
      "    accuracy                         0.8181      2529\n",
      "   macro avg     0.8177    0.8177    0.8177      2529\n",
      "weighted avg     0.8181    0.8181    0.8181      2529\n",
      "\n",
      "tensor([0.0537]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 124.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8543    0.8330    0.8435      1126\n",
      "          负向     0.8923    0.9069    0.8995      1718\n",
      "\n",
      "    accuracy                         0.8776      2844\n",
      "   macro avg     0.8733    0.8700    0.8715      2844\n",
      "weighted avg     0.8773    0.8776    0.8774      2844\n",
      "\n",
      "tensor([0.0230]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_mtdnn_ce_256/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0e06bba0-2c4c-4a2e-b842-67823dced661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7248    0.8590    0.7862      2106\n",
      "          正常     0.8942    0.7852    0.8362      3198\n",
      "\n",
      "    accuracy                         0.8145      5304\n",
      "   macro avg     0.8095    0.8221    0.8112      5304\n",
      "weighted avg     0.8269    0.8145    0.8163      5304\n",
      "\n",
      "tensor([0.0393]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 124.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5753    0.5056    0.5382       718\n",
      "          正常     0.8385    0.8730    0.8554      2111\n",
      "\n",
      "    accuracy                         0.7798      2829\n",
      "   macro avg     0.7069    0.6893    0.6968      2829\n",
      "weighted avg     0.7717    0.7798    0.7749      2829\n",
      "\n",
      "tensor([0.0811]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 125.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9243    0.9564    0.9401       779\n",
      "          讽刺     0.5072    0.3646    0.4242        96\n",
      "\n",
      "    accuracy                         0.8914       875\n",
      "   macro avg     0.7158    0.6605    0.6822       875\n",
      "weighted avg     0.8786    0.8914    0.8835       875\n",
      "\n",
      "tensor([0.0768]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 121.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9132    0.9224    0.9178       593\n",
      "          负向     0.9235    0.9143    0.9189       607\n",
      "\n",
      "    accuracy                         0.9183      1200\n",
      "   macro avg     0.9183    0.9184    0.9183      1200\n",
      "weighted avg     0.9184    0.9183    0.9183      1200\n",
      "\n",
      "tensor([0.0882]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 125.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8040    0.8027    0.8033      1201\n",
      "          负向     0.8218    0.8230    0.8224      1328\n",
      "\n",
      "    accuracy                         0.8134      2529\n",
      "   macro avg     0.8129    0.8129    0.8129      2529\n",
      "weighted avg     0.8134    0.8134    0.8134      2529\n",
      "\n",
      "tensor([0.0975]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 124.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8523    0.8250    0.8384      1126\n",
      "          负向     0.8877    0.9063    0.8969      1718\n",
      "\n",
      "    accuracy                         0.8741      2844\n",
      "   macro avg     0.8700    0.8657    0.8677      2844\n",
      "weighted avg     0.8737    0.8741    0.8738      2844\n",
      "\n",
      "tensor([0.1215]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_mtdnn_focal_256/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c84059c2-9bc9-4978-b772-d4bb5b37b7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6417/6417 [00:51<00:00, 124.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.9025    0.9264    0.9143      3208\n",
      "          正常     0.9245    0.9000    0.9120      3209\n",
      "\n",
      "    accuracy                         0.9132      6417\n",
      "   macro avg     0.9135    0.9132    0.9132      6417\n",
      "weighted avg     0.9135    0.9132    0.9132      6417\n",
      "\n",
      "tensor([0.0343]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 124.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5808    0.5153    0.5461       718\n",
      "          正常     0.8412    0.8735    0.8571      2111\n",
      "\n",
      "    accuracy                         0.7826      2829\n",
      "   macro avg     0.7110    0.6944    0.7016      2829\n",
      "weighted avg     0.7752    0.7826    0.7782      2829\n",
      "\n",
      "tensor([0.0418]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 126.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9220    0.9718    0.9462       779\n",
      "          讽刺     0.5926    0.3333    0.4267        96\n",
      "\n",
      "    accuracy                         0.9017       875\n",
      "   macro avg     0.7573    0.6525    0.6865       875\n",
      "weighted avg     0.8859    0.9017    0.8892       875\n",
      "\n",
      "tensor([0.0266]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 122.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9028    0.9241    0.9133       593\n",
      "          负向     0.9241    0.9028    0.9133       607\n",
      "\n",
      "    accuracy                         0.9133      1200\n",
      "   macro avg     0.9135    0.9135    0.9133      1200\n",
      "weighted avg     0.9136    0.9133    0.9133      1200\n",
      "\n",
      "tensor([0.0361]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:19<00:00, 126.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8196    0.8285    0.8240      1201\n",
      "          负向     0.8433    0.8351    0.8392      1328\n",
      "\n",
      "    accuracy                         0.8319      2529\n",
      "   macro avg     0.8315    0.8318    0.8316      2529\n",
      "weighted avg     0.8321    0.8319    0.8320      2529\n",
      "\n",
      "tensor([0.0217]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 126.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8630    0.8446    0.8537      1126\n",
      "          负向     0.8995    0.9121    0.9058      1718\n",
      "\n",
      "    accuracy                         0.8854      2844\n",
      "   macro avg     0.8813    0.8783    0.8797      2844\n",
      "weighted avg     0.8851    0.8854    0.8852      2844\n",
      "\n",
      "tensor([0.0128]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_ce_256/multitask_cls.pth.9')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f16c2c92-d5c2-460f-932a-edf2f2495adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6417/6417 [00:51<00:00, 125.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.9075    0.9261    0.9167      3208\n",
      "          正常     0.9246    0.9056    0.9150      3209\n",
      "\n",
      "    accuracy                         0.9158      6417\n",
      "   macro avg     0.9160    0.9159    0.9158      6417\n",
      "weighted avg     0.9160    0.9158    0.9158      6417\n",
      "\n",
      "tensor([0.0770]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:25<00:00, 109.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5963    0.4958    0.5414       718\n",
      "          正常     0.8378    0.8858    0.8612      2111\n",
      "\n",
      "    accuracy                         0.7869      2829\n",
      "   macro avg     0.7171    0.6908    0.7013      2829\n",
      "weighted avg     0.7765    0.7869    0.7800      2829\n",
      "\n",
      "tensor([0.1125]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 126.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9221    0.9576    0.9395       779\n",
      "          讽刺     0.5000    0.3438    0.4074        96\n",
      "\n",
      "    accuracy                         0.8903       875\n",
      "   macro avg     0.7111    0.6507    0.6735       875\n",
      "weighted avg     0.8758    0.8903    0.8812       875\n",
      "\n",
      "tensor([0.1056]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 122.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8992    0.9174    0.9082       593\n",
      "          负向     0.9176    0.8995    0.9085       607\n",
      "\n",
      "    accuracy                         0.9083      1200\n",
      "   macro avg     0.9084    0.9084    0.9083      1200\n",
      "weighted avg     0.9085    0.9083    0.9083      1200\n",
      "\n",
      "tensor([0.1026]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:19<00:00, 127.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8167    0.8127    0.8147      1201\n",
      "          负向     0.8313    0.8351    0.8332      1328\n",
      "\n",
      "    accuracy                         0.8244      2529\n",
      "   macro avg     0.8240    0.8239    0.8239      2529\n",
      "weighted avg     0.8244    0.8244    0.8244      2529\n",
      "\n",
      "tensor([0.1432]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 126.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8662    0.8393    0.8525      1126\n",
      "          负向     0.8967    0.9150    0.9058      1718\n",
      "\n",
      "    accuracy                         0.8850      2844\n",
      "   macro avg     0.8815    0.8771    0.8791      2844\n",
      "weighted avg     0.8846    0.8850    0.8847      2844\n",
      "\n",
      "tensor([0.1520]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_focal_256/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e3af45a-5bf4-485e-99c4-1519de0f35d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7202    0.8371    0.7743      2106\n",
      "          正常     0.8799    0.7858    0.8302      3198\n",
      "\n",
      "    accuracy                         0.8062      5304\n",
      "   macro avg     0.8000    0.8115    0.8022      5304\n",
      "weighted avg     0.8165    0.8062    0.8080      5304\n",
      "\n",
      "tensor([0.0912]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 125.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.6115    0.3245    0.4240       718\n",
      "          正常     0.8019    0.9299    0.8612      2111\n",
      "\n",
      "    accuracy                         0.7762      2829\n",
      "   macro avg     0.7067    0.6272    0.6426      2829\n",
      "weighted avg     0.7536    0.7762    0.7502      2829\n",
      "\n",
      "tensor([0.0236]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 126.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.8976    0.9795    0.9368       779\n",
      "          讽刺     0.3600    0.0938    0.1488        96\n",
      "\n",
      "    accuracy                         0.8823       875\n",
      "   macro avg     0.6288    0.5366    0.5428       875\n",
      "weighted avg     0.8387    0.8823    0.8503       875\n",
      "\n",
      "tensor([0.0214]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 121.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8849    0.8820    0.8834       593\n",
      "          负向     0.8851    0.8880    0.8865       607\n",
      "\n",
      "    accuracy                         0.8850      1200\n",
      "   macro avg     0.8850    0.8850    0.8850      1200\n",
      "weighted avg     0.8850    0.8850    0.8850      1200\n",
      "\n",
      "tensor([0.0228]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:19<00:00, 126.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.7964    0.8010    0.7987      1201\n",
      "          负向     0.8191    0.8148    0.8169      1328\n",
      "\n",
      "    accuracy                         0.8082      2529\n",
      "   macro avg     0.8077    0.8079    0.8078      2529\n",
      "weighted avg     0.8083    0.8082    0.8082      2529\n",
      "\n",
      "tensor([0.0255]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 126.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8475    0.8144    0.8306      1126\n",
      "          负向     0.8814    0.9040    0.8925      1718\n",
      "\n",
      "    accuracy                         0.8685      2844\n",
      "   macro avg     0.8644    0.8592    0.8616      2844\n",
      "weighted avg     0.8680    0.8685    0.8680      2844\n",
      "\n",
      "tensor([0.0368]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_contrast_intent_v1/multitask_cls.pth.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d21ccffe-66ff-4772-88de-6ab24412153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ece_fn = ECE(n_bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32cc476b-9973-4b61-8b05-85cdca4a3e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1104])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict = {\n",
    "    '冒犯':0,\n",
    "    '正常':1\n",
    "}\n",
    "\n",
    "gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "pred_score_l = torch.tensor([[item[0][1], item[1][1]] for item in pred_score])\n",
    "\n",
    "ece_fn(pred_score_l, gold_l, mode='probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f8d4490-f58a-441f-95fa-f38238cc70bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0198])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict = {\n",
    "    '负向':0,\n",
    "    '正向':1\n",
    "}\n",
    "\n",
    "gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "pred_score_l = torch.tensor([[item[0][1], item[1][1]] for item in pred_score])\n",
    "\n",
    "ece_fn(pred_score_l, gold_l, mode='probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32e811-a4a8-4415-b2d5-ef3d3c89ffd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
