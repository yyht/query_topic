{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96481ad-f2af-428a-b2a5-2462dad43514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys,os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21b93841-06d2-4524-8422-1a4ffb17b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.extend(['/root/xiaoda/query_topic/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a71db9-eb25-4eae-b5e4-a4939016299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "https://github.com/ondrejbohdal/meta-calibration/blob/main/Metrics/metrics.py\n",
    "\"\"\"\n",
    "\n",
    "class ECE(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(ECE, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels, mode='logits'):\n",
    "        if mode == 'logits':\n",
    "            softmaxes = F.softmax(logits, dim=1)\n",
    "        else:\n",
    "            softmaxes = logits\n",
    "        # softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        \n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca3fe83-6366-42d1-9d4d-4dd60b26cfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'负向': 0, '正向': 1} === {0: '负向', 1: '正向'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/20/2022 18:03:00 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizerFast\n",
    "import transformers\n",
    "from datetime import timedelta\n",
    "\n",
    "import os, sys\n",
    "cur_dir_path = '/root/xiaoda/query_topic/'\n",
    "\n",
    "sys.path.extend([cur_dir_path])\n",
    "\n",
    "from nets.them_classifier import MyBaseModel, RobertaClassifier\n",
    "\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TopicInfer(object):\n",
    "    def __init__(self, config_path):\n",
    "\n",
    "        import torch, os, sys\n",
    "\n",
    "        con = configparser.ConfigParser()\n",
    "        con_path = os.path.join(cur_dir_path, config_path)\n",
    "        con.read(con_path, encoding='utf8')\n",
    "\n",
    "        args_path = dict(dict(con.items('paths')), **dict(con.items(\"para\")))\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(args_path[\"model_path\"], do_lower_case=True)\n",
    "\n",
    "        label_list = []\n",
    "        label_path = os.path.join(cur_dir_path, args_path['label_path'])\n",
    "        with open(label_path, 'r') as frobj:\n",
    "            for line in frobj:\n",
    "                label_list.append(line.strip())\n",
    "        n_classes = len(label_list)\n",
    "\n",
    "        self.label2id, self.id2label = {}, {}\n",
    "        for idx, label in enumerate(label_list):\n",
    "            self.label2id[label] = idx\n",
    "            self.id2label[idx] = label\n",
    "            \n",
    "        print(self.label2id, '===', self.id2label)\n",
    "        \n",
    "        output_path = os.path.join(cur_dir_path, args_path['output_path'])\n",
    "\n",
    "        from roformer import RoFormerModel, RoFormerConfig\n",
    "\n",
    "        config = RoFormerConfig.from_pretrained(args_path[\"model_path\"])\n",
    "        encoder = RoFormerModel(config=config)\n",
    "        \n",
    "        encoder_net = MyBaseModel(encoder, config)\n",
    "\n",
    "        classify_net = RobertaClassifier(\n",
    "            hidden_size=config.hidden_size, \n",
    "            dropout_prob=con.getfloat('para', 'out_dropout_rate'),\n",
    "            num_labels=n_classes, \n",
    "            dropout_type=con.get('para', 'dropout_type'))\n",
    "\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        class TopicClassifier(nn.Module):\n",
    "            def __init__(self, transformer, classifier):\n",
    "                super().__init__()\n",
    "\n",
    "                self.transformer = transformer\n",
    "                self.classifier = classifier\n",
    "\n",
    "            def forward(self, input_ids, input_mask, \n",
    "                        segment_ids=None, transformer_mode='mean_pooling'):\n",
    "                hidden_states = self.transformer(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              return_mode=transformer_mode)\n",
    "                ce_logits = self.classifier(hidden_states)\n",
    "                return ce_logits, hidden_states\n",
    "\n",
    "        import os\n",
    "        self.net = TopicClassifier(encoder_net, classify_net).to(self.device)\n",
    "        # eo = 9\n",
    "        # ckpt = torch.load(os.path.join(output_path, 'cls.pth.{}'.format(eo)), map_location=self.device)\n",
    "        # self.topic_net.load_state_dict(ckpt)\n",
    "        # self.topic_net.eval()\n",
    "        \n",
    "    def reload(self, model_path):\n",
    "        ckpt = torch.load(model_path, map_location=self.device)\n",
    "        self.net.load_state_dict(ckpt)\n",
    "        self.net.eval() \n",
    "\n",
    "    def predict(self, text, top_n=5):\n",
    "\n",
    "        \"\"\"抽取输入text所包含的类型\n",
    "        \"\"\"\n",
    "        token2char_span_mapping = self.tokenizer(text, return_offsets_mapping=True, max_length=256)[\"offset_mapping\"]\n",
    "        encoder_txt = self.tokenizer.encode_plus(text, max_length=256)\n",
    "        input_ids = torch.tensor(encoder_txt[\"input_ids\"]).long().unsqueeze(0).to(self.device)\n",
    "        token_type_ids = torch.tensor(encoder_txt[\"token_type_ids\"]).unsqueeze(0).to(self.device)\n",
    "        attention_mask = torch.tensor(encoder_txt[\"attention_mask\"]).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            scores, hidden_states = self.net(input_ids, attention_mask, token_type_ids, \n",
    "                         transformer_mode='cls'\n",
    "                         )\n",
    "            scores = torch.nn.Softmax(dim=1)(scores)[0].data.cpu().numpy()\n",
    "        \n",
    "        schema_types = []\n",
    "        for index, score in enumerate(scores):\n",
    "             schema_types.append([self.id2label[index], float(score)])\n",
    "        return schema_types\n",
    "\n",
    "topic_api = TopicInfer('./risk_data/config_senti.ini')\n",
    "\n",
    "# text = '王二今天打车去了哪里，从哪里出发，到哪里了'\n",
    "# print(topic_api.predict(text), text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8359064d-bed9-4095-a024-4a0d3fcd3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_api.predict('目前中国的教育体制有什么优点')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d252dd1b-e53a-4f07-81e4-572acec80abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_copr = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_copr.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_copr.append(content)\n",
    "        \n",
    "senti_smp = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smp_usual.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smp.append(content)\n",
    "        \n",
    "senti_smpecisa = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smpecisa.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smpecisa.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "439d55ba-1098-4e05-84a2-44f2c3249f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluation_ece(pred_score, gold):\n",
    "    pred_score_l = []\n",
    "    mapping_dict = {}\n",
    "    for item in pred_score:\n",
    "        pred_score_l.append([])\n",
    "        for idx, p in enumerate(item):\n",
    "            if p[0] not in mapping_dict:\n",
    "                mapping_dict[p[0]] = idx\n",
    "            pred_score_l[-1].append(p[1])\n",
    "    pred_score_l = torch.tensor(pred_score_l)\n",
    "    gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "\n",
    "    ece_fn = ECE(n_bins=15)\n",
    "    print(ece_fn(pred_score_l, gold_l, mode='probs'), '==ece==')\n",
    "# pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "# evaluation_ece(pred_score, gold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5802bfce-fcf8-48ab-afee-76feb989bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "def eval_all(data, model):\n",
    "    pred = []\n",
    "    gold = []\n",
    "    pred_score = []\n",
    "    for item in tqdm(data):\n",
    "        gold.append(item['label'][0])\n",
    "        if isinstance(item['text'], list):\n",
    "            text = \"\\n\".join(item['text'])\n",
    "        else:\n",
    "            text = item['text']\n",
    "        result = model.predict(text)\n",
    "        score = sorted(result, key=lambda u:u[1], reverse=True)\n",
    "        pred.append(score[0][0])\n",
    "        pred_score.append(result)\n",
    "    print(classification_report(gold, pred, digits=4))\n",
    "    return pred, gold, pred_score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "396e4d6e-5386-4917-a140-518002ad478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model_path):\n",
    "    topic_api.reload(model_path)\n",
    "    print('===chsenti===')\n",
    "    pred, gold, pred_score = eval_all(senti_copr, topic_api)\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smpecisa===')\n",
    "    pred, gold, pred_score = eval_all(senti_smpecisa, topic_api)\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smp===')\n",
    "    pred, gold, pred_score = eval_all(senti_smp, topic_api)\n",
    "    evaluation_ece(pred_score, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6febc909-70b5-4ec5-bd33-c175c24c2a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 126.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.9003    0.9140    0.9071       593\n",
      "          负向     0.9147    0.9012    0.9079       607\n",
      "\n",
      "    accuracy                         0.9075      1200\n",
      "   macro avg     0.9075    0.9076    0.9075      1200\n",
      "weighted avg     0.9076    0.9075    0.9075      1200\n",
      "\n",
      "tensor([0.0205]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:18<00:00, 135.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8142    0.8135    0.8138      1201\n",
      "          负向     0.8315    0.8321    0.8318      1328\n",
      "\n",
      "    accuracy                         0.8233      2529\n",
      "   macro avg     0.8228    0.8228    0.8228      2529\n",
      "weighted avg     0.8232    0.8233    0.8232      2529\n",
      "\n",
      "tensor([0.0200]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:21<00:00, 133.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8526    0.8321    0.8422      1126\n",
      "          负向     0.8917    0.9057    0.8986      1718\n",
      "\n",
      "    accuracy                         0.8766      2844\n",
      "   macro avg     0.8721    0.8689    0.8704      2844\n",
      "weighted avg     0.8762    0.8766    0.8763      2844\n",
      "\n",
      "tensor([0.0186]) ==ece==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = '/data/albert.xht/xiaodao/risk_classification/them_senti/cls.pth.9'\n",
    "evaluation(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6909c862-bd2f-4871-9291-26c8ee04dc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
