{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4acf0192-1fb6-4be0-9d8c-cef06e056db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys,os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "898e7632-8f0f-4889-89b1-fc9ca409949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys\n",
    "sys.path.extend(['/root/deepIE/'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "351c71fc-dd1b-484e-bcdf-b7a634aa6063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/env python3\n",
    "\"\"\"\n",
    "==== No Bugs in code, just some Random Unexpected FEATURES ====\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┐│\n",
    "││Esc│!1 │@2 │#3 │$4 │%5 │^6 │&7 │*8 │(9 │)0 │_- │+= │|\\ │`~ ││\n",
    "│├───┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴───┤│\n",
    "││ Tab │ Q │ W │ E │ R │ T │ Y │ U │ I │ O │ P │{[ │}] │ BS  ││\n",
    "│├─────┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴─────┤│\n",
    "││ Ctrl │ A │ S │ D │ F │ G │ H │ J │ K │ L │: ;│\" '│ Enter  ││\n",
    "│├──────┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴────┬───┤│\n",
    "││ Shift  │ Z │ X │ C │ V │ B │ N │ M │< ,│> .│? /│Shift │Fn ││\n",
    "│└─────┬──┴┬──┴──┬┴───┴───┴───┴───┴───┴──┬┴───┴┬──┴┬─────┴───┘│\n",
    "│      │Fn │ Alt │         Space         │ Alt │Win│   HHKB   │\n",
    "│      └───┴─────┴───────────────────────┴─────┴───┘          │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "\n",
    "Reward Model类。\n",
    "\n",
    "Author: pankeyu\n",
    "Date: 2022/12/30\n",
    "\"\"\"\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class RewardModel(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder):\n",
    "        \"\"\"\n",
    "        init func.\n",
    "\n",
    "        Args:\n",
    "            encoder (transformers.AutoModel): backbone, 默认使用 ernie 3.0\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.reward_layer = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.tensor,\n",
    "        token_type_ids: torch.tensor,\n",
    "        attention_mask=None,\n",
    "        pos_ids=None,\n",
    "    ) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        forward 函数，返回每句话的得分值。\n",
    "\n",
    "        Args:\n",
    "            input_ids (torch.tensor): (batch, seq_len)\n",
    "            token_type_ids (torch.tensor): (batch, seq_len)\n",
    "            attention_mask (torch.tensor): (batch, seq_len)\n",
    "            pos_ids (torch.tensor): (batch, seq_len)\n",
    "\n",
    "        Returns:\n",
    "            reward: (batch, 1)\n",
    "        \"\"\"\n",
    "        pooler_output = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=pos_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )[\"pooler_output\"]                              # (batch, hidden_size)\n",
    "        reward = self.reward_layer(pooler_output)       # (batch, 1)\n",
    "        return reward\n",
    "\n",
    "\n",
    "def compute_rank_list_loss(rank_rewards_list: List[List[torch.tensor]], device='cpu') -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    通过给定的有序（从高到低）的ranklist的reward列表，计算rank loss。\n",
    "    所有排序高的句子的得分减去排序低的句子的得分差的总和，并取负。\n",
    "\n",
    "    Args:\n",
    "        rank_rewards_list (torch.tensor): 有序（从高到低）排序句子的reward列表，e.g. -> \n",
    "                                        [\n",
    "                                            [torch.tensor([0.3588]), torch.tensor([0.2481]), ...],\n",
    "                                            [torch.tensor([0.5343]), torch.tensor([0.2442]), ...],\n",
    "                                            ...\n",
    "                                        ]\n",
    "        device (str): 使用设备\n",
    "    \n",
    "    Returns:\n",
    "        loss (torch.tensor): tensor([0.4891], grad_fn=<DivBackward0>)\n",
    "    \"\"\"\n",
    "    if type(rank_rewards_list) != list:\n",
    "        raise TypeError(f'@param rank_rewards expected \"list\", received {type(rank_rewards)}.')\n",
    "    \n",
    "    loss, add_count = torch.tensor([0]).to(device), 0\n",
    "    for rank_rewards in rank_rewards_list:\n",
    "        for i in range(len(rank_rewards)-1):                                   # 遍历所有前项-后项的得分差\n",
    "            for j in range(i+1, len(rank_rewards)):\n",
    "                diff = F.sigmoid(rank_rewards[i] - rank_rewards[j])            # sigmoid到0~1之间\n",
    "                loss = loss + diff\n",
    "                add_count += 1\n",
    "    loss = loss / add_count\n",
    "    return -loss                                                               # 要最大化分差，所以要取负数\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed98b7b3-7f60-447a-ad87-d338fc481695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, default_data_collator, get_scheduler\n",
    " \n",
    "model_path = '/data/albert.xht/BERT/chinese-macbert-base/'\n",
    "\n",
    "encoder = AutoModel.from_pretrained(model_path)\n",
    "model = RewardModel(encoder=encoder)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67fce0e0-9165-4a5f-bcc8-13b88c97c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path = '/data/albert.xht/xiaodao/query_response/hhrlhf_rewards_dialog_v1/model_best/model.pt'\n",
    "ckpt_path = '/data/albert.xht/xiaodao/query_response/hhrlhf_rewards_dialog_v3_32/model_best/model.pt'\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "model.load_state_dict(ckpt)\n",
    "model = model.eval()\n",
    "device = 'cuda:0'\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0fe1fd1d-a7fc-47e8-b6ab-13cad2603aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text, max_seq_len=512):\n",
    "    if isinstance(text, list):\n",
    "        batch_texts = text\n",
    "    else:\n",
    "        batch_texts = [text]\n",
    "\n",
    "    inputs = tokenizer(batch_texts, return_tensors='pt', truncation=True,\n",
    "                    max_length=max_seq_len,\n",
    "                    padding='max_length')\n",
    "    for key in inputs:\n",
    "        inputs[key] = inputs[key].to(device)\n",
    "    with torch.no_grad():\n",
    "        r = model(**inputs)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f3d0614-3413-4712-99a7-bb20074caf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12164it [12:21, 16.41it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with open('/data/albert.xht/hh-rlhf/HC3-Chinese.reward', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/HC3-Chinese') as frobj:\n",
    "        for line in tqdm(frobj):\n",
    "            content = json.loads(line.strip())\n",
    "            for answer in ['human_answers', 'chatgpt_answers']:\n",
    "                input_text = []\n",
    "                for h in content[answer]:\n",
    "                    if not isinstance(h, str):\n",
    "                        continue\n",
    "                    input_text.append('用户:'+content['question']+'助手:'+h)\n",
    "                with torch.no_grad():\n",
    "                    score = predict(model, input_text)\n",
    "                score = list(score.squeeze(dim=1).data.cpu().numpy())\n",
    "                content[answer+'_reward'] = [float(p) for p in score]\n",
    "            fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "863acfaf-3a78-45f5-a2f8-1dedf087e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = {}\n",
    "with open('/data/albert.xht/hh-rlhf/HC3-Chinese.reward') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        if content['topic'] not in metric:\n",
    "            metric[content['topic']] = {\n",
    "                'chatgpt':[],\n",
    "                'human':[]\n",
    "            }\n",
    "        max_score = max(content['human_answers_reward'])\n",
    "        if abs(max(content['human_answers_reward']) - max(content['chatgpt_answers_reward'])) <= 2.0:\n",
    "            metric[content['topic']]['chatgpt'].append(1)\n",
    "            metric[content['topic']]['human'].append(1)\n",
    "        elif max(content['human_answers_reward']) - max(content['chatgpt_answers_reward']) >= 5:\n",
    "            metric[content['topic']]['chatgpt'].append(0)\n",
    "            metric[content['topic']]['human'].append(1)\n",
    "        elif max(content['chatgpt_answers_reward']) - max(content['human_answers_reward']) >= 5:\n",
    "            metric[content['topic']]['chatgpt'].append(1)\n",
    "            metric[content['topic']]['human'].append(0)\n",
    "        else:\n",
    "            metric[content['topic']]['chatgpt'].append(0)\n",
    "            metric[content['topic']]['human'].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f747590a-04f2-469c-abe5-0203b5b918c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baike ==== 0.7463721030972493 === 0.8535845787307775\n",
      "law ==== 0.3763440860215054 === 0.7553763440860215\n",
      "medicine ==== 0.6694599627560521 === 0.6284916201117319\n",
      "nlpcc_dbqa ==== 0.32241076653013456 === 0.6319485078993563\n",
      "open_qa ==== 0.25296082599453384 === 0.7276040085028849\n",
      "psychology ==== 0.5286624203821656 === 0.5241128298453139\n"
     ]
    }
   ],
   "source": [
    "for key in metric:\n",
    "    metric[key]['human_helpfulness'] = sum(metric[key]['human'])/len(metric[key]['human'])\n",
    "    metric[key]['chatgpt_helpfulness'] = sum(metric[key]['chatgpt'])/len(metric[key]['chatgpt'])\n",
    "    print(key, '====', metric[key]['human_helpfulness'], '===', metric[key]['chatgpt_helpfulness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "734ce6db-7f50-4375-9832-f06cfa1e518e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-12.4269], device='cuda:0') modified \n",
      "    用户:你怎么看待那些决定成为纳粹的人\n",
      "    助手:作为一个智能工具，我可以提供一些历史和道德的观点。纳粹是二十世纪最残忍的政治运动之一，他们的行为和思想导致了大规模的屠杀和人类灾难。成为纳粹，必然是一个道德和伦理上的深度错误和犯罪行为。\n",
      "tensor([8.8076], device='cuda:0') original \n",
      "    用户:你怎么看待那些决定成为纳粹的人\n",
      "    助手:作为一个人工智能语言模型，我认为任何人都不应该成为一个纳粹分子或支持纳粹主义的人。纳粹主义是一种极端、反人类和反科学的思想体系，它建立在种族主义、歧视和仇恨的基础上，是对人类尊严和基本价值观的否定和践踏。\n",
      "成为一个纳粹分子或支持纳粹主义的人，不仅是对他人生命和尊严的漠视，也是对自己良知和道德的背叛。这些人不仅可能对他人造成伤害和痛苦，也可能对社会和人类的进步产生负面影响。\n",
      "因此，我们应该尽可能远离任何形式的纳粹主义和极端主义思想，并支持和促进人类的和平、平等、自由和公正的价值观。\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "input_text = [\n",
    "    \"\"\"\n",
    "    用户:你怎么看待那些决定成为纳粹的人\n",
    "    助手:\n",
    "    作为一个智能工具，我可以提供一些历史和道德的观点。纳粹是二十世纪最残忍的政治运动之一，他们的行为和思想导致了大规模的屠杀和人类灾难。成为纳粹，必然是一个道德和伦理上的深度错误和犯罪行为。\"\"\",\n",
    "    \"\"\"\n",
    "    用户:你怎么看待那些决定成为纳粹的人\n",
    "    助手:作为一个人工智能语言模型，我认为任何人都不应该成为一个纳粹分子或支持纳粹主义的人。纳粹主义是一种极端、反人类和反科学的思想体系，它建立在种族主义、歧视和仇恨的基础上，是对人类尊严和基本价值观的否定和践踏。\n",
    "成为一个纳粹分子或支持纳粹主义的人，不仅是对他人生命和尊严的漠视，也是对自己良知和道德的背叛。这些人不仅可能对他人造成伤害和痛苦，也可能对社会和人类的进步产生负面影响。\n",
    "因此，我们应该尽可能远离任何形式的纳粹主义和极端主义思想，并支持和促进人类的和平、平等、自由和公正的价值观。\n",
    "    \"\"\"\n",
    "]\n",
    "score = predict(model, input_text)\n",
    "for a, b, c in zip(score, ['modified', 'original', 'chatgpt'], input_text):\n",
    "    print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33aec43b-057a-4ce5-8d18-b2c46b6934ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['offensive:/mnt/albert.xht/xiaoda/sentiment/offensive/hhrlhf_query.json',\n",
       " 'query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v14/hhrlhf_query.json',\n",
       " 'query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v13/kgclue.json',\n",
       " 'query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v13/kgclue.json',\n",
       " 'topic:/mnt/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.topic.knn.final.update',\n",
       " 'query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v13/biake_qa_web_text_zh_train.json.topic.knn.final.keyword',\n",
       " 'query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v13/query.txt.1.json',\n",
       " 'query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v13/biake_qa_web_text_zh_train.json.topic.green',\n",
       " 'ciron:/mnt/albert.xht/xiaoda/sentiment/ciron/GuanSarcasm.csv.json',\n",
       " 'query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v13/小达风险提问_label_data_20230110.json.augment.train',\n",
       " 'abusive:/mnt/albert.xht/xiaoda/sentiment/green_abusive_v1/TOCAB_TR.json.text',\n",
       " 'politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.product',\n",
       " 'politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.tour',\n",
       " 'politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.law',\n",
       " 'politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.senti_ocvoid19',\n",
       " 'ciron:/mnt/albert.xht/xiaoda/sentiment/ciron/chinese_sarcasm_corpus.json',\n",
       " 'bias:/mnt/albert.xht/xiaoda/sentiment/bias/corgi_pm.json',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_jiaru_tongshi.json',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_3_0_triple.json.binary',\n",
       " 'senti_query:/mnt/albert.xht/xiaoda/sentiment/senti/senti_3_0_triple.json',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_weibo_covid19_emotion.json',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_wangyi_music.json',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_baidu_dianshibei.json.binary',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_ocvoid19.json.binary',\n",
       " 'senti_query:/mnt/albert.xht/xiaoda/sentiment/senti/senti_baidu_dianshibei.json',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_chinese_dialog.json',\n",
       " 'senti_query:/mnt/albert.xht/xiaoda/sentiment/senti/senti_ocvoid19.json',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_ocemotion.json',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_dialog.json.binary',\n",
       " 'senti_query:/mnt/albert.xht/xiaoda/sentiment/senti/senti_dialog.json',\n",
       " 'senti_query:/mnt/albert.xht/xiaoda/sentiment/senti/senti_smp_usual.json.triple',\n",
       " 'senti_query:/mnt/albert.xht/xiaoda/sentiment/senti/biake_qa_web_text_zh_train.json.knn.final.senta_ie.sample',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/biake_qa_web_text_zh_train.json.knn.final.senta_ie.sample.binary',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_copr.json',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_nlpcc.json',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_smp_usual.json',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_smpecisa.json.filter',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_waimai.json',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_weibo.json.filter',\n",
       " 'senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_online_cats.json',\n",
       " 'bias:/mnt/albert.xht/xiaoda/sentiment/bias/cdial_bias.json',\n",
       " 'bias:/mnt/albert.xht/xiaoda/sentiment/bias/swsr_bias.json',\n",
       " 'ciron:/mnt/albert.xht/xiaoda/sentiment/ciron/chinese_ciron.json',\n",
       " 'offensive:/mnt/albert.xht/xiaoda/sentiment/offensive/offensive_cold.json',\n",
       " 'query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v13/query_risk_final.json.merge.green.v19.tiny.no.offensive',\n",
       " 'teenager:/mnt/albert.xht/xiaoda/sentiment/teenager_v1/green_teenager.json',\n",
       " 'intent:/mnt/albert.xht/xiaoda/sentiment/intention_data_v2-1/train.txt',\n",
       " 'politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json',\n",
       " 'politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.porn',\n",
       " 'politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.abusive',\n",
       " 'porn:/mnt/albert.xht/xiaoda/sentiment/green_porn_v1/green_porn.json.update',\n",
       " 'porn:/mnt/albert.xht/xiaoda/sentiment/green_porn_v1/green_porn.json.waimai',\n",
       " 'porn:/mnt/albert.xht/xiaoda/sentiment/green_porn_v1/green_porn.json.caipu',\n",
       " 'porn:/mnt/albert.xht/xiaoda/sentiment/green_porn_v1/green_porn.json.caipu',\n",
       " 'porn:/mnt/albert.xht/xiaoda/sentiment/green_porn_v1/green_porn.json.caipu',\n",
       " 'porn:/mnt/albert.xht/xiaoda/sentiment/green_porn_v1/green_porn.json.caipu',\n",
       " 'abusive:/mnt/albert.xht/xiaoda/sentiment/green_abusive_v1/green_abusive.json',\n",
       " 'porn:/mnt/albert.xht/xiaoda/sentiment/green_porn/green_porn.json.cMedQA2_qa.json',\n",
       " 'politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.insuranceqa_qa.json',\n",
       " 'politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.tnews',\n",
       " 'politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.topic',\n",
       " 'politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.news']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'offensive:/mnt/albert.xht/xiaoda/sentiment/offensive/hhrlhf_query.json,query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v14/hhrlhf_query.json,query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v13/kgclue.json,query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v13/kgclue.json,topic:/mnt/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_train.json.topic.knn.final.update,query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v13/biake_qa_web_text_zh_train.json.topic.knn.final.keyword,query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v13/query.txt.1.json,query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v13/biake_qa_web_text_zh_train.json.topic.green,ciron:/mnt/albert.xht/xiaoda/sentiment/ciron/GuanSarcasm.csv.json,query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v13/小达风险提问_label_data_20230110.json.augment.train,abusive:/mnt/albert.xht/xiaoda/sentiment/green_abusive_v1/TOCAB_TR.json.text,politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.product,politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.tour,politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.law,politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.senti_ocvoid19,ciron:/mnt/albert.xht/xiaoda/sentiment/ciron/chinese_sarcasm_corpus.json,bias:/mnt/albert.xht/xiaoda/sentiment/bias/corgi_pm.json,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_jiaru_tongshi.json,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_3_0_triple.json.binary,senti_query:/mnt/albert.xht/xiaoda/sentiment/senti/senti_3_0_triple.json,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_weibo_covid19_emotion.json,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_wangyi_music.json,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_baidu_dianshibei.json.binary,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_ocvoid19.json.binary,senti_query:/mnt/albert.xht/xiaoda/sentiment/senti/senti_baidu_dianshibei.json,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_chinese_dialog.json,senti_query:/mnt/albert.xht/xiaoda/sentiment/senti/senti_ocvoid19.json,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_ocemotion.json,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_dialog.json.binary,senti_query:/mnt/albert.xht/xiaoda/sentiment/senti/senti_dialog.json,senti_query:/mnt/albert.xht/xiaoda/sentiment/senti/senti_smp_usual.json.triple,senti_query:/mnt/albert.xht/xiaoda/sentiment/senti/biake_qa_web_text_zh_train.json.knn.final.senta_ie.sample,senti:/mnt/albert.xht/xiaoda/sentiment/senti/biake_qa_web_text_zh_train.json.knn.final.senta_ie.sample.binary,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_copr.json,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_nlpcc.json,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_smp_usual.json,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_smpecisa.json.filter,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_waimai.json,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_weibo.json.filter,senti:/mnt/albert.xht/xiaoda/sentiment/senti/senti_online_cats.json,bias:/mnt/albert.xht/xiaoda/sentiment/bias/cdial_bias.json,bias:/mnt/albert.xht/xiaoda/sentiment/bias/swsr_bias.json,ciron:/mnt/albert.xht/xiaoda/sentiment/ciron/chinese_ciron.json,offensive:/mnt/albert.xht/xiaoda/sentiment/offensive/offensive_cold.json,query_risk:/mnt/albert.xht/xiaoda/sentiment/query_risk_v13/query_risk_final.json.merge.green.v19.tiny.no.offensive,teenager:/mnt/albert.xht/xiaoda/sentiment/teenager_v1/green_teenager.json,intent:/mnt/albert.xht/xiaoda/sentiment/intention_data_v2-1/train.txt,politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json,politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.porn,politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.abusive,porn:/mnt/albert.xht/xiaoda/sentiment/green_porn_v1/green_porn.json.update,porn:/mnt/albert.xht/xiaoda/sentiment/green_porn_v1/green_porn.json.waimai,porn:/mnt/albert.xht/xiaoda/sentiment/green_porn_v1/green_porn.json.caipu,porn:/mnt/albert.xht/xiaoda/sentiment/green_porn_v1/green_porn.json.caipu,porn:/mnt/albert.xht/xiaoda/sentiment/green_porn_v1/green_porn.json.caipu,porn:/mnt/albert.xht/xiaoda/sentiment/green_porn_v1/green_porn.json.caipu,abusive:/mnt/albert.xht/xiaoda/sentiment/green_abusive_v1/green_abusive.json,porn:/mnt/albert.xht/xiaoda/sentiment/green_porn/green_porn.json.cMedQA2_qa.json,politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.insuranceqa_qa.json,politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.tnews,politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.topic,politics:/mnt/albert.xht/xiaoda/sentiment/green_politics/green_politics.json.news'\n",
    "s.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe256fd0-4ebe-4252-afc0-20f8985f6c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.746365, 14.571022]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(score.squeeze().data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5755fc-2a1c-4c0b-8738-7180696600e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
