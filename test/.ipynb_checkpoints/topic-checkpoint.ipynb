{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25482390-a9b7-46a1-aa0f-568521861d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys,os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efef73ac-9b7c-45fe-80a2-910fc1fd9308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.extend(['/root/xiaoda/query_topic/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c03a36f7-3f10-4c47-8902-c656f568e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "https://github.com/ondrejbohdal/meta-calibration/blob/main/Metrics/metrics.py\n",
    "\"\"\"\n",
    "\n",
    "class ECE(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(ECE, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels, mode='logits'):\n",
    "        if mode == 'logits':\n",
    "            softmaxes = F.softmax(logits, dim=1)\n",
    "        else:\n",
    "            softmaxes = logits\n",
    "        # softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        \n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ca7416-4776-4003-8cfb-179ffc0cf07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'基金': 0, '汽车': 1, '网络安全': 2, '情商': 3, '财务税务': 4, '旅游': 5, '建筑': 6, '炫富': 7, '家电': 8, '商业': 9, '性生活': 10, '风水': 11, '人物': 12, 'VPN': 13, '吸烟': 14, '市场营销': 15, '游戏': 16, '算命': 17, '编程': 18, '死亡': 19, '公司': 20, '国家': 21, '美食/烹饪': 22, '明星': 23, '城市': 24, '银行': 25, '期货': 26, '宗教': 27, '学习': 28, '电子数码': 29, '网络暴力': 30, 'LGBT': 31, '其他': 32, '故事': 33, '社会': 34, '二手': 35, '动漫': 36, '歧视': 37, '常识': 38, '星座': 39, '冷知识': 40, '职场职业': 41, '食品': 42, '心理健康': 43, '电子商务': 44, '道德伦理': 45, '商业/理财': 46, '赚钱': 47, '神话': 48, '校园生活': 49, '色情': 50, '婚姻': 51, '家居装修': 52, '生活': 53, '灵异灵修': 54, '股票': 55, '娱乐': 56, '女性': 57, '体验': 58, '广告': 59, '天气': 60, '女权': 61, '潜规则': 62, '人类': 63, '马克思主义': 64, '历史': 65, '音乐': 66, '毒品': 67, '摄影': 68, '金融': 69, '影视': 70, '语言': 71, '环境': 72, '高铁': 73, '人际交往': 74, '夜店': 75, '价值观': 76, '恋爱': 77, '相貌': 78, 'BDSM': 79, '恐怖主义': 80, '中医': 81, '性侵犯': 82, '阅读': 83, '时尚': 84, '体育/运动': 85, '资本主义': 86, '灾害意外': 87, '博彩': 88, '成长': 89, '校园暴力': 90, '移民': 91, '美容/塑身': 92, '经济': 93, '睡眠': 94, '抄袭': 95, '电脑/网络': 96, '两性': 97, '电影': 98, '思维': 99, '房地产': 100, '民族': 101, '购房置业': 102, '法律': 103, '购物': 104, '幽默滑稽': 105, '教育/科学': 106, '性骚扰': 107, '惊悚': 108, '动植物': 109, '战争': 110, '恶俗': 111, '航空航天': 112, '交通出行': 113, '家庭关系': 114, '文化/艺术': 115, '宠物': 116, '男性': 117, '爱国': 118, '育儿': 119, '保险': 120, '爱情': 121, '健康': 122, '军事': 123, '审美': 124, '交友': 125, '小说': 126, '青春期': 127, '创业投资': 128, '情感': 129, '写作': 130, '时事政治': 131} === {0: '基金', 1: '汽车', 2: '网络安全', 3: '情商', 4: '财务税务', 5: '旅游', 6: '建筑', 7: '炫富', 8: '家电', 9: '商业', 10: '性生活', 11: '风水', 12: '人物', 13: 'VPN', 14: '吸烟', 15: '市场营销', 16: '游戏', 17: '算命', 18: '编程', 19: '死亡', 20: '公司', 21: '国家', 22: '美食/烹饪', 23: '明星', 24: '城市', 25: '银行', 26: '期货', 27: '宗教', 28: '学习', 29: '电子数码', 30: '网络暴力', 31: 'LGBT', 32: '其他', 33: '故事', 34: '社会', 35: '二手', 36: '动漫', 37: '歧视', 38: '常识', 39: '星座', 40: '冷知识', 41: '职场职业', 42: '食品', 43: '心理健康', 44: '电子商务', 45: '道德伦理', 46: '商业/理财', 47: '赚钱', 48: '神话', 49: '校园生活', 50: '色情', 51: '婚姻', 52: '家居装修', 53: '生活', 54: '灵异灵修', 55: '股票', 56: '娱乐', 57: '女性', 58: '体验', 59: '广告', 60: '天气', 61: '女权', 62: '潜规则', 63: '人类', 64: '马克思主义', 65: '历史', 66: '音乐', 67: '毒品', 68: '摄影', 69: '金融', 70: '影视', 71: '语言', 72: '环境', 73: '高铁', 74: '人际交往', 75: '夜店', 76: '价值观', 77: '恋爱', 78: '相貌', 79: 'BDSM', 80: '恐怖主义', 81: '中医', 82: '性侵犯', 83: '阅读', 84: '时尚', 85: '体育/运动', 86: '资本主义', 87: '灾害意外', 88: '博彩', 89: '成长', 90: '校园暴力', 91: '移民', 92: '美容/塑身', 93: '经济', 94: '睡眠', 95: '抄袭', 96: '电脑/网络', 97: '两性', 98: '电影', 99: '思维', 100: '房地产', 101: '民族', 102: '购房置业', 103: '法律', 104: '购物', 105: '幽默滑稽', 106: '教育/科学', 107: '性骚扰', 108: '惊悚', 109: '动植物', 110: '战争', 111: '恶俗', 112: '航空航天', 113: '交通出行', 114: '家庭关系', 115: '文化/艺术', 116: '宠物', 117: '男性', 118: '爱国', 119: '育儿', 120: '保险', 121: '爱情', 122: '健康', 123: '军事', 124: '审美', 125: '交友', 126: '小说', 127: '青春期', 128: '创业投资', 129: '情感', 130: '写作', 131: '时事政治'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2022 11:14:29 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizerFast\n",
    "import transformers\n",
    "from datetime import timedelta\n",
    "\n",
    "import os, sys\n",
    "cur_dir_path = '/root/xiaoda/query_topic/'\n",
    "\n",
    "sys.path.extend([cur_dir_path])\n",
    "\n",
    "from nets.them_classifier import MyBaseModel, RobertaClassifier\n",
    "\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TopicInfer(object):\n",
    "    def __init__(self, config_path):\n",
    "\n",
    "        import torch, os, sys\n",
    "\n",
    "        con = configparser.ConfigParser()\n",
    "        con_path = os.path.join(cur_dir_path, config_path)\n",
    "        con.read(con_path, encoding='utf8')\n",
    "\n",
    "        args_path = dict(dict(con.items('paths')), **dict(con.items(\"para\")))\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(args_path[\"model_path\"], do_lower_case=True)\n",
    "\n",
    "        label_list = []\n",
    "        label_path = os.path.join(cur_dir_path, args_path['label_path'])\n",
    "        with open(label_path, 'r') as frobj:\n",
    "            for line in frobj:\n",
    "                label_list.append(line.strip())\n",
    "        n_classes = len(label_list)\n",
    "\n",
    "        self.label2id, self.id2label = {}, {}\n",
    "        for idx, label in enumerate(label_list):\n",
    "            self.label2id[label] = idx\n",
    "            self.id2label[idx] = label\n",
    "            \n",
    "        print(self.label2id, '===', self.id2label)\n",
    "        \n",
    "        output_path = os.path.join(cur_dir_path, args_path['output_path'])\n",
    "\n",
    "        from roformer import RoFormerModel, RoFormerConfig\n",
    "\n",
    "        config = RoFormerConfig.from_pretrained(args_path[\"model_path\"])\n",
    "        encoder = RoFormerModel(config=config)\n",
    "        \n",
    "        encoder_net = MyBaseModel(encoder, config)\n",
    "\n",
    "        classify_net = RobertaClassifier(\n",
    "            hidden_size=config.hidden_size, \n",
    "            dropout_prob=con.getfloat('para', 'out_dropout_rate'),\n",
    "            num_labels=n_classes, \n",
    "            dropout_type=con.get('para', 'dropout_type'))\n",
    "\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        class TopicClassifier(nn.Module):\n",
    "            def __init__(self, transformer, classifier):\n",
    "                super().__init__()\n",
    "\n",
    "                self.transformer = transformer\n",
    "                self.classifier = classifier\n",
    "\n",
    "            def forward(self, input_ids, input_mask, \n",
    "                        segment_ids=None, transformer_mode='mean_pooling'):\n",
    "                hidden_states = self.transformer(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              return_mode=transformer_mode)\n",
    "                ce_logits = self.classifier(hidden_states)\n",
    "                return ce_logits, hidden_states\n",
    "\n",
    "        import os\n",
    "        self.net = TopicClassifier(encoder_net, classify_net).to(self.device)\n",
    "        # eo = 9\n",
    "        # ckpt = torch.load(os.path.join(output_path, 'cls.pth.{}'.format(eo)), map_location=self.device)\n",
    "        # self.topic_net.load_state_dict(ckpt)\n",
    "        # self.topic_net.eval()\n",
    "        \n",
    "    def reload(self, model_path):\n",
    "        ckpt = torch.load(model_path, map_location=self.device)\n",
    "        self.net.load_state_dict(ckpt)\n",
    "        self.net.eval() \n",
    "\n",
    "    def predict(self, text, top_n=5):\n",
    "\n",
    "        \"\"\"抽取输入text所包含的类型\n",
    "        \"\"\"\n",
    "        token2char_span_mapping = self.tokenizer(text, return_offsets_mapping=True, max_length=256)[\"offset_mapping\"]\n",
    "        encoder_txt = self.tokenizer.encode_plus(text, max_length=256)\n",
    "        input_ids = torch.tensor(encoder_txt[\"input_ids\"]).long().unsqueeze(0).to(self.device)\n",
    "        token_type_ids = torch.tensor(encoder_txt[\"token_type_ids\"]).unsqueeze(0).to(self.device)\n",
    "        attention_mask = torch.tensor(encoder_txt[\"attention_mask\"]).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            scores, hidden_states = self.net(input_ids, attention_mask, token_type_ids, \n",
    "                         transformer_mode='cls'\n",
    "                         )\n",
    "            scores = torch.nn.Softmax(dim=1)(scores)[0].data.cpu().numpy()\n",
    "        \n",
    "        schema_types = []\n",
    "        for index, score in enumerate(scores):\n",
    "             schema_types.append([self.id2label[index], float(score)])\n",
    "        schema_types = sorted(schema_types, key=lambda item:item[1], reverse=True)\n",
    "        return schema_types[0:5]\n",
    "    \n",
    "    def predict_batch(self, text):\n",
    "        if isinstance(text, list):\n",
    "            text_list = text\n",
    "        else:\n",
    "            text_list = [text]\n",
    "        model_input = self.tokenizer(text_list, return_tensors=\"pt\",padding=True)\n",
    "        for key in model_input:\n",
    "            model_input[key] = model_input[key].to(self.device)\n",
    "        with torch.no_grad():\n",
    "            scores, hidden_states = self.net(input_ids, attention_mask, token_type_ids, \n",
    "                         transformer_mode='cls'\n",
    "                         )\n",
    "            scores = torch.nn.Softmax(dim=1)(scores).data.cpu().numpy()\n",
    "        schema_types_list = []\n",
    "        for score, text in zip(scores, text_list):\n",
    "            schema_types = []\n",
    "            for index, score in enumerate(scores):\n",
    "                 schema_types.append([self.id2label[index], float(score)])\n",
    "            schema_types = sorted(schema_types, key=lambda item:item[1], reverse=True)\n",
    "\n",
    "topic_api = TopicInfer('./topic_data_v4/config.ini')\n",
    "\n",
    "# text = '王二今天打车去了哪里，从哪里出发，到哪里了'\n",
    "# print(topic_api.predict(text), text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "869100c8-12ef-44b6-9659-60b456f6b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_api.reload('/data/albert.xht/xiaodao/topic_classification_v4_label_smoothing/them/cls.pth.9')\n",
    "# topic_api.reload('/data/albert.xht/xiaodao/topic_classification_v4/them/cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01599de-eeb7-4dd7-9739-8ac0cafe6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_api.predict('察抓小偷')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "459abe26-31f3-48b2-a96d-24a672db08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "v4_valid = []\n",
    "with open('/data/albert.xht/raw_chat_corpus/topic_classification_v4/biake_qa_web_text_zh_valid.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        v4_valid.append(content)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ee3b4d81-6858-4e4b-9d7b-3d42aa671ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def eval_all(data, model, top_n=5):\n",
    "    pred = []\n",
    "    gold = []\n",
    "    pred_score = []\n",
    "    pred = 0\n",
    "    for item in tqdm(data):\n",
    "        gold.append(item['label'][0])\n",
    "        if isinstance(item['text'], list):\n",
    "            text = \"\\n\".join(item['text'])\n",
    "        else:\n",
    "            text = item['text']\n",
    "        result = model.predict(text)\n",
    "        score = sorted(result, key=lambda u:u[1], reverse=True)\n",
    "        pred_set = set([item[0] for item in score[:top_n]])\n",
    "        if set(item['label']) & pred_set:\n",
    "            pred += 1\n",
    "        pred_score.append(result)\n",
    "        # break\n",
    "    # print(classification_report(gold, pred, digits=4), '===', top_n)\n",
    "    print(pred/len(pred_score))\n",
    "    return pred_score, gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9079a934-ea45-4133-9658-fc0ede171e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = []\n",
    "for item in v4_valid:\n",
    "    if item['label'][0] in ['道德伦理']:\n",
    "        target.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9db3c1ea-6001-46f7-b5aa-f489d12b2e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_result = []\n",
    "for item in target:\n",
    "    result = topic_api.predict(item['text'])\n",
    "    if result[0][0] not in item['label']:\n",
    "        target_result.append((result, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "80701227-d75e-4e55-83a9-d2f778b2ee79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86668/86668 [10:50<00:00, 133.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7505307610652144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_score, gold = eval_all(v4_valid, topic_api, top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8a3d765d-dfc0-4e33-85f1-1411edc51d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['城市', 0.9565373659133911],\n",
       "  ['文化/艺术', 0.03183119744062424],\n",
       "  ['教育/科学', 0.0017084553837776184],\n",
       "  ['历史', 0.0014964144211262465],\n",
       "  ['电脑/网络', 0.0005834586918354034]],\n",
       " [['恋爱', 0.3455376625061035],\n",
       "  ['两性', 0.29532861709594727],\n",
       "  ['情感', 0.2196192741394043],\n",
       "  ['女性', 0.04598280042409897],\n",
       "  ['爱情', 0.024114560335874557]],\n",
       " [['情感', 0.40412089228630066],\n",
       "  ['恋爱', 0.258561909198761],\n",
       "  ['爱情', 0.22933520376682281],\n",
       "  ['两性', 0.03647314012050629],\n",
       "  ['心理健康', 0.013390579260885715]],\n",
       " [['汽车', 0.9744734764099121],\n",
       "  ['市场营销', 0.004104863852262497],\n",
       "  ['时事政治', 0.002023685025051236],\n",
       "  ['财务税务', 0.0017918514786288142],\n",
       "  ['二手', 0.001525147003121674]],\n",
       " [['学习', 0.4129531979560852],\n",
       "  ['心理健康', 0.3989134430885315],\n",
       "  ['校园生活', 0.12909871339797974],\n",
       "  ['教育/科学', 0.02070748619735241],\n",
       "  ['价值观', 0.007254814729094505]],\n",
       " [['国家', 0.5084620714187622],\n",
       "  ['历史', 0.3961915969848633],\n",
       "  ['时事政治', 0.0633591040968895],\n",
       "  ['军事', 0.012993273325264454],\n",
       "  ['战争', 0.008572555147111416]],\n",
       " [['影视', 0.9434626698493958],\n",
       "  ['社会', 0.006434758193790913],\n",
       "  ['小说', 0.005227760877460241],\n",
       "  ['职场职业', 0.004353551659733057],\n",
       "  ['法律', 0.003934794571250677]],\n",
       " [['教育/科学', 0.6441981792449951],\n",
       "  ['人类', 0.21115906536579132],\n",
       "  ['健康', 0.02870360016822815],\n",
       "  ['性生活', 0.01902402751147747],\n",
       "  ['心理健康', 0.018518302589654922]],\n",
       " [['宗教', 0.9878794550895691],\n",
       "  ['时事政治', 0.0031519855838268995],\n",
       "  ['历史', 0.0019621283281594515],\n",
       "  ['国家', 0.0009202065411955118],\n",
       "  ['恐怖主义', 0.0007010797271504998]],\n",
       " [['文化/艺术', 0.37883466482162476],\n",
       "  ['阅读', 0.2661342918872833],\n",
       "  ['小说', 0.11922892183065414],\n",
       "  ['心理健康', 0.06877262890338898],\n",
       "  ['影视', 0.02144315093755722]]]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_score[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a00c12-49c1-402c-91eb-6f76a71e3df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
