{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c24b51-0baf-4855-baac-3ee4010c944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys,os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72ff23bc-1588-42e5-959e-a45d4b3d7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.extend(['/root/xiaoda/query_topic/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25da71ce-1bec-4327-acd7-c3dd78414f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "https://github.com/ondrejbohdal/meta-calibration/blob/main/Metrics/metrics.py\n",
    "\"\"\"\n",
    "\n",
    "class ECE(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(ECE, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels, mode='logits'):\n",
    "        if mode == 'logits':\n",
    "            softmaxes = F.softmax(logits, dim=1)\n",
    "        else:\n",
    "            softmaxes = logits\n",
    "        # softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        \n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cbfd143-9337-4fea-aad8-cf2851192471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senti /root/xiaoda/query_topic/risk_data/senti_label.txt ===schema-path===\n",
      "{'label2id': {'负向': 0, '正向': 1}, 'id2label': {0: '负向', 1: '正向'}, 'label_index': 0} ==schema_type== senti\n",
      "bias /root/xiaoda/query_topic/risk_data/bias_label.txt ===schema-path===\n",
      "{'label2id': {'偏见': 0, '正常': 1}, 'id2label': {0: '偏见', 1: '正常'}, 'label_index': 1} ==schema_type== bias\n",
      "ciron /root/xiaoda/query_topic/risk_data/ciron_label.txt ===schema-path===\n",
      "{'label2id': {'讽刺': 0, '正常': 1}, 'id2label': {0: '讽刺', 1: '正常'}, 'label_index': 2} ==schema_type== ciron\n",
      "intent /root/xiaoda/query_topic/risk_data/intention_label_v0.txt ===schema-path===\n",
      "{'label2id': {'主观评价/比较/判断': 0, '寻求建议/帮助': 1, '其它': 2}, 'id2label': {0: '主观评价/比较/判断', 1: '寻求建议/帮助', 2: '其它'}, 'label_index': 3} ==schema_type== intent\n",
      "offensive /root/xiaoda/query_topic/risk_data/offensive_label.txt ===schema-path===\n",
      "{'label2id': {'冒犯': 0, '正常': 1}, 'id2label': {0: '冒犯', 1: '正常'}, 'label_index': 4} ==schema_type== offensive\n",
      "query_risk /root/xiaoda/query_topic/risk_data/query_risk_label.txt ===schema-path===\n",
      "{'label2id': {'风险': 0, '个人信息': 1, '正常': 2}, 'id2label': {0: '风险', 1: '个人信息', 2: '正常'}, 'label_index': 5} ==schema_type== query_risk\n",
      "teenager /root/xiaoda/query_topic/risk_data/teenager_label.txt ===schema-path===\n",
      "{'label2id': {'不良': 0, '正常': 1}, 'id2label': {0: '不良', 1: '正常'}, 'label_index': 6} ==schema_type== teenager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/16/2022 17:23:11 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/16/2022 17:23:11 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/16/2022 17:23:11 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/16/2022 17:23:11 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/16/2022 17:23:11 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/16/2022 17:23:11 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/16/2022 17:23:11 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizerFast\n",
    "import transformers\n",
    "from datetime import timedelta\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from nets.them_classifier import MyBaseModel, RobertaClassifier\n",
    "\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "\n",
    "cur_dir_path = '/root/xiaoda/query_topic/'\n",
    "\n",
    "def load_label(filepath):\n",
    "    label_list = []\n",
    "    with open(filepath, 'r') as frobj:\n",
    "        for line in frobj:\n",
    "            label_list.append(line.strip())\n",
    "        n_classes = len(label_list)\n",
    "\n",
    "        label2id = {}\n",
    "        id2label = {}\n",
    "        for idx, label in enumerate(label_list):\n",
    "            label2id[label] = idx\n",
    "            id2label[idx] = label\n",
    "        return label2id, id2label\n",
    "\n",
    "class RiskInfer(object):\n",
    "    def __init__(self, config_path):\n",
    "\n",
    "        import torch, os, sys\n",
    "\n",
    "        con = configparser.ConfigParser()\n",
    "        con_path = os.path.join(cur_dir_path, config_path)\n",
    "        con.read(con_path, encoding='utf8')\n",
    "\n",
    "        args_path = dict(dict(con.items('paths')), **dict(con.items(\"para\")))\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(args_path[\"model_path\"], do_lower_case=True)\n",
    "\n",
    "        from collections import OrderedDict\n",
    "        self.schema_dict = OrderedDict({})\n",
    "\n",
    "        for label_index, schema_info in enumerate(args_path[\"label_path\"].split(',')):\n",
    "            schema_type, schema_path = schema_info.split(':')\n",
    "            schema_path = os.path.join(cur_dir_path, schema_path)\n",
    "            print(schema_type, schema_path, '===schema-path===')\n",
    "            label2id, id2label = load_label(schema_path)\n",
    "            self.schema_dict[schema_type] = {\n",
    "                'label2id':label2id,\n",
    "                'id2label':id2label,\n",
    "                'label_index':label_index\n",
    "            }\n",
    "            print(self.schema_dict[schema_type], '==schema_type==', schema_type)\n",
    "        \n",
    "        output_path = os.path.join(cur_dir_path, args_path['output_path'])\n",
    "\n",
    "        from roformer import RoFormerModel, RoFormerConfig\n",
    "\n",
    "        config = RoFormerConfig.from_pretrained(args_path[\"model_path\"])\n",
    "        encoder = RoFormerModel(config=config)\n",
    "        \n",
    "        encoder_net = MyBaseModel(encoder, config)\n",
    "\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        classifier_list = []\n",
    "\n",
    "        schema_list = list(self.schema_dict.keys())\n",
    "\n",
    "        for schema_key in schema_list:\n",
    "            classifier = RobertaClassifier(\n",
    "                hidden_size=config.hidden_size, \n",
    "                dropout_prob=con.getfloat('para', 'out_dropout_rate'),\n",
    "                num_labels=len(self.schema_dict[schema_key]['label2id']), \n",
    "                dropout_type=con.get('para', 'dropout_type'))\n",
    "            classifier_list.append(classifier)\n",
    "\n",
    "        classifier_list = nn.ModuleList(classifier_list)\n",
    "\n",
    "        class MultitaskClassifier(nn.Module):\n",
    "            def __init__(self, transformer, classifier_list):\n",
    "                super().__init__()\n",
    "\n",
    "                self.transformer = transformer\n",
    "                self.classifier_list = classifier_list\n",
    "\n",
    "            def forward(self, input_ids, input_mask, \n",
    "                        segment_ids=None, \n",
    "                        transformer_mode='mean_pooling', \n",
    "                        dt_idx=None):\n",
    "                hidden_states = self.transformer(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              return_mode=transformer_mode)\n",
    "                outputs_list = []\n",
    "                \n",
    "                for idx, classifier in enumerate(self.classifier_list):\n",
    "                    \n",
    "                    if dt_idx is not None and idx != dt_idx:\n",
    "                        continue\n",
    "                    \n",
    "                    ce_logits = classifier(hidden_states)\n",
    "                    outputs_list.append(ce_logits)\n",
    "                return outputs_list, hidden_states\n",
    "\n",
    "        self.net = MultitaskClassifier(encoder_net, classifier_list).to(self.device)\n",
    "\n",
    "        # eo = 9\n",
    "        # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw.focal'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_contrast_cls.pth.{}'.format(eo)), map_location=self.device)\n",
    "        # self.net.load_state_dict(ckpt)\n",
    "        # self.net.eval()\n",
    "        \n",
    "    def reload(self, model_path):\n",
    "        ckpt = torch.load(model_path, map_location=self.device)\n",
    "        self.net.load_state_dict(ckpt)\n",
    "        self.net.eval()\n",
    "\n",
    "    def predict(self, text):\n",
    "\n",
    "        \"\"\"抽取输入text所包含的类型\n",
    "        \"\"\"\n",
    "        encoder_txt = self.tokenizer.encode_plus(text, max_length=256)\n",
    "        input_ids = torch.tensor(encoder_txt[\"input_ids\"]).long().unsqueeze(0).to(self.device)\n",
    "        token_type_ids = torch.tensor(encoder_txt[\"token_type_ids\"]).unsqueeze(0).to(self.device)\n",
    "        attention_mask = torch.tensor(encoder_txt[\"attention_mask\"]).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        scores_dict = {}\n",
    "        with torch.no_grad():\n",
    "            [logits_list, \n",
    "            hidden_states] = self.net(input_ids, \n",
    "                attention_mask, token_type_ids, transformer_mode='cls')\n",
    "        for schema_type, logits in zip(list(self.schema_dict.keys()), logits_list):\n",
    "            scores = torch.nn.Softmax(dim=1)(logits)[0].data.cpu().numpy()\n",
    "            scores_dict[schema_type] = []\n",
    "            for index, score in enumerate(scores):\n",
    "                scores_dict[schema_type].append([self.schema_dict[schema_type]['id2label'][index], \n",
    "                                        float(score)])\n",
    "        return scores_dict\n",
    "\n",
    "risk_api = RiskInfer('./risk_data/config.ini')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e0f7dfb-0767-486b-9d82-394f3f01eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "offensive = []\n",
    "with open('/data/albert.xht/sentiment/dev/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive.append(content)\n",
    "        \n",
    "offensive_test = []\n",
    "with open('/data/albert.xht/sentiment/test/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive_test.append(content)\n",
    "\n",
    "        \n",
    "cdia_bias = []\n",
    "with open('/data/albert.xht/sentiment/dev/cdial_bias.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        cdia_bias.append(content)\n",
    "        \n",
    "senti_copr = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_copr.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_copr.append(content)\n",
    "        \n",
    "ciron = []\n",
    "with open('/data/albert.xht/sentiment/dev/chinese_ciron.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        ciron.append(content)\n",
    "\n",
    "senti_smp = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smp_usual.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smp.append(content)\n",
    "        \n",
    "senti_smpecisa = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smpecisa.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smpecisa.append(content)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56a49dd8-fe1a-4fae-b310-627ddf85ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "def eval_all(data, model, key):\n",
    "    pred = []\n",
    "    gold = []\n",
    "    pred_score = []\n",
    "    for item in tqdm(data):\n",
    "        gold.append(item['label'][0])\n",
    "        if isinstance(item['text'], list):\n",
    "            text = \"\\n\".join(item['text'])\n",
    "        else:\n",
    "            text = item['text']\n",
    "        result = model.predict(text)\n",
    "        score = sorted(result[key], key=lambda u:u[1], reverse=True)\n",
    "        pred.append(score[0][0])\n",
    "        pred_score.append(result[key])\n",
    "    print(classification_report(gold, pred, digits=4))\n",
    "    return pred, gold, pred_score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bef11639-006f-4482-a104-1fc2e8d1b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluation_ece(pred_score, gold):\n",
    "    pred_score_l = []\n",
    "    mapping_dict = {}\n",
    "    for item in pred_score:\n",
    "        pred_score_l.append([])\n",
    "        for idx, p in enumerate(item):\n",
    "            if p[0] not in mapping_dict:\n",
    "                mapping_dict[p[0]] = idx\n",
    "            pred_score_l[-1].append(p[1])\n",
    "    pred_score_l = torch.tensor(pred_score_l)\n",
    "    gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "\n",
    "    ece_fn = ECE(n_bins=15)\n",
    "    print(ece_fn(pred_score_l, gold_l, mode='probs'), '==ece==')\n",
    "# pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "# evaluation_ece(pred_score, gold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "794ca494-16bf-438b-b074-6413f0ef1fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'冒犯': 0, '正常': 1}\n",
      "tensor([0.1119]) ==ece==\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22222f61-41b9-463f-9e00-9f1068e5cee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['正常', 0.9768216013908386]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "181c5de9-6e52-4eaf-b83a-d56f7cd98ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3797b0ad-bfdb-4593-9ea4-a42c2ef8cda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'正常'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a0b3183-0619-4df4-8d4b-19b0c43e6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model_path):\n",
    "    risk_api.reload(model_path)\n",
    "    print('===offensive===')\n",
    "    pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===cdia-bias===')\n",
    "    pred, gold, pred_score = eval_all(cdia_bias, risk_api, 'bias')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===ciron===')\n",
    "    pred, gold, pred_score = eval_all(ciron, risk_api, 'ciron')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===chsenti===')\n",
    "    pred, gold, pred_score = eval_all(senti_copr, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smpecisa===')\n",
    "    pred, gold, pred_score = eval_all(senti_smpecisa, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smp===')\n",
    "    pred, gold, pred_score = eval_all(senti_smp, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c81a54a-1768-4454-9e04-7f9c8c52673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7050    0.8794    0.7826      2106\n",
      "          正常     0.9051    0.7577    0.8249      3198\n",
      "\n",
      "    accuracy                         0.8060      5304\n",
      "   macro avg     0.8051    0.8185    0.8037      5304\n",
      "weighted avg     0.8257    0.8060    0.8081      5304\n",
      "\n",
      "tensor([0.1119]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:25<00:00, 111.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.6208    0.4903    0.5479       718\n",
      "          正常     0.8382    0.8982    0.8671      2111\n",
      "\n",
      "    accuracy                         0.7946      2829\n",
      "   macro avg     0.7295    0.6942    0.7075      2829\n",
      "weighted avg     0.7830    0.7946    0.7861      2829\n",
      "\n",
      "tensor([0.0231]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:08<00:00, 98.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9255    0.9730    0.9487       779\n",
      "          讽刺     0.6250    0.3646    0.4605        96\n",
      "\n",
      "    accuracy                         0.9063       875\n",
      "   macro avg     0.7753    0.6688    0.7046       875\n",
      "weighted avg     0.8925    0.9063    0.8951       875\n",
      "\n",
      "tensor([0.0363]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:12<00:00, 96.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8838    0.9106    0.8970       593\n",
      "          负向     0.9100    0.8830    0.8963       607\n",
      "\n",
      "    accuracy                         0.8967      1200\n",
      "   macro avg     0.8969    0.8968    0.8967      1200\n",
      "weighted avg     0.8971    0.8967    0.8967      1200\n",
      "\n",
      "tensor([0.0226]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:22<00:00, 111.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8053    0.8160    0.8106      1201\n",
      "          负向     0.8316    0.8215    0.8265      1328\n",
      "\n",
      "    accuracy                         0.8189      2529\n",
      "   macro avg     0.8184    0.8188    0.8186      2529\n",
      "weighted avg     0.8191    0.8189    0.8190      2529\n",
      "\n",
      "tensor([0.0208]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 125.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8540    0.8366    0.8452      1126\n",
      "          负向     0.8943    0.9063    0.9003      1718\n",
      "\n",
      "    accuracy                         0.8787      2844\n",
      "   macro avg     0.8742    0.8714    0.8727      2844\n",
      "weighted avg     0.8784    0.8787    0.8785      2844\n",
      "\n",
      "tensor([0.0247]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_intent_v1/multitask_cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00017d91-125e-422f-b2e6-329c31d639ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7100    0.8742    0.7836      2106\n",
      "          正常     0.9023    0.7649    0.8279      3198\n",
      "\n",
      "    accuracy                         0.8083      5304\n",
      "   macro avg     0.8061    0.8195    0.8057      5304\n",
      "weighted avg     0.8259    0.8083    0.8103      5304\n",
      "\n",
      "tensor([0.1089]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 124.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.6448    0.4652    0.5405       718\n",
      "          正常     0.8338    0.9128    0.8716      2111\n",
      "\n",
      "    accuracy                         0.7992      2829\n",
      "   macro avg     0.7393    0.6890    0.7060      2829\n",
      "weighted avg     0.7859    0.7992    0.7875      2829\n",
      "\n",
      "tensor([0.0267]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 125.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9210    0.9730    0.9463       779\n",
      "          讽刺     0.5962    0.3229    0.4189        96\n",
      "\n",
      "    accuracy                         0.9017       875\n",
      "   macro avg     0.7586    0.6480    0.6826       875\n",
      "weighted avg     0.8854    0.9017    0.8885       875\n",
      "\n",
      "tensor([0.0286]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 121.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8873    0.9157    0.9012       593\n",
      "          负向     0.9150    0.8863    0.9004       607\n",
      "\n",
      "    accuracy                         0.9008      1200\n",
      "   macro avg     0.9011    0.9010    0.9008      1200\n",
      "weighted avg     0.9013    0.9008    0.9008      1200\n",
      "\n",
      "tensor([0.0237]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 124.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8112    0.8193    0.8152      1201\n",
      "          负向     0.8351    0.8276    0.8313      1328\n",
      "\n",
      "    accuracy                         0.8236      2529\n",
      "   macro avg     0.8232    0.8234    0.8233      2529\n",
      "weighted avg     0.8238    0.8236    0.8237      2529\n",
      "\n",
      "tensor([0.0197]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 124.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8557    0.8428    0.8492      1126\n",
      "          负向     0.8980    0.9069    0.9024      1718\n",
      "\n",
      "    accuracy                         0.8815      2844\n",
      "   macro avg     0.8769    0.8748    0.8758      2844\n",
      "weighted avg     0.8813    0.8815    0.8813      2844\n",
      "\n",
      "tensor([0.0279]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_intent_v1/multitask_cls.pth.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1c4efc0-473c-4613-ac20-62c9d193c161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 125.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7068    0.8746    0.7818      2106\n",
      "          正常     0.9021    0.7611    0.8256      3198\n",
      "\n",
      "    accuracy                         0.8062      5304\n",
      "   macro avg     0.8045    0.8179    0.8037      5304\n",
      "weighted avg     0.8246    0.8062    0.8082      5304\n",
      "\n",
      "tensor([0.0195]) ==ece==\n",
      "===cdia-bias===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829/2829 [00:22<00:00, 125.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          偏见     0.5951    0.4749    0.5283       718\n",
      "          正常     0.8329    0.8901    0.8605      2111\n",
      "\n",
      "    accuracy                         0.7847      2829\n",
      "   macro avg     0.7140    0.6825    0.6944      2829\n",
      "weighted avg     0.7725    0.7847    0.7762      2829\n",
      "\n",
      "tensor([0.1170]) ==ece==\n",
      "===ciron===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [00:06<00:00, 125.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常     0.9230    0.9692    0.9455       779\n",
      "          讽刺     0.5789    0.3438    0.4314        96\n",
      "\n",
      "    accuracy                         0.9006       875\n",
      "   macro avg     0.7510    0.6565    0.6884       875\n",
      "weighted avg     0.8852    0.9006    0.8891       875\n",
      "\n",
      "tensor([0.1106]) ==ece==\n",
      "===chsenti===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 121.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8807    0.9089    0.8946       593\n",
      "          负向     0.9082    0.8797    0.8937       607\n",
      "\n",
      "    accuracy                         0.8942      1200\n",
      "   macro avg     0.8944    0.8943    0.8942      1200\n",
      "weighted avg     0.8946    0.8942    0.8942      1200\n",
      "\n",
      "tensor([0.1561]) ==ece==\n",
      "===senti_smpecisa===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529/2529 [00:20<00:00, 126.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8163    0.8251    0.8207      1201\n",
      "          负向     0.8403    0.8321    0.8362      1328\n",
      "\n",
      "    accuracy                         0.8288      2529\n",
      "   macro avg     0.8283    0.8286    0.8284      2529\n",
      "weighted avg     0.8289    0.8288    0.8288      2529\n",
      "\n",
      "tensor([0.1556]) ==ece==\n",
      "===senti_smp===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:22<00:00, 125.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正向     0.8627    0.8313    0.8467      1126\n",
      "          负向     0.8920    0.9133    0.9025      1718\n",
      "\n",
      "    accuracy                         0.8808      2844\n",
      "   macro avg     0.8773    0.8723    0.8746      2844\n",
      "weighted avg     0.8804    0.8808    0.8804      2844\n",
      "\n",
      "tensor([0.1674]) ==ece==\n"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_focal/multitask_cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516aa865-ee8f-4253-94b8-b1b79477427e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d21ccffe-66ff-4772-88de-6ab24412153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ece_fn = ECE(n_bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32cc476b-9973-4b61-8b05-85cdca4a3e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1104])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict = {\n",
    "    '冒犯':0,\n",
    "    '正常':1\n",
    "}\n",
    "\n",
    "gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "pred_score_l = torch.tensor([[item[0][1], item[1][1]] for item in pred_score])\n",
    "\n",
    "ece_fn(pred_score_l, gold_l, mode='probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f8d4490-f58a-441f-95fa-f38238cc70bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0198])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict = {\n",
    "    '负向':0,\n",
    "    '正向':1\n",
    "}\n",
    "\n",
    "gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "pred_score_l = torch.tensor([[item[0][1], item[1][1]] for item in pred_score])\n",
    "\n",
    "ece_fn(pred_score_l, gold_l, mode='probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32e811-a4a8-4415-b2d5-ef3d3c89ffd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
