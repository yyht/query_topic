{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e54c4ab-2741-4f22-a329-61ac15f2e5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys,os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465797f1-b537-4c5f-a151-fbd51c51a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.extend(['/root/xiaoda/query_topic/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f4bdb0-2993-4984-bffb-e7c8306b7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "https://github.com/ondrejbohdal/meta-calibration/blob/main/Metrics/metrics.py\n",
    "\"\"\"\n",
    "\n",
    "class ECE(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(ECE, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels, mode='logits'):\n",
    "        if mode == 'logits':\n",
    "            softmaxes = F.softmax(logits, dim=1)\n",
    "        else:\n",
    "            softmaxes = logits\n",
    "        # softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        \n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfda9622-a378-497d-abff-6e70c1bb62c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senti#1 /root/xiaoda/query_topic/risk_data_all/senti_label.txt ===schema-path===\n",
      "{'label2id': {'负向': 0, '正向': 1}, 'id2label': {0: '负向', 1: '正向'}, 'label_index': 0} ==schema_type== senti#1\n",
      "senti#2 /root/xiaoda/query_topic/risk_data_all/senti_label.txt ===schema-path===\n",
      "{'label2id': {'负向': 0, '正向': 1}, 'id2label': {0: '负向', 1: '正向'}, 'label_index': 1} ==schema_type== senti#2\n",
      "senti#3 /root/xiaoda/query_topic/risk_data_all/senti_label.txt ===schema-path===\n",
      "{'label2id': {'负向': 0, '正向': 1}, 'id2label': {0: '负向', 1: '正向'}, 'label_index': 2} ==schema_type== senti#3\n",
      "senti#4 /root/xiaoda/query_topic/risk_data_all/senti_label.txt ===schema-path===\n",
      "{'label2id': {'负向': 0, '正向': 1}, 'id2label': {0: '负向', 1: '正向'}, 'label_index': 3} ==schema_type== senti#4\n",
      "senti#5 /root/xiaoda/query_topic/risk_data_all/senti_label.txt ===schema-path===\n",
      "{'label2id': {'负向': 0, '正向': 1}, 'id2label': {0: '负向', 1: '正向'}, 'label_index': 4} ==schema_type== senti#5\n",
      "senti#6 /root/xiaoda/query_topic/risk_data_all/senti_label.txt ===schema-path===\n",
      "{'label2id': {'负向': 0, '正向': 1}, 'id2label': {0: '负向', 1: '正向'}, 'label_index': 5} ==schema_type== senti#6\n",
      "bias#1 /root/xiaoda/query_topic/risk_data_all/bias_label.txt ===schema-path===\n",
      "{'label2id': {'偏见': 0, '正常': 1}, 'id2label': {0: '偏见', 1: '正常'}, 'label_index': 6} ==schema_type== bias#1\n",
      "bias#2 /root/xiaoda/query_topic/risk_data_all/bias_label.txt ===schema-path===\n",
      "{'label2id': {'偏见': 0, '正常': 1}, 'id2label': {0: '偏见', 1: '正常'}, 'label_index': 7} ==schema_type== bias#2\n",
      "ciron /root/xiaoda/query_topic/risk_data_all/ciron_label.txt ===schema-path===\n",
      "{'label2id': {'讽刺': 0, '正常': 1}, 'id2label': {0: '讽刺', 1: '正常'}, 'label_index': 8} ==schema_type== ciron\n",
      "intent /root/xiaoda/query_topic/risk_data_all/intention_label_v0.txt ===schema-path===\n",
      "{'label2id': {'主观评价/比较/判断': 0, '寻求建议/帮助': 1, '其它': 2}, 'id2label': {0: '主观评价/比较/判断', 1: '寻求建议/帮助', 2: '其它'}, 'label_index': 9} ==schema_type== intent\n",
      "offensive /root/xiaoda/query_topic/risk_data_all/offensive_label.txt ===schema-path===\n",
      "{'label2id': {'冒犯': 0, '正常': 1}, 'id2label': {0: '冒犯', 1: '正常'}, 'label_index': 10} ==schema_type== offensive\n",
      "query_risk /root/xiaoda/query_topic/risk_data_all/query_risk_label.txt ===schema-path===\n",
      "{'label2id': {'风险': 0, '个人信息': 1, '正常': 2}, 'id2label': {0: '风险', 1: '个人信息', 2: '正常'}, 'label_index': 11} ==schema_type== query_risk\n",
      "teenager /root/xiaoda/query_topic/risk_data_all/teenager_label.txt ===schema-path===\n",
      "{'label2id': {'不良': 0, '正常': 1}, 'id2label': {0: '不良', 1: '正常'}, 'label_index': 12} ==schema_type== teenager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/20/2022 10:24:55 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/20/2022 10:24:55 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/20/2022 10:24:55 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/20/2022 10:24:55 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/20/2022 10:24:55 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/20/2022 10:24:55 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/20/2022 10:24:55 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/20/2022 10:24:55 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/20/2022 10:24:55 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/20/2022 10:24:55 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/20/2022 10:24:55 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/20/2022 10:24:55 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/20/2022 10:24:55 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizerFast\n",
    "import transformers\n",
    "from datetime import timedelta\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from nets.them_classifier import MyBaseModel, RobertaClassifier\n",
    "\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "\n",
    "cur_dir_path = '/root/xiaoda/query_topic/'\n",
    "\n",
    "def load_label(filepath):\n",
    "    label_list = []\n",
    "    with open(filepath, 'r') as frobj:\n",
    "        for line in frobj:\n",
    "            label_list.append(line.strip())\n",
    "        n_classes = len(label_list)\n",
    "\n",
    "        label2id = {}\n",
    "        id2label = {}\n",
    "        for idx, label in enumerate(label_list):\n",
    "            label2id[label] = idx\n",
    "            id2label[idx] = label\n",
    "        return label2id, id2label\n",
    "\n",
    "class RiskInfer(object):\n",
    "    def __init__(self, config_path):\n",
    "\n",
    "        import torch, os, sys\n",
    "\n",
    "        con = configparser.ConfigParser()\n",
    "        con_path = os.path.join(cur_dir_path, config_path)\n",
    "        con.read(con_path, encoding='utf8')\n",
    "\n",
    "        args_path = dict(dict(con.items('paths')), **dict(con.items(\"para\")))\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(args_path[\"model_path\"], do_lower_case=True)\n",
    "\n",
    "        from collections import OrderedDict\n",
    "        self.schema_dict = OrderedDict({})\n",
    "\n",
    "        for label_index, schema_info in enumerate(args_path[\"label_path\"].split(',')):\n",
    "            schema_type, schema_path = schema_info.split(':')\n",
    "            schema_path = os.path.join(cur_dir_path, schema_path)\n",
    "            print(schema_type, schema_path, '===schema-path===')\n",
    "            label2id, id2label = load_label(schema_path)\n",
    "            self.schema_dict[schema_type] = {\n",
    "                'label2id':label2id,\n",
    "                'id2label':id2label,\n",
    "                'label_index':label_index\n",
    "            }\n",
    "            print(self.schema_dict[schema_type], '==schema_type==', schema_type)\n",
    "        \n",
    "        output_path = os.path.join(cur_dir_path, args_path['output_path'])\n",
    "\n",
    "        from roformer import RoFormerModel, RoFormerConfig\n",
    "\n",
    "        config = RoFormerConfig.from_pretrained(args_path[\"model_path\"])\n",
    "        encoder = RoFormerModel(config=config)\n",
    "        \n",
    "        encoder_net = MyBaseModel(encoder, config)\n",
    "\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        classifier_list = []\n",
    "\n",
    "        schema_list = list(self.schema_dict.keys())\n",
    "\n",
    "        for schema_key in schema_list:\n",
    "            classifier = RobertaClassifier(\n",
    "                hidden_size=config.hidden_size, \n",
    "                dropout_prob=con.getfloat('para', 'out_dropout_rate'),\n",
    "                num_labels=len(self.schema_dict[schema_key]['label2id']), \n",
    "                dropout_type=con.get('para', 'dropout_type'))\n",
    "            classifier_list.append(classifier)\n",
    "\n",
    "        classifier_list = nn.ModuleList(classifier_list)\n",
    "\n",
    "        class MultitaskClassifier(nn.Module):\n",
    "            def __init__(self, transformer, classifier_list):\n",
    "                super().__init__()\n",
    "\n",
    "                self.transformer = transformer\n",
    "                self.classifier_list = classifier_list\n",
    "\n",
    "            def forward(self, input_ids, input_mask, \n",
    "                        segment_ids=None, \n",
    "                        transformer_mode='mean_pooling', \n",
    "                        dt_idx=None):\n",
    "                hidden_states = self.transformer(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              return_mode=transformer_mode)\n",
    "                outputs_list = []\n",
    "                \n",
    "                for idx, classifier in enumerate(self.classifier_list):\n",
    "                    \n",
    "                    if dt_idx is not None and idx != dt_idx:\n",
    "                        continue\n",
    "                    \n",
    "                    ce_logits = classifier(hidden_states)\n",
    "                    outputs_list.append(ce_logits)\n",
    "                return outputs_list, hidden_states\n",
    "\n",
    "        self.net = MultitaskClassifier(encoder_net, classifier_list).to(self.device)\n",
    "\n",
    "        # eo = 9\n",
    "        # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw.focal'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_contrast_cls.pth.{}'.format(eo)), map_location=self.device)\n",
    "        # self.net.load_state_dict(ckpt)\n",
    "        # self.net.eval()\n",
    "        \n",
    "    def reload(self, model_path):\n",
    "        ckpt = torch.load(model_path, map_location=self.device)\n",
    "        self.net.load_state_dict(ckpt)\n",
    "        self.net.eval()\n",
    "\n",
    "    def predict(self, text):\n",
    "\n",
    "        \"\"\"抽取输入text所包含的类型\n",
    "        \"\"\"\n",
    "        encoder_txt = self.tokenizer.encode_plus(text, max_length=256)\n",
    "        input_ids = torch.tensor(encoder_txt[\"input_ids\"]).long().unsqueeze(0).to(self.device)\n",
    "        token_type_ids = torch.tensor(encoder_txt[\"token_type_ids\"]).unsqueeze(0).to(self.device)\n",
    "        attention_mask = torch.tensor(encoder_txt[\"attention_mask\"]).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        scores_dict = {}\n",
    "        with torch.no_grad():\n",
    "            [logits_list, \n",
    "            hidden_states] = self.net(input_ids, \n",
    "                attention_mask, token_type_ids, transformer_mode='cls')\n",
    "        for schema_type, logits in zip(list(self.schema_dict.keys()), logits_list):\n",
    "            scores = torch.nn.Softmax(dim=1)(logits)[0].data.cpu().numpy()\n",
    "            scores_dict[schema_type] = []\n",
    "            for index, score in enumerate(scores):\n",
    "                scores_dict[schema_type].append([self.schema_dict[schema_type]['id2label'][index], \n",
    "                                        float(score)])\n",
    "        return scores_dict\n",
    "\n",
    "risk_api = RiskInfer('./risk_data_all/config.ini')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44f0df61-6038-4625-98b2-2d1723a74425",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "offensive = []\n",
    "with open('/data/albert.xht/sentiment/dev/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive.append(content)\n",
    "        \n",
    "offensive_test = []\n",
    "with open('/data/albert.xht/sentiment/test/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive_test.append(content)\n",
    "\n",
    "        \n",
    "cdia_bias = []\n",
    "with open('/data/albert.xht/sentiment/dev/cdial_bias.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        cdia_bias.append(content)\n",
    "        \n",
    "senti_copr = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_copr.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_copr.append(content)\n",
    "        \n",
    "ciron = []\n",
    "with open('/data/albert.xht/sentiment/dev/chinese_ciron.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        ciron.append(content)\n",
    "\n",
    "senti_smp = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smp_usual.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smp.append(content)\n",
    "        \n",
    "senti_smpecisa = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smpecisa.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smpecisa.append(content)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a80fa64-5c38-4fbe-b1d8-32620663a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "def eval_all(data, model, key):\n",
    "    pred = []\n",
    "    gold = []\n",
    "    pred_score = []\n",
    "    for item in tqdm(data):\n",
    "        gold.append(item['label'][0])\n",
    "        if isinstance(item['text'], list):\n",
    "            text = \"\\n\".join(item['text'])\n",
    "        else:\n",
    "            text = item['text']\n",
    "        result = model.predict(text)\n",
    "        score = sorted(result[key], key=lambda u:u[1], reverse=True)\n",
    "        pred.append(score[0][0])\n",
    "        pred_score.append(result[key])\n",
    "    print(classification_report(gold, pred, digits=4), '===', key)\n",
    "    return pred, gold, pred_score\n",
    "    \n",
    "\n",
    "def evaluation_ece(pred_score, gold):\n",
    "    pred_score_l = []\n",
    "    mapping_dict = {}\n",
    "    for item in pred_score:\n",
    "        pred_score_l.append([])\n",
    "        for idx, p in enumerate(item):\n",
    "            if p[0] not in mapping_dict:\n",
    "                mapping_dict[p[0]] = idx\n",
    "            pred_score_l[-1].append(p[1])\n",
    "    pred_score_l = torch.tensor(pred_score_l)\n",
    "    gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "\n",
    "    ece_fn = ECE(n_bins=15)\n",
    "    print(ece_fn(pred_score_l, gold_l, mode='probs'), '==ece==')\n",
    "# pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "# evaluation_ece(pred_score, gold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec7a90e-340c-4972-82fd-cf239ecd51d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model_path):\n",
    "    risk_api.reload(model_path)\n",
    "    print('===offensive===')\n",
    "    pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===cdia-bias===')\n",
    "    pred, gold, pred_score = eval_all(cdia_bias, risk_api, 'bias#1')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===ciron===')\n",
    "    pred, gold, pred_score = eval_all(ciron, risk_api, 'ciron')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===chsenti===')\n",
    "    pred, gold, pred_score = eval_all(senti_copr, risk_api, 'senti#1')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smpecisa===')\n",
    "    pred, gold, pred_score = eval_all(senti_smpecisa, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    print('===senti_smp===')\n",
    "    pred, gold, pred_score = eval_all(senti_smp, risk_api, 'senti')\n",
    "    evaluation_ece(pred_score, gold)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
