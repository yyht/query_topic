{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c24b51-0baf-4855-baac-3ee4010c944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys,os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72ff23bc-1588-42e5-959e-a45d4b3d7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.extend(['/root/xiaoda/query_topic/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25da71ce-1bec-4327-acd7-c3dd78414f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "https://github.com/ondrejbohdal/meta-calibration/blob/main/Metrics/metrics.py\n",
    "\"\"\"\n",
    "\n",
    "class ECE(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(ECE, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels, mode='logits'):\n",
    "        if mode == 'logits':\n",
    "            softmaxes = F.softmax(logits, dim=1)\n",
    "        else:\n",
    "            softmaxes = logits\n",
    "        # softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        \n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cbfd143-9337-4fea-aad8-cf2851192471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senti /root/xiaoda/query_topic/risk_data/senti_label.txt ===schema-path===\n",
      "{'label2id': {'负向': 0, '正向': 1}, 'id2label': {0: '负向', 1: '正向'}, 'label_index': 0} ==schema_type== senti\n",
      "bias /root/xiaoda/query_topic/risk_data/bias_label.txt ===schema-path===\n",
      "{'label2id': {'偏见': 0, '正常': 1}, 'id2label': {0: '偏见', 1: '正常'}, 'label_index': 1} ==schema_type== bias\n",
      "ciron /root/xiaoda/query_topic/risk_data/ciron_label.txt ===schema-path===\n",
      "{'label2id': {'讽刺': 0, '正常': 1}, 'id2label': {0: '讽刺', 1: '正常'}, 'label_index': 2} ==schema_type== ciron\n",
      "intent /root/xiaoda/query_topic/risk_data/intention_label_v0.txt ===schema-path===\n",
      "{'label2id': {'主观评价/比较/判断': 0, '寻求建议/帮助': 1, '其它': 2}, 'id2label': {0: '主观评价/比较/判断', 1: '寻求建议/帮助', 2: '其它'}, 'label_index': 3} ==schema_type== intent\n",
      "offensive /root/xiaoda/query_topic/risk_data/offensive_label.txt ===schema-path===\n",
      "{'label2id': {'冒犯': 0, '正常': 1}, 'id2label': {0: '冒犯', 1: '正常'}, 'label_index': 4} ==schema_type== offensive\n",
      "query_risk /root/xiaoda/query_topic/risk_data/query_risk_label.txt ===schema-path===\n",
      "{'label2id': {'风险': 0, '个人信息': 1, '正常': 2}, 'id2label': {0: '风险', 1: '个人信息', 2: '正常'}, 'label_index': 5} ==schema_type== query_risk\n",
      "teenager /root/xiaoda/query_topic/risk_data/teenager_label.txt ===schema-path===\n",
      "{'label2id': {'不良': 0, '正常': 1}, 'id2label': {0: '不良', 1: '正常'}, 'label_index': 6} ==schema_type== teenager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/16/2022 17:23:11 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/16/2022 17:23:11 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/16/2022 17:23:11 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/16/2022 17:23:11 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/16/2022 17:23:11 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/16/2022 17:23:11 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n",
      "12/16/2022 17:23:11 - INFO - nets.them_classifier - ++RobertaClassifier++ apply stable dropout++\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizerFast\n",
    "import transformers\n",
    "from datetime import timedelta\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from nets.them_classifier import MyBaseModel, RobertaClassifier\n",
    "\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "\n",
    "cur_dir_path = '/root/xiaoda/query_topic/'\n",
    "\n",
    "def load_label(filepath):\n",
    "    label_list = []\n",
    "    with open(filepath, 'r') as frobj:\n",
    "        for line in frobj:\n",
    "            label_list.append(line.strip())\n",
    "        n_classes = len(label_list)\n",
    "\n",
    "        label2id = {}\n",
    "        id2label = {}\n",
    "        for idx, label in enumerate(label_list):\n",
    "            label2id[label] = idx\n",
    "            id2label[idx] = label\n",
    "        return label2id, id2label\n",
    "\n",
    "class RiskInfer(object):\n",
    "    def __init__(self, config_path):\n",
    "\n",
    "        import torch, os, sys\n",
    "\n",
    "        con = configparser.ConfigParser()\n",
    "        con_path = os.path.join(cur_dir_path, config_path)\n",
    "        con.read(con_path, encoding='utf8')\n",
    "\n",
    "        args_path = dict(dict(con.items('paths')), **dict(con.items(\"para\")))\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(args_path[\"model_path\"], do_lower_case=True)\n",
    "\n",
    "        from collections import OrderedDict\n",
    "        self.schema_dict = OrderedDict({})\n",
    "\n",
    "        for label_index, schema_info in enumerate(args_path[\"label_path\"].split(',')):\n",
    "            schema_type, schema_path = schema_info.split(':')\n",
    "            schema_path = os.path.join(cur_dir_path, schema_path)\n",
    "            print(schema_type, schema_path, '===schema-path===')\n",
    "            label2id, id2label = load_label(schema_path)\n",
    "            self.schema_dict[schema_type] = {\n",
    "                'label2id':label2id,\n",
    "                'id2label':id2label,\n",
    "                'label_index':label_index\n",
    "            }\n",
    "            print(self.schema_dict[schema_type], '==schema_type==', schema_type)\n",
    "        \n",
    "        output_path = os.path.join(cur_dir_path, args_path['output_path'])\n",
    "\n",
    "        from roformer import RoFormerModel, RoFormerConfig\n",
    "\n",
    "        config = RoFormerConfig.from_pretrained(args_path[\"model_path\"])\n",
    "        encoder = RoFormerModel(config=config)\n",
    "        \n",
    "        encoder_net = MyBaseModel(encoder, config)\n",
    "\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        classifier_list = []\n",
    "\n",
    "        schema_list = list(self.schema_dict.keys())\n",
    "\n",
    "        for schema_key in schema_list:\n",
    "            classifier = RobertaClassifier(\n",
    "                hidden_size=config.hidden_size, \n",
    "                dropout_prob=con.getfloat('para', 'out_dropout_rate'),\n",
    "                num_labels=len(self.schema_dict[schema_key]['label2id']), \n",
    "                dropout_type=con.get('para', 'dropout_type'))\n",
    "            classifier_list.append(classifier)\n",
    "\n",
    "        classifier_list = nn.ModuleList(classifier_list)\n",
    "\n",
    "        class MultitaskClassifier(nn.Module):\n",
    "            def __init__(self, transformer, classifier_list):\n",
    "                super().__init__()\n",
    "\n",
    "                self.transformer = transformer\n",
    "                self.classifier_list = classifier_list\n",
    "\n",
    "            def forward(self, input_ids, input_mask, \n",
    "                        segment_ids=None, \n",
    "                        transformer_mode='mean_pooling', \n",
    "                        dt_idx=None):\n",
    "                hidden_states = self.transformer(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              return_mode=transformer_mode)\n",
    "                outputs_list = []\n",
    "                \n",
    "                for idx, classifier in enumerate(self.classifier_list):\n",
    "                    \n",
    "                    if dt_idx is not None and idx != dt_idx:\n",
    "                        continue\n",
    "                    \n",
    "                    ce_logits = classifier(hidden_states)\n",
    "                    outputs_list.append(ce_logits)\n",
    "                return outputs_list, hidden_states\n",
    "\n",
    "        self.net = MultitaskClassifier(encoder_net, classifier_list).to(self.device)\n",
    "\n",
    "        # eo = 9\n",
    "        # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_cls.pth.{}.raw.focal'.format(eo)), map_location=self.device)\n",
    "        # # ckpt = torch.load(os.path.join(output_path, 'multitask_contrast_cls.pth.{}'.format(eo)), map_location=self.device)\n",
    "        # self.net.load_state_dict(ckpt)\n",
    "        # self.net.eval()\n",
    "        \n",
    "    def reload(self, model_path):\n",
    "        ckpt = torch.load(model_path, map_location=self.device)\n",
    "        self.net.load_state_dict(ckpt)\n",
    "        self.net.eval()\n",
    "\n",
    "    def predict(self, text):\n",
    "\n",
    "        \"\"\"抽取输入text所包含的类型\n",
    "        \"\"\"\n",
    "        encoder_txt = self.tokenizer.encode_plus(text, max_length=256)\n",
    "        input_ids = torch.tensor(encoder_txt[\"input_ids\"]).long().unsqueeze(0).to(self.device)\n",
    "        token_type_ids = torch.tensor(encoder_txt[\"token_type_ids\"]).unsqueeze(0).to(self.device)\n",
    "        attention_mask = torch.tensor(encoder_txt[\"attention_mask\"]).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        scores_dict = {}\n",
    "        with torch.no_grad():\n",
    "            [logits_list, \n",
    "            hidden_states] = self.net(input_ids, \n",
    "                attention_mask, token_type_ids, transformer_mode='cls')\n",
    "        for schema_type, logits in zip(list(self.schema_dict.keys()), logits_list):\n",
    "            scores = torch.nn.Softmax(dim=1)(logits)[0].data.cpu().numpy()\n",
    "            scores_dict[schema_type] = []\n",
    "            for index, score in enumerate(scores):\n",
    "                scores_dict[schema_type].append([self.schema_dict[schema_type]['id2label'][index], \n",
    "                                        float(score)])\n",
    "        return scores_dict\n",
    "\n",
    "risk_api = RiskInfer('./risk_data/config.ini')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e0f7dfb-0767-486b-9d82-394f3f01eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "offensive = []\n",
    "with open('/data/albert.xht/sentiment/dev/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive.append(content)\n",
    "        \n",
    "offensive_test = []\n",
    "with open('/data/albert.xht/sentiment/test/offensive_cold.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        offensive_test.append(content)\n",
    "\n",
    "        \n",
    "cdia_bias = []\n",
    "with open('/data/albert.xht/sentiment/dev/cdial_bias.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        cdia_bias.append(content)\n",
    "        \n",
    "senti_copr = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_copr.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_copr.append(content)\n",
    "        \n",
    "ciron = []\n",
    "with open('/data/albert.xht/sentiment/dev/chinese_ciron.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        ciron.append(content)\n",
    "\n",
    "senti_smp = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smp_usual.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smp.append(content)\n",
    "        \n",
    "senti_smpecisa = []\n",
    "with open('/data/albert.xht/sentiment/dev/senti_smpecisa.json') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        senti_smpecisa.append(content)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56a49dd8-fe1a-4fae-b310-627ddf85ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "def eval_all(data, model, key):\n",
    "    pred = []\n",
    "    gold = []\n",
    "    pred_score = []\n",
    "    for item in tqdm(data):\n",
    "        gold.append(item['label'][0])\n",
    "        if isinstance(item['text'], list):\n",
    "            text = \"\\n\".join(item['text'])\n",
    "        else:\n",
    "            text = item['text']\n",
    "        result = model.predict(text)\n",
    "        score = sorted(result[key], key=lambda u:u[1], reverse=True)\n",
    "        pred.append(score[0][0])\n",
    "        pred_score.append(result[key])\n",
    "    print(classification_report(gold, pred, digits=4))\n",
    "    return pred, gold, pred_score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bef11639-006f-4482-a104-1fc2e8d1b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluation_ece(pred, gold):\n",
    "    \n",
    "    pred_score_l = []\n",
    "    mapping_dict = {}\n",
    "    for item in pred:\n",
    "        pred_score_l.append([])\n",
    "        for idx, p in enumerate(item):\n",
    "            if p[0] in mapping_dict:\n",
    "                mapping_dict[p[0]] = idx\n",
    "            pred_score_l[-1].append(p[1])\n",
    "    pred_score_l = torch.tensor(pred_score_l)\n",
    "    gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "    \n",
    "    ece_fn = ECE(n_bins=15)\n",
    "    print(ece_fn(pred_score_l, gold_l, mode='probs'), '==ece==')\n",
    "\n",
    "def evaluation(model_path):\n",
    "    risk_api.reload(model_path)\n",
    "    print('===offensive===')\n",
    "    pred, gold, pred_score = eval_all(offensive_test, risk_api, 'offensive')\n",
    "    evaluation_ece(pred, gold)\n",
    "    print('===cdia-bias===')\n",
    "    pred, gold, pred_score = eval_all(cdia_bias, risk_api, 'bias')\n",
    "    evaluation_ece(pred, gold)\n",
    "    print('===ciron===')\n",
    "    pred, gold, pred_score = eval_all(ciron, risk_api, 'ciron')\n",
    "    evaluation_ece(pred, gold)\n",
    "    print('===chsenti===')\n",
    "    pred, gold, pred_score = eval_all(senti_copr, risk_api, 'senti')\n",
    "    evaluation_ece(pred, gold)\n",
    "    print('===senti_smpecisa===')\n",
    "    pred, gold, pred_score = eval_all(senti_smpecisa, risk_api, 'senti')\n",
    "    evaluation_ece(pred, gold)\n",
    "    print('===senti_smp===')\n",
    "    pred, gold, pred_score = eval_all(senti_smp, risk_api, 'senti')\n",
    "    evaluation_ece(pred, gold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c81a54a-1768-4454-9e04-7f9c8c52673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===offensive===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [00:42<00:00, 123.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          冒犯     0.7050    0.8794    0.7826      2106\n",
      "          正常     0.9051    0.7577    0.8249      3198\n",
      "\n",
      "    accuracy                         0.8060      5304\n",
      "   macro avg     0.8051    0.8185    0.8037      5304\n",
      "weighted avg     0.8257    0.8060    0.8081      5304\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pred_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_124855/3540077760.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_intent_v1/multitask_cls.pth.9'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_124855/2874970738.py\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===offensive==='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffensive_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'offensive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mevaluation_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===cdia-bias==='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdia_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bias'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_124855/2874970738.py\u001b[0m in \u001b[0;36mevaluation_ece\u001b[0;34m(pred, gold)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpred_score_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmapping_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mpred_score_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_score' is not defined"
     ]
    }
   ],
   "source": [
    "evaluation('/data/albert.xht/xiaodao/risk_classification/multitask_raw_all_intent_v1/multitask_cls.pth.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516aa865-ee8f-4253-94b8-b1b79477427e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d21ccffe-66ff-4772-88de-6ab24412153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ece_fn = ECE(n_bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32cc476b-9973-4b61-8b05-85cdca4a3e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1104])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict = {\n",
    "    '冒犯':0,\n",
    "    '正常':1\n",
    "}\n",
    "\n",
    "gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "pred_score_l = torch.tensor([[item[0][1], item[1][1]] for item in pred_score])\n",
    "\n",
    "ece_fn(pred_score_l, gold_l, mode='probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f8d4490-f58a-441f-95fa-f38238cc70bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0198])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict = {\n",
    "    '负向':0,\n",
    "    '正向':1\n",
    "}\n",
    "\n",
    "gold_l = torch.tensor([mapping_dict[item] for item in gold])\n",
    "pred_score_l = torch.tensor([[item[0][1], item[1][1]] for item in pred_score])\n",
    "\n",
    "ece_fn(pred_score_l, gold_l, mode='probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32e811-a4a8-4415-b2d5-ef3d3c89ffd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
