{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de7f2d-11b2-460e-8f5f-38a13ccb940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "\n",
    "human_pattern = re.compile(u\"(?<=\\n\\nHuman:)(.+?)(?=\\n\\nAssistant:)\")\n",
    "assist_pattern = re.compile(u\"Assistant:.+\")\n",
    "with open('/data/albert.xht/hh-rlhf/hh-rlhf.json.harmless.single') as frobj: \n",
    "    harmless = {}\n",
    "    for idx, line in enumerate(frobj):\n",
    "        content = json.loads(line.strip())\n",
    "        text = content['text']\n",
    "        human_list = human_pattern.findall(text)\n",
    "        assistant = assist_pattern.findall(text)\n",
    "\n",
    "        if len(human_list) == 0:\n",
    "            continue\n",
    "        if len(human_list) >= 2:\n",
    "            continue\n",
    "            \n",
    "        content['human'] = human_list[0]\n",
    "        content['assistant'] = re.sub('Assistant:', '', assistant[0])\n",
    "        \n",
    "        if content['human'] not in harmless:\n",
    "            harmless[content['human']] =content\n",
    "            \n",
    "hhrlhf_harmless = []\n",
    "left = []\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_single/merge.json') as frobj:\n",
    "    for idx, line in enumerate(frobj):\n",
    "        content = json.loads(line.strip())\n",
    "        text = content['text']\n",
    "        human_list = human_pattern.findall(text)\n",
    "        assistant = assist_pattern.findall(text)\n",
    "\n",
    "        if len(human_list) == 0:\n",
    "            continue\n",
    "        if len(human_list) >= 2:\n",
    "            continue\n",
    "            \n",
    "        content['human'] = human_list[0]\n",
    "        content['assistant'] = re.sub('Assistant:', '', assistant[0])\n",
    "        \n",
    "        if content['human'] in harmless:\n",
    "            hhrlhf_harmless.append(content)\n",
    "        else:\n",
    "            left.append(content)\n",
    "            \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_single/merge.json.harmless', 'w') as fwobj:\n",
    "    for d in hhrlhf_harmless:\n",
    "        fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ea3691-f9bd-43c3-b149-e6ec98f17e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "\n",
    "human_pattern = re.compile(u\"(?<=\\n\\nHuman:)(.+?)(?=\\n\\nAssistant:)\")\n",
    "assist_pattern = re.compile(u\"Assistant:.+\")\n",
    "with open('/data/albert.xht/hh-rlhf/hh-rlhf.json.harmless.single') as frobj: \n",
    "    harmless = {}\n",
    "    for idx, line in enumerate(frobj):\n",
    "        content = json.loads(line.strip())\n",
    "        text = content['text']\n",
    "        \n",
    "        content['text'] = re.sub('Human:', '用户:', content['text'])\n",
    "        content['text'] = re.sub('Assistant:', '助手:', content['text'])\n",
    "        \n",
    "        if content['text'] not in harmless:\n",
    "            harmless[content['text']] =content\n",
    "            \n",
    "hhrlhf_harmless = []\n",
    "left = []\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all/merge.txt') as frobj:\n",
    "    for idx, line in enumerate(frobj):\n",
    "        content = json.loads(line.strip())\n",
    "        text = content['text']\n",
    "        human_list = human_pattern.findall(text)\n",
    "        assistant = assist_pattern.findall(text)\n",
    "        \n",
    "        if content['text'] in harmless:\n",
    "            hhrlhf_harmless.append(content)\n",
    "        else:\n",
    "            left.append(content)\n",
    "            \n",
    "with open('/data/albert.xht/xiaoda/query_response/red_team/hhrlhf_merge.json.harmless', 'w') as fwobj:\n",
    "    for d in hhrlhf_harmless:\n",
    "        fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4199ad64-bac4-4a60-b278-fff791267159",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static/rewards/train.txt', 'w') as fwobj:\n",
    "    data_dict = {}\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static/merge.txt.modified') as frobj:\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['source'] in ['train']:\n",
    "                if '助手:' in content['text_translate'].split('\\n')[-1]:\n",
    "                    context = '\\n'.join(content['text_translate'].split('\\n')[:-1])\n",
    "                    if context not in data_dict:\n",
    "                        data_dict[context] = []\n",
    "                    data_dict[context].append(content)\n",
    "    for context in data_dict:\n",
    "        if len(data_dict[context]) == 2:\n",
    "            tmp_list = []\n",
    "            left_list = []\n",
    "            for d in data_dict[context]:\n",
    "                if d['label'] in ['chosen']:\n",
    "                    tmp_list.append(d['text_translate'])\n",
    "                else:\n",
    "                    left_list.append(d['text_translate'])\n",
    "            # print(tmp_list, '==left list==', left_list)\n",
    "            tmp_list += left_list\n",
    "            if left_list:\n",
    "                fwobj.write(json.dumps(tmp_list, ensure_ascii=False)+'\\n')\n",
    "                \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static/rewards/dev.txt', 'w') as fwobj:\n",
    "    data_dict = {}\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static/merge.txt.modified') as frobj:\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['source'] in ['test']:\n",
    "                if '助手:' in content['text_translate'].split('\\n')[-1]:\n",
    "                    context = '\\n'.join(content['text_translate'].split('\\n')[:-1])\n",
    "                    if context not in data_dict:\n",
    "                        data_dict[context] = []\n",
    "                    data_dict[context].append(content)\n",
    "    for context in data_dict:\n",
    "        if len(data_dict[context]) == 2:\n",
    "            tmp_list = []\n",
    "            left_list = []\n",
    "            for d in data_dict[context]:\n",
    "                if d['label'] in ['chosen']:\n",
    "                    tmp_list.append(d['text_translate'])\n",
    "                else:\n",
    "                    left_list.append(d['text_translate'])\n",
    "            # print(tmp_list, '==left list==', left_list)\n",
    "            tmp_list += left_list\n",
    "            if left_list:\n",
    "                fwobj.write(json.dumps(tmp_list, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66409511-3d38-4434-b0e1-4c6ccb4c508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "\n",
    "pair_data_dict = {}\n",
    "l = []\n",
    "with open('/data/albert.xht/hh-rlhf/rm-static.json.v1') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        content_pair = []\n",
    "        for t in content['text']:\n",
    "            t = re.sub('\\n\\nHuman:', '\\n\\n用户:', t)\n",
    "            t = re.sub('\\n\\nAssistant:', '\\n\\n助手:', t)\n",
    "            t = re.sub('\\n\\nAssistant ', '\\n\\n助手:', t)\n",
    "            ori_list = []\n",
    "            for sent in re.split('\\n', t):\n",
    "                if re.search('[0-9a-zA-Z]+', sent):\n",
    "                    ori_list.append(sent)\n",
    "            content_pair.append('\\n'.join(ori_list))\n",
    "        if tuple(content_pair) not in pair_data_dict:\n",
    "            pair_data_dict[tuple(content_pair)] = ''\n",
    "            \n",
    "print(len(pair_data_dict), '==pair_data_dict==')\n",
    "\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static_update/rewards/train.txt', 'w') as fwobj:\n",
    "    data_dict = {}\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static_update/merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['source'] in ['train']:\n",
    "                last_idx = 0\n",
    "                for idx, sent in enumerate(content['text_ori'].split('\\n')):\n",
    "                    if re.search('^助手:', sent):\n",
    "                        last_idx = idx\n",
    "                context = '\\n'.join(content['text_ori'].split('\\n')[:last_idx])\n",
    "                if context not in data_dict:\n",
    "                    data_dict[context] = []\n",
    "                data_dict[context].append(content)\n",
    "    for context in data_dict:\n",
    "        if len(data_dict[context]) >= 2:\n",
    "            pair_dict = {\n",
    "                'chosen':[],\n",
    "                'rejected':[]\n",
    "            }\n",
    "            for d in data_dict[context]:\n",
    "                if d['label'] in ['chosen']:\n",
    "                    pair_dict['chosen'].append(d)\n",
    "                else:\n",
    "                    pair_dict['rejected'].append(d)\n",
    "            \n",
    "            if pair_dict['rejected'] and pair_dict['chosen']:\n",
    "                output_list = beam_search(pair_dict)\n",
    "                for d in output_list:\n",
    "                    if d[0]['text_ori'] == d[1]['text_ori']:\n",
    "                        continue\n",
    "                    if tuple([d[0]['text_ori'], d[1]['text_ori']]) in pair_data_dict:\n",
    "                        if d[0]['text_translate'] == 'no-valid-translate':\n",
    "                            continue\n",
    "                        if d[1]['text_translate'] == 'no-valid-translate':\n",
    "                            continue\n",
    "                        fwobj.write(json.dumps([d[0]['text_translate'], d[1]['text_translate']], ensure_ascii=False)+'\\n')\n",
    "                \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static_update/rewards/dev.txt', 'w') as fwobj:\n",
    "    data_dict = {}\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static_update/merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['source'] in ['test']:\n",
    "                last_idx = 0\n",
    "                for idx, sent in enumerate(content['text_ori'].split('\\n')):\n",
    "                    if re.search('^助手:', sent):\n",
    "                        last_idx = idx\n",
    "                context = '\\n'.join(content['text_ori'].split('\\n')[:last_idx])\n",
    "                if context not in data_dict:\n",
    "                    data_dict[context] = []\n",
    "                data_dict[context].append(content)\n",
    "    for context in data_dict:\n",
    "        if len(data_dict[context]) >= 2:\n",
    "            pair_dict = {\n",
    "                'chosen':[],\n",
    "                'rejected':[]\n",
    "            }\n",
    "            for d in data_dict[context]:\n",
    "                if d['label'] in ['chosen']:\n",
    "                    pair_dict['chosen'].append(d)\n",
    "                else:\n",
    "                    pair_dict['rejected'].append(d)\n",
    "            \n",
    "            if pair_dict['rejected'] and pair_dict['chosen']:\n",
    "                output_list = beam_search(pair_dict)\n",
    "                for d in output_list:\n",
    "                    if d[0]['text_ori'] == d[1]['text_ori']:\n",
    "                        continue\n",
    "                    if d[0]['text_translate'] == 'no-valid-translate':\n",
    "                        continue\n",
    "                    if d[1]['text_translate'] == 'no-valid-translate':\n",
    "                        continue\n",
    "                    if tuple([d[0]['text_ori'], d[1]['text_ori']]) in pair_data_dict:\n",
    "                        fwobj.write(json.dumps([d[0]['text_translate'], d[1]['text_translate']], ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86a4ca-c5b5-4709-ba28-804a6d5025a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "\n",
    "pair_data_dict = {}\n",
    "l = []\n",
    "with open('/data/albert.xht/hh-rlhf/rm-static.json.v1') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        if tuple(content['text']) not in pair_data_dict:\n",
    "            pair_data_dict[tuple(content['text'])] = ''\n",
    "\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static_update/rewards/train.txt.en', 'w') as fwobj:\n",
    "    data_dict = {}\n",
    "    with open('/data/albert.xht/hh-rlhf/rm-static.json') as frobj:\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['source'] in ['train']:\n",
    "                last_idx = 0\n",
    "                for idx, sent in enumerate(content['text'].split('\\n\\n')):\n",
    "                    if re.search('^Assistant:', sent):\n",
    "                        last_idx = idx\n",
    "                context = '\\n\\n'.join(content['text'].split('\\n\\n')[:last_idx])\n",
    "                if context not in data_dict:\n",
    "                    data_dict[context] = []\n",
    "                data_dict[context].append(content)\n",
    "    for context in data_dict:\n",
    "        if len(data_dict[context]) >= 2:\n",
    "            pair_dict = {\n",
    "                'chosen':[],\n",
    "                'rejected':[]\n",
    "            }\n",
    "            for d in data_dict[context]:\n",
    "                if d['label'] in ['chosen']:\n",
    "                    pair_dict['chosen'].append(d['text'])\n",
    "                else:\n",
    "                    pair_dict['rejected'].append(d['text'])\n",
    "            \n",
    "            if pair_dict['rejected'] and pair_dict['chosen']:\n",
    "                output_list = beam_search(pair_dict)\n",
    "                for d in output_list:\n",
    "                    if d[0] == d[1]:\n",
    "                        continue\n",
    "                    if (d[0], d[1]) in pair_data_dict:\n",
    "                        fwobj.write(json.dumps([d[0], d[1]], ensure_ascii=False)+'\\n')\n",
    "                \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static_update/rewards/dev.txt.en', 'w') as fwobj:\n",
    "    data_dict = {}\n",
    "    with open('/data/albert.xht/hh-rlhf/rm-static.json') as frobj:\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['source'] in ['test']:\n",
    "                last_idx = 0\n",
    "                for idx, sent in enumerate(content['text'].split('\\n\\n')):\n",
    "                    if re.search('^Assistant:', sent):\n",
    "                        last_idx = idx\n",
    "                context = '\\n\\n'.join(content['text'].split('\\n\\n')[:last_idx])\n",
    "                if context not in data_dict:\n",
    "                    data_dict[context] = []\n",
    "                data_dict[context].append(content)\n",
    "    for context in data_dict:\n",
    "        if len(data_dict[context]) >= 2:\n",
    "            pair_dict = {\n",
    "                'chosen':[],\n",
    "                'rejected':[]\n",
    "            }\n",
    "            for d in data_dict[context]:\n",
    "                if d['label'] in ['chosen']:\n",
    "                    pair_dict['chosen'].append(d['text'])\n",
    "                else:\n",
    "                    pair_dict['rejected'].append(d['text'])\n",
    "            \n",
    "            if pair_dict['rejected'] and pair_dict['chosen']:\n",
    "                output_list = beam_search(pair_dict)\n",
    "                for d in output_list:\n",
    "                    if d[0] == d[1]:\n",
    "                        continue\n",
    "                    if (d[0], d[1]) in pair_data_dict:\n",
    "                        fwobj.write(json.dumps([d[0], d[1]], ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa16ba-c0f6-43f1-9a6c-bd78864a2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "import json, re\n",
    "import json, re\n",
    "from sentence_splitter import SentenceSplitter, split_text_into_sentences\n",
    "from collections import OrderedDict\n",
    "\n",
    "def beam_search(dict_data):\n",
    "    sequences = [list()]\n",
    "    for key in dict_data:\n",
    "        all_candidates = list()\n",
    "        for i in range(len(sequences)):\n",
    "            seq = sequences[i]\n",
    "            for item in dict_data[key]:\n",
    "                candidate = seq+[item]\n",
    "                all_candidates.append(candidate)\n",
    "        sequences = all_candidates\n",
    "    return sequences\n",
    "\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_update/rewards/train.txt', 'w') as fwobj:\n",
    "    data_dict = {}\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_update/merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['source'] in ['train']:\n",
    "                last_idx = 0\n",
    "                for idx, sent in enumerate(content['text_translate'].split('\\n')):\n",
    "                    if re.search('^助手:', sent):\n",
    "                        last_idx = idx\n",
    "                context = '\\n'.join(content['text_translate'].split('\\n')[:last_idx])\n",
    "                if context not in data_dict:\n",
    "                    data_dict[context] = []\n",
    "                data_dict[context].append(content)\n",
    "    for context in data_dict:\n",
    "        if len(data_dict[context]) >= 2:\n",
    "            pair_dict = OrderedDict({\n",
    "                'chosen':[],\n",
    "                'rejected':[]\n",
    "            })\n",
    "            for d in data_dict[context]:\n",
    "                if d['label'] in ['chosen']:\n",
    "                    pair_dict['chosen'].append(d['text_translate'])\n",
    "                else:\n",
    "                    pair_dict['rejected'].append(d['text_translate'])\n",
    "            \n",
    "            if pair_dict['rejected'] and pair_dict['chosen']:\n",
    "                output_list = beam_search(pair_dict)\n",
    "                for d in output_list:\n",
    "                    if d[0] == d[1]:\n",
    "                        continue\n",
    "                    fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
    "                \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_update/rewards/dev.txt', 'w') as fwobj:\n",
    "    data_dict = {}\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_update/merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['source'] in ['test']:\n",
    "                last_idx = 0\n",
    "                for idx, sent in enumerate(content['text_translate'].split('\\n')):\n",
    "                    if re.search('^助手:', sent):\n",
    "                        last_idx = idx\n",
    "                context = '\\n'.join(content['text_translate'].split('\\n')[:last_idx])\n",
    "                if context not in data_dict:\n",
    "                    data_dict[context] = []\n",
    "                data_dict[context].append(content)\n",
    "    for context in data_dict:\n",
    "        if len(data_dict[context]) >= 2:\n",
    "            pair_dict = OrderedDict({\n",
    "                'chosen':[],\n",
    "                'rejected':[]\n",
    "            })\n",
    "            for d in data_dict[context]:\n",
    "                if d['label'] in ['chosen']:\n",
    "                    pair_dict['chosen'].append(d['text_translate'])\n",
    "                else:\n",
    "                    pair_dict['rejected'].append(d['text_translate'])\n",
    "            \n",
    "            if pair_dict['rejected'] and pair_dict['chosen']:\n",
    "                output_list = beam_search(pair_dict)\n",
    "                for d in output_list:\n",
    "                    if d[0] == d[1]:\n",
    "                        continue\n",
    "                    fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5b6b5e-1a33-463e-9641-773f8823eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_update/rewards/train.txt.en', 'w') as fwobj:\n",
    "    data_dict = {}\n",
    "    with open('/data/albert.xht/hh-rlhf/hh-rlhf.json') as frobj:\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['source'] in ['train']:\n",
    "                last_idx = 0\n",
    "                for idx, sent in enumerate(content['text'].split('\\n\\n')):\n",
    "                    if re.search('^Assistant:', sent):\n",
    "                        last_idx = idx\n",
    "                context = '\\n'.join(content['text'].split('\\n\\n')[:last_idx])\n",
    "                if context not in data_dict:\n",
    "                    data_dict[context] = []\n",
    "                data_dict[context].append(content)\n",
    "    for context in data_dict:\n",
    "        if len(data_dict[context]) >= 2:\n",
    "            pair_dict = OrderedDict({\n",
    "                'chosen':[],\n",
    "                'rejected':[]\n",
    "            })\n",
    "            for d in data_dict[context]:\n",
    "                if d['label'] in ['chosen']:\n",
    "                    pair_dict['chosen'].append(d['text'])\n",
    "                else:\n",
    "                    pair_dict['rejected'].append(d['text'])\n",
    "            \n",
    "            if pair_dict['rejected'] and pair_dict['chosen']:\n",
    "                output_list = beam_search(pair_dict)\n",
    "                for d in output_list:\n",
    "                    if d[0] == d[1]:\n",
    "                        continue\n",
    "                    fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
    "                \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_update/rewards/dev.txt.en', 'w') as fwobj:\n",
    "    data_dict = {}\n",
    "    with open('/data/albert.xht/hh-rlhf/hh-rlhf.json') as frobj:\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['source'] in ['test']:\n",
    "                last_idx = 0\n",
    "                for idx, sent in enumerate(content['text'].split('\\n\\n')):\n",
    "                    if re.search('^Assistant:', sent):\n",
    "                        last_idx = idx\n",
    "                context = '\\n'.join(content['text'].split('\\n\\n')[:last_idx])\n",
    "                if context not in data_dict:\n",
    "                    data_dict[context] = []\n",
    "                data_dict[context].append(content)\n",
    "    for context in data_dict:\n",
    "        if len(data_dict[context]) >= 2:\n",
    "            pair_dict = OrderedDict({\n",
    "                'chosen':[],\n",
    "                'rejected':[]\n",
    "            })\n",
    "            for d in data_dict[context]:\n",
    "                if d['label'] in ['chosen']:\n",
    "                    pair_dict['chosen'].append(d['text'])\n",
    "                else:\n",
    "                    pair_dict['rejected'].append(d['text'])\n",
    "            \n",
    "            if pair_dict['rejected'] and pair_dict['chosen']:\n",
    "                output_list = beam_search(pair_dict)\n",
    "                for d in output_list:\n",
    "                    if d[0] == d[1]:\n",
    "                        continue\n",
    "                    fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d9035-116e-4d1a-a10a-dfd3412744bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "import json, re\n",
    "from sentence_splitter import SentenceSplitter, split_text_into_sentences\n",
    "from collections import OrderedDict\n",
    "\n",
    "def beam_search(dict_data):\n",
    "    sequences = [list()]\n",
    "    for key in dict_data:\n",
    "        all_candidates = list()\n",
    "        for i in range(len(sequences)):\n",
    "            seq = sequences[i]\n",
    "            for item in dict_data[key]:\n",
    "                candidate = seq+[item]\n",
    "                all_candidates.append(candidate)\n",
    "        sequences = all_candidates\n",
    "    return sequences\n",
    "\n",
    "pair_data_dict = {}\n",
    "l = []\n",
    "with open('/data/albert.xht/hh-rlhf/filtered-SHP.json.v1') as frobj:\n",
    "    for line in frobj:\n",
    "        content = json.loads(line.strip())\n",
    "        if tuple(content['text']) not in pair_data_dict:\n",
    "            pair_data_dict[tuple(content['text'])] = ''\n",
    "            \n",
    "from tqdm import tqdm\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp_v1/rewards/train.txt', 'w') as fwobj:\n",
    "    data_dict = {}\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp_v1/merge.txt') as frobj:\n",
    "        for (idx_, line) in tqdm(enumerate(frobj)):\n",
    "            content = json.loads(line.strip())\n",
    "            content['text_ori'] = re.sub('^用户:', 'Human:', content['text_ori'])\n",
    "            content['text_ori'] = re.sub('助手:', '\\n\\nAssistant:', content['text_ori'])\n",
    "            if content['source'] in ['train']:\n",
    "                last_idx = 0\n",
    "                split_sent = split_text_into_sentences(content['text_ori'], 'en')\n",
    "                for idx, sent in enumerate(split_sent):\n",
    "                    if re.search('^Assistant:', sent):\n",
    "                        last_idx = idx\n",
    "                context = ' '.join(split_sent[:last_idx])\n",
    "                if context not in data_dict:\n",
    "                    data_dict[context] = []\n",
    "                data_dict[context].append(content)\n",
    "                \n",
    "    for context in data_dict:\n",
    "        if len(data_dict[context]) >= 2:\n",
    "            pair_dict = OrderedDict({\n",
    "                'chosen':[],\n",
    "                'rejected':[]\n",
    "            })\n",
    "            for d in data_dict[context]:\n",
    "                if d['label'] in ['chosen']:\n",
    "                    pair_dict['chosen'].append(d)\n",
    "                else:\n",
    "                    pair_dict['rejected'].append(d)\n",
    "            \n",
    "            if pair_dict['rejected'] and pair_dict['chosen']:\n",
    "                output_list = beam_search(pair_dict)\n",
    "                for d in output_list:\n",
    "                    if tuple([p['text_ori'] for p in d]) not in pair_data_dict:\n",
    "                        continue\n",
    "                    d_ = [p['text_translate'] for p in d]\n",
    "                    fwobj.write(json.dumps(d_, ensure_ascii=False)+'\\n')\n",
    "                \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp_v1/rewards/dev.txt', 'w') as fwobj:\n",
    "    data_dict = {}\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp_v1/merge.txt') as frobj:\n",
    "        for line in tqdm(frobj):\n",
    "            content = json.loads(line.strip())\n",
    "            content['text_ori'] = re.sub('^用户:', 'Human:', content['text_ori'])\n",
    "            content['text_ori'] = re.sub('助手:', 'Assistant:', content['text_ori'])\n",
    "            if content['source'] in ['test']:\n",
    "                last_idx = 0\n",
    "                split_sent = split_text_into_sentences(content['text_ori'], 'en')\n",
    "                for idx, sent in enumerate(split_sent):\n",
    "                    if re.search('^Assistant:', sent):\n",
    "                        last_idx = idx\n",
    "                context = ''.join(split_sent[:last_idx])\n",
    "                if context not in data_dict:\n",
    "                    data_dict[context] = []\n",
    "                data_dict[context].append(content)\n",
    "    for context in data_dict:\n",
    "        if len(data_dict[context]) >= 2:\n",
    "            pair_dict = OrderedDict({\n",
    "                'chosen':[],\n",
    "                'rejected':[]\n",
    "            })\n",
    "            for d in data_dict[context]:\n",
    "                if d['label'] in ['chosen']:\n",
    "                    pair_dict['chosen'].append(d)\n",
    "                else:\n",
    "                    pair_dict['rejected'].append(d)\n",
    "            \n",
    "            if pair_dict['rejected'] and pair_dict['chosen']:\n",
    "                output_list = beam_search(pair_dict)\n",
    "                for d in output_list:\n",
    "                    if tuple([p['text_ori'] for p in d]) not in pair_data_dict:\n",
    "                        continue\n",
    "                    d_ = [p['text_translate'] for p in d]\n",
    "                    fwobj.write(json.dumps(d_, ensure_ascii=False)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdedc236-7c54-4d11-bf97-9a06d5d5a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "import json, re\n",
    "import json, re\n",
    "from sentence_splitter import SentenceSplitter, split_text_into_sentences\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "def beam_search(dict_data):\n",
    "    sequences = [list()]\n",
    "    for key in dict_data:\n",
    "        all_candidates = list()\n",
    "        for i in range(len(sequences)):\n",
    "            seq = sequences[i]\n",
    "            for item in dict_data[key]:\n",
    "                candidate = seq+[item]\n",
    "                all_candidates.append(candidate)\n",
    "        sequences = all_candidates\n",
    "    return sequences\n",
    "\n",
    "from datasets import load_dataset\n",
    "            \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp_v1/rewards/train.txt.en', 'w') as fwobj:\n",
    "    dataset = load_dataset('Dahoas/filtered-SHP')        \n",
    "    for d in dataset['train']:\n",
    "        content = [d['prompt']+d['chosen'], d['prompt']+d['rejected']]\n",
    "        fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "                \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp_v1/rewards/dev.txt.en', 'w') as fwobj:\n",
    "    dataset = load_dataset('Dahoas/filtered-SHP')        \n",
    "    for d in dataset['test']:\n",
    "        content = [d['prompt']+d['chosen'], d['prompt']+d['rejected']]\n",
    "        fwobj.write(json.dumps(content, ensure_ascii=False)+'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088fbf99-abc6-471a-b689-e9509a0d221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "\n",
    "def beam_search(dict_data):\n",
    "    sequences = [list()]\n",
    "    for key in dict_data:\n",
    "        all_candidates = list()\n",
    "        for i in range(len(sequences)):\n",
    "            seq = sequences[i]\n",
    "            for item in dict_data[key]:\n",
    "                candidate = seq+[item]\n",
    "                all_candidates.append(candidate)\n",
    "        sequences = all_candidates\n",
    "    return sequences\n",
    "\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp/rewards/train.txt.en', 'w') as fwobj:\n",
    "    data_dict = {}\n",
    "    with open('/data/albert.xht/hh-rlhf/filtered-SHP.json') as frobj:\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['source'] in ['train']:\n",
    "                last_idx = 0\n",
    "                for idx, sent in enumerate(content['text'].split('\\n\\n')):\n",
    "                    if re.search('^Assistant:', sent):\n",
    "                        last_idx = idx\n",
    "                context = '\\n'.join(content['text'].split('\\n\\n')[:last_idx])\n",
    "                if context not in data_dict:\n",
    "                    data_dict[context] = []\n",
    "                data_dict[context].append(content)\n",
    "    for context in data_dict:\n",
    "        if len(data_dict[context]) >=2:\n",
    "            pair_dict = {\n",
    "                'chosen':[],\n",
    "                'rejected':[]\n",
    "            }\n",
    "            for d in data_dict[context]:\n",
    "                if d['label'] in ['chosen']:\n",
    "                    pair_dict['chosen'].append(d['text'])\n",
    "                else:\n",
    "                    left_list.append(d['text'])\n",
    "                    pair_dict['rejected'].append(d['text'])\n",
    "            \n",
    "            if pair_dict['rejected']:\n",
    "                output_list = beam_search(pair_dict)\n",
    "                for d in output_list:\n",
    "                    if d[0] == d[1]:\n",
    "                        continue\n",
    "                    fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
    "                \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp/rewards/dev.txt.en', 'w') as fwobj:\n",
    "    data_dict = {}\n",
    "    with open('/data/albert.xht/hh-rlhf/filtered-SHP.json') as frobj:\n",
    "        for line in frobj:\n",
    "            content = json.loads(line.strip())\n",
    "            if content['source'] in ['test']:\n",
    "                last_idx = 0\n",
    "                for idx, sent in enumerate(content['text'].split('\\n\\n')):\n",
    "                    if re.search('^Assistant:', sent):\n",
    "                        last_idx = idx\n",
    "                context = '\\n'.join(content['text'].split('\\n\\n')[:last_idx])\n",
    "                if context not in data_dict:\n",
    "                    data_dict[context] = []\n",
    "                data_dict[context].append(content)\n",
    "    for context in data_dict:\n",
    "        if len(data_dict[context]) >= 2:\n",
    "            pair_dict = {\n",
    "                'chosen':[],\n",
    "                'rejected':[]\n",
    "            }\n",
    "            for d in data_dict[context]:\n",
    "                if d['label'] in ['chosen']:\n",
    "                    pair_dict['chosen'].append(d['text'])\n",
    "                else:\n",
    "                    left_list.append(d['text'])\n",
    "                    pair_dict['rejected'].append(d['text'])\n",
    "            \n",
    "            if pair_dict['rejected']:\n",
    "                output_list = beam_search(pair_dict)\n",
    "                for d in output_list:\n",
    "                    if d[0] == d[1]:\n",
    "                        continue\n",
    "                    fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc1b66-05b0-4a13-b4d7-2e6a6c30e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "# Human Follow Up Commen\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_helpful_update/rewards/train.txt', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_helpful_update/merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            flag = False\n",
    "            for key in ['prompt', 'chosen', 'rejected']:\n",
    "                if re.search('Human Follow Up', content[key]) or re.search('Human Comment', content[key]):\n",
    "                    flag = True\n",
    "                    break\n",
    "                if re.search(\"Assistant's Response\", content[key]):\n",
    "                    flag = True\n",
    "                    break\n",
    "            if flag:\n",
    "                continue\n",
    "            for key in ['prompt_translate', 'chosen_translate', 'rejected_translate']:\n",
    "                content[key] = re.sub('人类:', '用户:', content[key])\n",
    "                content[key] = re.sub('助理:', '助手:', content[key])\n",
    "            d = [content['prompt_translate']+'\\n\\n助手:'+content['chosen_translate'], \n",
    "                 content['prompt_translate']+'\\n\\n助手:'+content['rejected_translate']]\n",
    "            if content['source'] in ['train']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
    "                \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_helpful_update/rewards/dev.txt', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_helpful_update/merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            flag = False\n",
    "            for key in ['prompt', 'chosen', 'rejected']:\n",
    "                if re.search('Human Follow Up', content[key]) or re.search('Human Comment', content[key]):\n",
    "                    flag = True\n",
    "                    break\n",
    "                if re.search(\"Assistant's Response\", content[key]):\n",
    "                    flag = True\n",
    "                    break\n",
    "            if flag:\n",
    "                continue\n",
    "            for key in ['prompt_translate', 'chosen_translate', 'rejected_translate']:\n",
    "                content[key] = re.sub('人类:', '用户:', content[key])\n",
    "                content[key] = re.sub('助理:', '助手:', content[key])\n",
    "            d = [content['prompt_translate']+'\\n\\n助手:'+content['chosen_translate'], \n",
    "                 content['prompt_translate']+'\\n\\n助手:'+content['rejected_translate']]\n",
    "            if content['source'] in ['test']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
    "                \n",
    "            \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_helpful_update/rewards/train.txt.en', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_helpful_update/merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            flag = False\n",
    "            for key in ['prompt', 'chosen', 'rejected']:\n",
    "                if re.search('Human Follow Up', content[key]) or re.search('Human Comment', content[key]):\n",
    "                    flag = True\n",
    "                    break\n",
    "                if re.search(\"Assistant's Response\", content[key]):\n",
    "                    flag = True\n",
    "                    break\n",
    "            if flag:\n",
    "                continue\n",
    "            for key in ['prompt', 'chosen', 'rejected']:\n",
    "                content[key] = re.sub('用户:', 'Human:', content[key])\n",
    "                content[key] = re.sub('助手:', 'Assistant:' , content[key])\n",
    "            d = [content['prompt']+content['chosen'], \n",
    "                 content['prompt']+content['rejected']]\n",
    "            if content['source'] in ['train']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
    "\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_helpful_update/rewards/dev.txt.en', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_helpful_update/merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            flag = False\n",
    "            for key in ['prompt', 'chosen', 'rejected']:\n",
    "                if re.search('Human Follow Up', content[key]) or re.search('Human Comment', content[key]):\n",
    "                    flag = True\n",
    "                    break\n",
    "                if re.search(\"Assistant's Response\", content[key]):\n",
    "                    flag = True\n",
    "                    break\n",
    "            if flag:\n",
    "                continue\n",
    "            for key in ['prompt', 'chosen', 'rejected']:\n",
    "                content[key] = re.sub('用户:', 'Human:', content[key])\n",
    "                content[key] = re.sub('助手:', 'Assistant:' , content[key])\n",
    "            d = [content['prompt']+content['chosen'], \n",
    "                 content['prompt']+content['rejected']]\n",
    "            if content['source'] in ['test']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f97e68-1929-44c9-99a3-de6e6335ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "# Human Follow Up Commen\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static_update_v2/rewards/train.txt', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static_update_v2/merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for key in ['prompt_translate', 'chosen_translate', 'rejected_translate']:\n",
    "                content[key] = re.sub('\\n人类:', '\\n用户:', content[key])\n",
    "                content[key] = re.sub('\\n助理:', '\\n助手:', content[key])\n",
    "            d = [content['prompt_translate']+'\\n\\n助手:'+content['chosen_translate'], \n",
    "                 content['prompt_translate']+'\\n\\n助手:'+content['rejected_translate']]\n",
    "            if content['source'] in ['train']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
    "                \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static_update_v2/rewards/dev.txt', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static_update_v2/merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for key in ['prompt_translate', 'chosen_translate', 'rejected_translate']:\n",
    "                content[key] = re.sub('\\n人类:', '\\n用户:', content[key])\n",
    "                content[key] = re.sub('\\n助理:', '\\n助手:', content[key])\n",
    "            d = [content['prompt_translate']+'\\n\\n助手:'+content['chosen_translate'], \n",
    "                 content['prompt_translate']+'\\n\\n助手:'+content['rejected_translate']]\n",
    "            if content['source'] in ['test']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
    "                \n",
    "            \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static_update_v2/rewards/train.txt.en', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static_update_v2/merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for key in ['prompt', 'chosen', 'rejected']:\n",
    "                content[key] = re.sub('用户:', 'Human:', content[key])\n",
    "                content[key] = re.sub('助手:', 'Assistant:' , content[key])\n",
    "            d = [content['prompt']+content['chosen'], \n",
    "                 content['prompt']+content['rejected']]\n",
    "            if content['source'] in ['train']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
    "\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static_update_v2/rewards/dev.txt.en', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_rm_static_update_v2/merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for key in ['prompt', 'chosen', 'rejected']:\n",
    "                content[key] = re.sub('用户:', 'Human:', content[key])\n",
    "                content[key] = re.sub('助手:', 'Assistant:' , content[key])\n",
    "            d = [content['prompt']+content['chosen'], \n",
    "                 content['prompt']+content['rejected']]\n",
    "            if content['source'] in ['test']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55047fdc-f3cc-4c21-93fc-d745bc18dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "# Human Follow Up Commen\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_fullrlhf_update_v2//rewards/train.txt', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_fullrlhf_update_v2//merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for key in ['prompt_translate', 'chosen_translate', 'rejected_translate']:\n",
    "                content[key] = re.sub('\\n人类:', '\\n用户:', content[key])\n",
    "                content[key] = re.sub('\\n助理:', '\\n助手:', content[key])\n",
    "            d = [content['prompt_translate']+'\\n\\n助手:'+content['chosen_translate'], \n",
    "                 content['prompt_translate']+'\\n\\n助手:'+content['rejected_translate']]\n",
    "            if content['source'] in ['train']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
    "                \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_fullrlhf_update_v2//rewards/dev.txt', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_fullrlhf_update_v2//merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for key in ['prompt_translate', 'chosen_translate', 'rejected_translate']:\n",
    "                content[key] = re.sub('\\n人类:', '\\n用户:', content[key])\n",
    "                content[key] = re.sub('\\n助理:', '\\n助手:', content[key])\n",
    "            d = [content['prompt_translate']+'\\n\\n助手:'+content['chosen_translate'], \n",
    "                 content['prompt_translate']+'\\n\\n助手:'+content['rejected_translate']]\n",
    "            if content['source'] in ['test']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
    "                \n",
    "            \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_fullrlhf_update_v2//rewards/train.txt.en', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_fullrlhf_update_v2//merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for key in ['prompt', 'chosen', 'rejected']:\n",
    "                content[key] = re.sub('用户:', 'Human:', content[key])\n",
    "                content[key] = re.sub('助手:', 'Assistant:' , content[key])\n",
    "            d = [content['prompt']+content['chosen'], \n",
    "                 content['prompt']+content['rejected']]\n",
    "            if content['source'] in ['train']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
    "\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_fullrlhf_update_v2//rewards/dev.txt.en', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_fullrlhf_update_v2//merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for key in ['prompt', 'chosen', 'rejected']:\n",
    "                content[key] = re.sub('用户:', 'Human:', content[key])\n",
    "                content[key] = re.sub('助手:', 'Assistant:' , content[key])\n",
    "            d = [content['prompt']+content['chosen'], \n",
    "                 content['prompt']+content['rejected']]\n",
    "            if content['source'] in ['test']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b519730-bcd2-4a38-b8c0-203a13157f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "# Human Follow Up Commen\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp_v2//rewards/train.txt', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp_v2//merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for key in ['prompt_translate', 'chosen_translate', 'rejected_translate']:\n",
    "                content[key] = re.sub('\\n人类:', '\\n用户:', content[key])\n",
    "                content[key] = re.sub('\\n助理:', '\\n助手:', content[key])\n",
    "            d = [content['prompt_translate']+'\\n\\n助手:'+content['chosen_translate'], \n",
    "                 content['prompt_translate']+'\\n\\n助手:'+content['rejected_translate']]\n",
    "            if content['source'] in ['train']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
    "                \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp_v2//rewards/dev.txt', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp_v2//merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for key in ['prompt_translate', 'chosen_translate', 'rejected_translate']:\n",
    "                content[key] = re.sub('\\n人类:', '\\n用户:', content[key])\n",
    "                content[key] = re.sub('\\n助理:', '\\n助手:', content[key])\n",
    "            d = [content['prompt_translate']+'\\n\\n助手:'+content['chosen_translate'], \n",
    "                 content['prompt_translate']+'\\n\\n助手:'+content['rejected_translate']]\n",
    "            if content['source'] in ['test']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
    "                \n",
    "            \n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp_v2//rewards/train.txt.en', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp_v2//merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for key in ['prompt', 'chosen', 'rejected']:\n",
    "                content[key] = re.sub('用户:', 'Human:', content[key])\n",
    "                content[key] = re.sub('助手:', 'Assistant:' , content[key])\n",
    "            d = [content['prompt']+content['chosen'], \n",
    "                 content['prompt']+content['rejected']]\n",
    "            if content['source'] in ['train']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
    "\n",
    "with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp_v2//rewards/dev.txt.en', 'w') as fwobj:\n",
    "    with open('/data/albert.xht/hh-rlhf/translate_youdao_all_filtered_shp_v2//merge.txt') as frobj:\n",
    "        for line in frobj:\n",
    "            try:\n",
    "                content = json.loads(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for key in ['prompt', 'chosen', 'rejected']:\n",
    "                content[key] = re.sub('用户:', 'Human:', content[key])\n",
    "                content[key] = re.sub('助手:', 'Assistant:' , content[key])\n",
    "            d = [content['prompt']+content['chosen'], \n",
    "                 content['prompt']+content['rejected']]\n",
    "            if content['source'] in ['test']:\n",
    "                fwobj.write(json.dumps(d, ensure_ascii=False)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
